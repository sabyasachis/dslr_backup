{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-17T13:53:41.795Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from open3d import read_point_cloud\n",
    "\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "def find_valid_points(local_point_cloud):\n",
    "    \"\"\"\n",
    "    find valid points in local point cloud\n",
    "        invalid points have all zeros local coordinates\n",
    "    local_point_cloud: <BxNxk> \n",
    "    valid_points: <BxN> indices  of valid point (0/1)\n",
    "    \"\"\"\n",
    "    eps = 1e-6\n",
    "    non_zero_coord = torch.abs(local_point_cloud) > eps\n",
    "    valid_points = torch.sum(non_zero_coord, dim=-1)\n",
    "    valid_points = valid_points > 0\n",
    "    return valid_points\n",
    "\n",
    "\n",
    "class SimulatedPointCloud(Dataset):\n",
    "    def __init__(self, root, trans_by_pose=None):\n",
    "        # trans_by_pose: <Bx3> pose\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self._trans_by_pose = trans_by_pose\n",
    "        file_list = glob.glob(os.path.join(self.root, '*pcd'))\n",
    "        self.file_list = sorted(file_list)\n",
    "\n",
    "\n",
    "#        self.pcds = [] # a list of open3d pcd objects \n",
    "        point_clouds = [] #a list of tensor <Lx2>\n",
    "        for file in self.file_list:\n",
    "            pcd = read_point_cloud(file)\n",
    "#            self.pcds.append(pcd)\n",
    "            current_point_cloud = np.asarray(pcd.points, dtype=np.float32)[:, 0:2]        \n",
    "            point_clouds.append(current_point_cloud)\n",
    "\n",
    "        point_clouds = np.asarray(point_clouds)\n",
    "        try:\n",
    "            self.point_clouds = torch.from_numpy(point_clouds) # <NxLx2>\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            # Handling the uniform size change across all point clouds\n",
    "            NEW_SIZE = max([current_point_cloud.shape[0] for current_point_cloud in point_clouds]) + 1\n",
    "            print('Aligning pt clouds to equal size of {}'.format(NEW_SIZE))\n",
    "\n",
    "            np.random.seed(0)\n",
    "            new_point_clouds = []\n",
    "            for current_point_cloud in point_clouds:\n",
    "                old_size = current_point_cloud.shape[0]\n",
    "                delta_size = NEW_SIZE - old_size\n",
    "                idx_list = np.random.randint(low=0, high=old_size, size=delta_size)\n",
    "                delta_point_cloud = np.array([current_point_cloud[idx] for idx in idx_list])\n",
    "                new_point_cloud = np.concatenate([current_point_cloud, delta_point_cloud])\n",
    "                new_point_clouds.append(new_point_cloud)\n",
    "            point_clouds = np.asarray(new_point_clouds)\n",
    "            self.point_clouds = torch.from_numpy(point_clouds) # <NxLx2>\n",
    "\n",
    "        self.valid_points = find_valid_points(self.point_clouds) # <NxL>\n",
    "\n",
    "        # number of points in each point cloud\n",
    "        self.n_obs = self.point_clouds.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pcd = self.point_clouds[index,:,:]  # <Lx2>\n",
    "        valid_points = self.valid_points[index,:]\n",
    "        if self._trans_by_pose is not None:\n",
    "            pcd = pcd.unsqueeze(0)  # <1XLx2>\n",
    "            pose = self._trans_by_pose[index, :].unsqueeze(0)  # <1x3>\n",
    "            pcd = utils.transform_to_global_2D(pose, pcd).squeeze(0)\n",
    "        return pcd,valid_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.point_clouds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometry utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     19,
     53,
     87,
     100,
     124,
     166,
     241,
     262,
     274,
     280,
     301
    ]
   },
   "outputs": [],
   "source": [
    "def transform_to_global_2D(pose, obs_local):\n",
    "    \"\"\" \n",
    "    transform local point cloud to global frame\n",
    "    row-based matrix product\n",
    "    pose: <Bx3> each row represents <x,y,theta>\n",
    "    obs_local: <BxLx2> \n",
    "    \"\"\"\n",
    "    L = obs_local.shape[1]\n",
    "    # c0 is the loc of sensor in global coord. frame c0: <Bx2>\n",
    "    c0, theta0 = pose[:, 0:2], pose[:, 2]\n",
    "    c0 = c0.unsqueeze(1).expand(-1, L, -1)  # <BxLx2>\n",
    "\n",
    "    cos = torch.cos(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    sin = torch.sin(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    R_transpose = torch.cat((cos, sin, -sin, cos), dim=1).reshape(-1, 2, 2)\n",
    "\n",
    "    obs_global = torch.bmm(obs_local, R_transpose) + c0\n",
    "    return obs_global\n",
    "\n",
    "def transform_to_global_AVD(pose, obs_local):\n",
    "    \"\"\"\n",
    "    transform obs local coordinate to global corrdinate frame\n",
    "    :param pose: <Bx3> <x,z,theta> y = 0\n",
    "    :param obs_local: <BxLx3> (unorganized) or <BxHxWx3> (organized)\n",
    "    :return obs_global: <BxLx3> (unorganized) or <BxHxWx3> (organized)\n",
    "    \"\"\"\n",
    "    is_organized = 1 if len(obs_local.shape) == 4 else 0\n",
    "    b = obs_local.shape[0]\n",
    "    if is_organized:\n",
    "        H,W = obs_local.shape[1:3]\n",
    "        obs_local = obs_local.view(b,-1,3) # <BxLx3>\n",
    "    \n",
    "    L = obs_local.shape[1]\n",
    "\n",
    "    c0, theta0 = pose[:,0:2],pose[:,2] # c0 is the loc of sensor in global coord frame c0 <Bx2> <x,z>\n",
    "\n",
    "    zero = torch.zeros_like(c0[:,:1])\n",
    "    c0 = torch.cat((c0,zero),-1) # <Bx3> <x,z,y=0>\n",
    "    c0 = c0[:,[0,2,1]] # <Bx3> <x,y=0,z>\n",
    "    c0 = c0.unsqueeze(1).expand(-1,L,-1) # <BxLx3>\n",
    "    \n",
    "    cos = torch.cos(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    sin = torch.sin(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    zero = torch.zeros_like(sin)\n",
    "    one = torch.ones_like(sin)\n",
    "    \n",
    "    R_y_transpose = torch.cat((cos,zero,-sin,zero,one,zero,sin,zero,cos),dim=1).reshape(-1,3,3)\n",
    "    obs_global = torch.bmm(obs_local,R_y_transpose) + c0\n",
    "    if is_organized:\n",
    "        obs_global = obs_global.view(b,H,W,3)\n",
    "    return obs_global\n",
    "\n",
    "\n",
    "def rigid_transform_kD(A, B):\n",
    "    \"\"\"\n",
    "    Find optimal transformation between two sets of corresponding points\n",
    "    Adapted from: http://nghiaho.com/uploads/code/rigid_transform_3D.py_\n",
    "    Args:\n",
    "        A.B: <Nxk> each row represent a k-D points\n",
    "    Returns:\n",
    "        R: kxk\n",
    "        t: kx1\n",
    "        B = R*A+t\n",
    "    \"\"\"\n",
    "    assert len(A) == len(B)\n",
    "    N,k = A.shape\n",
    "    \n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    \n",
    "    # centre the points\n",
    "    AA = A - np.tile(centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "\n",
    "    H = np.matmul(np.transpose(AA) , BB)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = np.matmul(Vt.T , U.T)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[k-1,:] *= -1\n",
    "        R = np.matmul(Vt.T , U.T)\n",
    "\n",
    "    t = np.matmul(-R,centroid_A.T) + centroid_B.T\n",
    "    t = np.expand_dims(t,-1)\n",
    "    return R, t\n",
    "\n",
    "def estimate_normal_eig(data):\n",
    "    \"\"\"\n",
    "    Computes the vector normal to the k-dimensional sample points\n",
    "    \"\"\"\n",
    "    data -= np.mean(data,axis=0)\n",
    "    data = data.T\n",
    "    A = np.cov(data)\n",
    "    w,v = np.linalg.eig(A)\n",
    "    idx = np.argmin(w)\n",
    "    v = v[:,idx]\n",
    "    v /= np.linalg.norm(v,2)\n",
    "    return v\n",
    "    \n",
    "def surface_normal(pc,n_neighbors=6):\n",
    "    \"\"\"\n",
    "    Estimate point cloud surface normal\n",
    "    Args:\n",
    "        pc: Nxk matrix representing k-dimensional point cloud\n",
    "    \"\"\"\n",
    "    \n",
    "    n_points,k = pc.shape\n",
    "    v = np.zeros_like(pc)\n",
    "    \n",
    "    # nn search\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(pc)\n",
    "    _, indices = nbrs.kneighbors(pc)\n",
    "    neighbor_points = pc[indices]\n",
    "    for i in range(n_points):\n",
    "        # estimate surface normal\n",
    "        v_tmp = estimate_normal_eig(neighbor_points[i,])\n",
    "        v_tmp[abs(v_tmp)<1e-5] = 0\n",
    "        if v_tmp[0] < 0:\n",
    "            v_tmp *= -1\n",
    "        v[i,:] = v_tmp\n",
    "    return v\n",
    "\n",
    "\n",
    "def point2plane_metrics_2D(p,q,v):\n",
    "    \"\"\"\n",
    "    Point-to-plane minimization\n",
    "    Chen, Y. and G. Medioni. “Object Modelling by Registration of Multiple Range Images.” \n",
    "    Image Vision Computing. Butterworth-Heinemann . Vol. 10, Issue 3, April 1992, pp. 145-155.\n",
    "    \n",
    "    Args:\n",
    "        p: Nx2 matrix, moving point locations\n",
    "        q: Nx2 matrix, fixed point locations\n",
    "        v:Nx2 matrix, fixed point normal\n",
    "    Returns:\n",
    "        R: 2x2 matrix\n",
    "        t: 2x1 matrix\n",
    "    \"\"\"\n",
    "    assert q.shape[1] == p.shape[1] == v.shape[1] == 2, 'points must be 2D'\n",
    "    \n",
    "    p,q,v = np.array(p),np.array(q),np.array(v)\n",
    "    c = np.expand_dims(np.cross(p,v),-1)\n",
    "    cn = np.concatenate((c,v),axis=1)  # [ci,nix,niy]\n",
    "    C = np.matmul(cn.T,cn)\n",
    "    if np.linalg.cond(C)>=1/sys.float_info.epsilon:\n",
    "        # handle singular matrix\n",
    "        raise ArithmeticError('Singular matrix')\n",
    "    \n",
    "#     print(C.shape)\n",
    "    qp = q-p\n",
    "    b = np.array([\n",
    "        [(qp*cn[:,0:1]*v).sum()],\n",
    "        [(qp*cn[:,1:2]*v).sum()],\n",
    "        [(qp*cn[:,2:]*v).sum()],\n",
    "    ])\n",
    "\n",
    "    X = np.linalg.solve(C, b)\n",
    "    cos_ = np.cos(X[0])[0]\n",
    "    sin_ = np.sin(X[0])[0]\n",
    "    R = np.array([\n",
    "        [cos_,-sin_],\n",
    "        [sin_,cos_]\n",
    "    ])\n",
    "    t = np.array(X[1:])\n",
    "    return R,t\n",
    "\n",
    "def icp(src,dst,nv=None,n_iter=100,init_pose=[0,0,0],torlerance=1e-6,metrics='point',verbose=False):\n",
    "    '''\n",
    "    Currently only works for 2D case\n",
    "    Args:\n",
    "        src: <Nx2> 2-dim moving points\n",
    "        dst: <Nx2> 2-dim fixed points\n",
    "        n_iter: a positive integer to specify the maxium nuber of iterations\n",
    "        init_pose: [tx,ty,theta] initial transformation\n",
    "        torlerance: the tolerance of registration error\n",
    "        metrics: 'point' or 'plane'\n",
    "        \n",
    "    Return:\n",
    "        src: transformed src points\n",
    "        R: rotation matrix\n",
    "        t: translation vector\n",
    "        R*src + t\n",
    "    '''\n",
    "    n_src = src.shape[0]\n",
    "    if metrics == 'plane' and nv is None:\n",
    "        nv = surface_normal(dst)\n",
    "\n",
    "    #src = np.matrix(src)\n",
    "    #dst = np.matrix(dst)\n",
    "    #Initialise with the initial pose estimation\n",
    "    R_init = np.array([[np.cos(init_pose[2]),-np.sin(init_pose[2])],\n",
    "                   [np.sin(init_pose[2]), np.cos(init_pose[2])] \n",
    "                      ])\n",
    "    t_init = np.array([[init_pose[0]],\n",
    "                   [init_pose[1]]\n",
    "                      ])  \n",
    "    \n",
    "    #src =  R_init*src.T + t_init\n",
    "    src = np.matmul(R_init,src.T) + t_init\n",
    "    src = src.T\n",
    "    \n",
    "    R,t = R_init,t_init\n",
    "\n",
    "    prev_err = np.inf\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(dst)\n",
    "    for i in range(n_iter):\n",
    "        # Find the nearest neighbours\n",
    "        _, indices = nbrs.kneighbors(src)\n",
    "\n",
    "        # Compute the transformation\n",
    "        if metrics == 'point':\n",
    "            R0,t0 = rigid_transform_kD(src,dst[indices[:,0]])\n",
    "        elif metrics=='plane':\n",
    "            try:\n",
    "                R0,t0 = point2plane_metrics_2D(src,dst[indices[:,0]], nv[indices[:,0]]) \n",
    "            except ArithmeticError:\n",
    "                print('Singular matrix')\n",
    "                return src,R,t\n",
    "        else:\n",
    "            raise ValueError('metrics: {} not recognized.'.format(metrics))\n",
    "        # Update dst and compute error\n",
    "        src = np.matmul(R0,src.T) + t0\n",
    "        src = src.T\n",
    "\n",
    "        R = np.matmul(R0,R)\n",
    "        t = np.matmul(R0,t) + t0\n",
    "        #R = R0*R\n",
    "        #t = R0*t + t0\n",
    "        current_err = np.sqrt((np.array(src-dst[indices[:,0]])**2).sum()/n_src)\n",
    "\n",
    "        if verbose:\n",
    "            print('iter: {}, error: {}'.format(i,current_err))\n",
    "            \n",
    "        if  np.abs(current_err - prev_err) < torlerance:\n",
    "            break\n",
    "        else:\n",
    "            prev_err = current_err\n",
    "            \n",
    "    return src,R,t\n",
    "\n",
    "\n",
    "def compute_ate(output,target):\n",
    "    \"\"\"\n",
    "    compute absolute trajectory error for avd dataset\n",
    "    Args:\n",
    "        output: <Nx3> predicted trajectory positions, where N is #scans\n",
    "        target: <Nx3> ground truth trajectory positions\n",
    "    Returns:\n",
    "        trans_error: <N> absolute trajectory error for each pose\n",
    "        output_aligned: <Nx3> aligned position in ground truth coord\n",
    "    \"\"\"\n",
    "    R,t = rigid_transform_kD(output,target)\n",
    "    output_aligned = np.matmul(R , output.T) + t\n",
    "    output_aligned = output_aligned.T\n",
    "\n",
    "    align_error = np.array(output_aligned - target)\n",
    "    trans_error = np.sqrt(np.sum(align_error**2,1))\n",
    "    \n",
    "    ate = np.sqrt(np.dot(trans_error,trans_error) / len(trans_error))\n",
    "\n",
    "    return ate,output_aligned\n",
    "\n",
    "def remove_invalid_pcd(pcd):\n",
    "    \"\"\"\n",
    "    remove invalid in valid points that have all-zero coordinates\n",
    "    pcd: open3d pcd objective\n",
    "    \"\"\"\n",
    "    pcd_np = np.asarray(pcd.points) # <Nx3>\n",
    "    non_zero_coord = np.abs(pcd_np) > 1e-6 # <Nx3>\n",
    "    valid_ind = np.sum(non_zero_coord,axis=-1)>0 #<N>\n",
    "    valid_ind = list(np.nonzero(valid_ind)[0])\n",
    "    valid_pcd = open3d.select_down_sample(pcd,valid_ind)\n",
    "    return valid_pcd\n",
    "\n",
    "def ang2mat(theta):\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    R = np.array([[c,-s],[s,c]])\n",
    "    return R\n",
    "\n",
    "def cat_pose_2D(pose0,pose1):\n",
    "    \"\"\"\n",
    "    pose0, pose1: <Nx3>, numpy array\n",
    "    each row: <x,y,theta>\n",
    "    \"\"\"\n",
    "    assert(pose0.shape==pose1.shape)\n",
    "    n_pose = pose0.shape[0]\n",
    "    pose_out = np.zeros_like(pose0) \n",
    "    for i in range(n_pose):\n",
    "        R0 = ang2mat(pose0[i,-1])\n",
    "        R1 = ang2mat(pose1[i,-1])\n",
    "        t0 = np.expand_dims(pose0[i,:2],-1)\n",
    "        t1 = np.expand_dims(pose1[i,:2],-1)\n",
    "        \n",
    "        R = np.matmul(R1,R0)\n",
    "        theta = np.arctan2(R[1,0],R[0,0])\n",
    "        t = np.matmul(R1,t0) + t1\n",
    "        pose_out[i,:2] = t.T\n",
    "        pose_out[i,2] = theta\n",
    "    return pose_out\n",
    "\n",
    "def convert_depth_map_to_pc(depth,fxy,cxy,max_depth=7000,depth_scale=2000):\n",
    "    \"\"\"\n",
    "    create point cloud from depth map and camera instrinsic\n",
    "    depth: <hxw> numpy array\n",
    "    fxy: [fx,fy]\n",
    "    cxy: [cx,cy]\n",
    "    \"\"\"\n",
    "    fx,fy = fxy \n",
    "    cx,cy = cxy\n",
    "    h,w = depth.shape\n",
    "    \n",
    "    c,r = np.meshgrid(range(1,w+1), range(1,h+1))\n",
    "    invalid = depth >= max_depth\n",
    "    depth[invalid] = 0\n",
    "\n",
    "    z = depth / float(depth_scale)\n",
    "    x = z * (c-cx) / fx\n",
    "    y = z * (r-cy) / fy\n",
    "    xyz = np.dstack((x,y,z)).astype(np.float32)\n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open 3d utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     16,
     27
    ]
   },
   "outputs": [],
   "source": [
    "def transform_to_global_open3d(pose,local_pcd):\n",
    "    pcd = copy.deepcopy(local_pcd)\n",
    "    n_pcd = len(pcd)\n",
    "    for i in range(n_pcd):\n",
    "        tx,ty,theta = pose[i,:]\n",
    "        cos,sin = np.cos(theta),np.sin(theta)\n",
    "        trans = np.array([\n",
    "                        [cos,-sin,0,tx],\n",
    "                        [sin,cos,0,ty],\n",
    "                        [0,0,1,0],\n",
    "                        [0,0,0,1],\n",
    "                        ])\n",
    "        pcd[i].transform(trans) \n",
    "    return pcd\n",
    "\n",
    "\n",
    "def np_to_pcd(xyz):\n",
    "    \"\"\"\n",
    "    convert numpy array to point cloud object in open3d\n",
    "    \"\"\"\n",
    "    xyz = xyz.reshape(-1,3)\n",
    "    pcd = o3d.PointCloud()\n",
    "    pcd.points = o3d.Vector3dVector(xyz)\n",
    "    pcd.paint_uniform_color(np.random.rand(3,))\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def load_obs_global_est(file_name):\n",
    "    \"\"\"\n",
    "    load saved obs_global_est.npy file and convert to point cloud object\n",
    "    \"\"\"\n",
    "    obs_global_est = np.load(file_name)\n",
    "    n_pc = obs_global_est.shape[0]\n",
    "    pcds = o3d.PointCloud()\n",
    "\n",
    "    for i in range(n_pc):\n",
    "        xyz = obs_global_est[i,:,:]\n",
    "        current_pcd = np_to_pcd(xyz)\n",
    "        pcds += current_pcd\n",
    "    return pcds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     17,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def save_opt(working_dir, opt):\n",
    "    \"\"\"\n",
    "    Save option as a json file\n",
    "    \"\"\"\n",
    "    opt = vars(opt)\n",
    "    save_name = os.path.join(working_dir, 'opt.json')\n",
    "    with open(save_name, 'wt') as f:\n",
    "        json.dump(opt, f, indent=4, sort_keys=True)\n",
    "\n",
    "\n",
    "def save_checkpoint(save_name, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, save_name)\n",
    "    print('model saved to {}'.format(save_name))\n",
    "\n",
    "\n",
    "def load_checkpoint(save_name, model, optimizer):\n",
    "    state = torch.load(save_name)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from {}'.format(save_name))\n",
    "\n",
    "\n",
    "def load_opt_from_json(file_name):\n",
    "    if os.path.isfile(file_name):\n",
    "        with open(file_name,'rb') as f:\n",
    "            opt_dict = json.load(f)\n",
    "            return opt_dict\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Can't find file: {}. Run training script first\".format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     17,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def save_opt(working_dir, opt):\n",
    "    \"\"\"\n",
    "    Save option as a json file\n",
    "    \"\"\"\n",
    "    opt = vars(opt)\n",
    "    save_name = os.path.join(working_dir, 'opt.json')\n",
    "    with open(save_name, 'wt') as f:\n",
    "        json.dump(opt, f, indent=4, sort_keys=True)\n",
    "\n",
    "\n",
    "def save_checkpoint(save_name, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, save_name)\n",
    "    print('model saved to {}'.format(save_name))\n",
    "\n",
    "\n",
    "def load_checkpoint(save_name, model, optimizer):\n",
    "    state = torch.load(save_name)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from {}'.format(save_name))\n",
    "\n",
    "\n",
    "def load_opt_from_json(file_name):\n",
    "    if os.path.isfile(file_name):\n",
    "        with open(file_name,'rb') as f:\n",
    "            opt_dict = json.load(f)\n",
    "            return opt_dict\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Can't find file: {}. Run training script first\".format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCE / Chamfer Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     42
    ]
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsLoss2(nn.Module):\n",
    "    def __init__(self, weight=None, reduction='elementwise_mean'):\n",
    "        super(BCEWithLogitsLoss2, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.register_buffer('weight', weight)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return bce_with_logits(input, target, weight=self.weight, reduction=self.reduction)\n",
    "\n",
    "\n",
    "def bce_with_logits(input, target, weight=None, reduction='elementwise_mean'):\n",
    "    \"\"\"\n",
    "    This function differs from F.binary_cross_entropy_with_logits in the way \n",
    "    that if weight is not None, the loss is normalized by weight\n",
    "    \"\"\"\n",
    "    if not (target.size() == input.size()):\n",
    "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(\n",
    "            target.size(), input.size()))\n",
    "    if weight is not None:\n",
    "        if not (weight.size() == input.size()):\n",
    "            raise ValueError(\"Weight size ({}) must be the same as input size ({})\".format(\n",
    "                weight.size(), input.size()))\n",
    "\n",
    "    max_val = (-input).clamp(min=0)\n",
    "    loss = input - input * target + max_val + \\\n",
    "        ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "    if weight is not None:\n",
    "        loss = loss * weight\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'elementwise_mean':\n",
    "        if weight is not None:\n",
    "            # different from F.binary_cross_entropy_with_logits\n",
    "            return loss.sum() / weight.sum()\n",
    "        else:\n",
    "            return loss.mean()\n",
    "    else:\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "def bce(pred, targets, weight=None):\n",
    "    criternion = BCEWithLogitsLoss2(weight=weight)\n",
    "    loss = criternion(pred, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     49,
     73
    ]
   },
   "outputs": [],
   "source": [
    "INF = 1000000\n",
    "\n",
    "\n",
    "class ChamfersDistance(nn.Module):\n",
    "    '''\n",
    "    Extensively search to compute the Chamfersdistance. \n",
    "    '''\n",
    "\n",
    "    def forward(self, input1, input2, valid1=None, valid2=None):\n",
    "\n",
    "        # input1, input2: BxNxK, BxMxK, K = 3\n",
    "        B, N, K = input1.shape\n",
    "        _, M, _ = input2.shape\n",
    "        if valid1 is not None:\n",
    "            # ignore invalid points\n",
    "            valid1 = valid1.type(torch.float32)\n",
    "            valid2 = valid2.type(torch.float32)\n",
    "\n",
    "            invalid1 = 1 - valid1.unsqueeze(-1).expand(-1, -1, K)\n",
    "            invalid2 = 1 - valid2.unsqueeze(-1).expand(-1, -1, K)\n",
    "\n",
    "            input1 = input1 + invalid1 * INF * torch.ones_like(input1)\n",
    "            input2 = input2 + invalid2 * INF * torch.ones_like(input2)\n",
    "\n",
    "        # Repeat (x,y,z) M times in a row\n",
    "        input11 = input1.unsqueeze(2)           # BxNx1xK\n",
    "        input11 = input11.expand(B, N, M, K)    # BxNxMxK\n",
    "        # Repeat (x,y,z) N times in a column\n",
    "        input22 = input2.unsqueeze(1)           # Bx1xMxK\n",
    "        input22 = input22.expand(B, N, M, K)    # BxNxMxK\n",
    "        # compute the distance matrix\n",
    "        D = input11 - input22                   # BxNxMxK\n",
    "        D = torch.norm(D, p=2, dim=3)         # BxNxM\n",
    "\n",
    "        dist0, _ = torch.min(D, dim=1)        # BxM\n",
    "        dist1, _ = torch.min(D, dim=2)        # BxN\n",
    "\n",
    "        if valid1 is not None:\n",
    "            dist0 = torch.sum(dist0 * valid2, 1) / torch.sum(valid2, 1)\n",
    "            dist1 = torch.sum(dist1 * valid1, 1) / torch.sum(valid1, 1)\n",
    "        else:\n",
    "            dist0 = torch.mean(dist0, 1)\n",
    "            dist1 = torch.mean(dist1, 1)\n",
    "\n",
    "        loss = dist0 + dist1  # B\n",
    "        loss = torch.mean(loss)                             # 1\n",
    "        return loss\n",
    "\n",
    "\n",
    "def registration_loss(obs, valid_obs=None):\n",
    "    \"\"\"\n",
    "    Registration consistency\n",
    "    obs: <BxLx2> a set of obs frame in the same coordinate system\n",
    "    select of frame as reference (ref_id) and the rest as target\n",
    "    compute chamfer distance between each target frame and reference\n",
    "\n",
    "    valid_obs: <BxL> indics of valid points in obs\n",
    "    \"\"\"\n",
    "    criternion = ChamfersDistance()\n",
    "    bs = obs.shape[0]\n",
    "    ref_id = 0\n",
    "    ref_map = obs[ref_id, :, :].unsqueeze(0).expand(bs - 1, -1, -1)\n",
    "    valid_ref = valid_obs[ref_id, :].unsqueeze(0).expand(bs - 1, -1)\n",
    "\n",
    "    tgt_list = list(range(bs))\n",
    "    tgt_list.pop(ref_id)\n",
    "    tgt_map = obs[tgt_list, :, :]\n",
    "    valid_tgt = valid_obs[tgt_list, :]\n",
    "\n",
    "    loss = criternion(ref_map, tgt_map, valid_ref, valid_tgt)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def chamfer_loss(obs, valid_obs=None, seq=2):\n",
    "    bs = obs.shape[0]\n",
    "    total_step = bs - seq + 1\n",
    "    loss = 0.\n",
    "    for step in range(total_step):\n",
    "        current_obs = obs[step:step + seq]\n",
    "        current_valid_obs = valid_obs[step:step + seq]\n",
    "\n",
    "        current_loss = registration_loss(current_obs, current_valid_obs)\n",
    "        loss = loss + current_loss\n",
    "\n",
    "    loss = loss / total_step\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepmapping / Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from .networks import LocNetReg2D, LocNetRegAVD, MLP\n",
    "# from utils import transform_to_global_2D, transform_to_global_AVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14,
     29,
     74,
     76
    ]
   },
   "outputs": [],
   "source": [
    "def get_M_net_inputs_labels(occupied_points, unoccupited_points):\n",
    "    \"\"\"\n",
    "    get global coord (occupied and unoccupied) and corresponding labels\n",
    "    \"\"\"\n",
    "    n_pos = occupied_points.shape[1]\n",
    "    inputs = torch.cat((occupied_points, unoccupited_points), 1)\n",
    "    bs, N, _ = inputs.shape\n",
    "\n",
    "    gt = torch.zeros([bs, N, 1], device=occupied_points.device)\n",
    "    gt.requires_grad_(False)\n",
    "    gt[:, :n_pos, :] = 1\n",
    "    return inputs, gt\n",
    "\n",
    "\n",
    "def sample_unoccupied_point(local_point_cloud, n_samples):\n",
    "    \"\"\"\n",
    "    sample unoccupied points along rays in local point cloud\n",
    "    sensor located at origin\n",
    "    local_point_cloud: <BxNxk>\n",
    "    n_samples: number of samples on each ray\n",
    "    \"\"\"\n",
    "    bs, L, k = local_point_cloud.shape\n",
    "    unoccupied = torch.zeros(bs, L * n_samples, k,\n",
    "                             device=local_point_cloud.device)\n",
    "    for idx in range(1, n_samples + 1):\n",
    "        fac = torch.rand(1).item()\n",
    "        unoccupied[:, (idx - 1) * L:idx * L, :] = local_point_cloud * fac\n",
    "    return unoccupied\n",
    "\n",
    "class DeepMapping2D(nn.Module):\n",
    "    def __init__(self, loss_fn, n_obs=256, n_samples=19, dim=[2, 64, 512, 512, 256, 128, 1]):\n",
    "        super(DeepMapping2D, self).__init__()\n",
    "        self.n_obs = n_obs\n",
    "        self.n_samples = n_samples\n",
    "        self.loss_fn = loss_fn\n",
    "        self.loc_net = LocNetReg2D(n_points=n_obs, out_dims=3)\n",
    "        self.occup_net = MLP(dim)\n",
    "\n",
    "    def forward(self, obs_local,valid_points):\n",
    "        # obs_local: <BxLx2>\n",
    "        self.obs_local = deepcopy(obs_local)\n",
    "        self.valid_points = valid_points\n",
    "\n",
    "        self.pose_est = self.loc_net(self.obs_local)\n",
    "\n",
    "        self.obs_global_est = transform_to_global_2D(\n",
    "            self.pose_est, self.obs_local)\n",
    "\n",
    "        if self.training:\n",
    "            self.unoccupied_local = sample_unoccupied_point(\n",
    "                self.obs_local, self.n_samples)\n",
    "            self.unoccupied_global = transform_to_global_2D(\n",
    "                self.pose_est, self.unoccupied_local)\n",
    "\n",
    "            inputs, self.gt = get_M_net_inputs_labels(\n",
    "                self.obs_global_est, self.unoccupied_global)\n",
    "            self.occp_prob = self.occup_net(inputs)\n",
    "            loss = self.compute_loss()\n",
    "            return loss\n",
    "\n",
    "    def compute_loss(self):\n",
    "        valid_unoccupied_points = self.valid_points.repeat(1, self.n_samples)\n",
    "        bce_weight = torch.cat(\n",
    "            (self.valid_points, valid_unoccupied_points), 1).float()\n",
    "        # <Bx(n+1)Lx1> same as occp_prob and gt\n",
    "        bce_weight = bce_weight.unsqueeze(-1)\n",
    "\n",
    "        if self.loss_fn.__name__ == 'bce_ch':\n",
    "            loss = self.loss_fn(self.occp_prob, self.gt, self.obs_global_est,\n",
    "                                self.valid_points, bce_weight, seq=4, gamma=0.1)  # BCE_CH\n",
    "        elif self.loss_fn.__name__ == 'bce':\n",
    "            loss = self.loss_fn(self.occp_prob, self.gt, bce_weight)  # BCE\n",
    "        return loss\n",
    "\n",
    "class DeepMapping_AVD(nn.Module):\n",
    "    #def __init__(self, loss_fn, n_samples=35, dim=[3, 256, 256, 256, 256, 256, 256, 1]):\n",
    "    def __init__(self, loss_fn, n_samples=35, dim=[3, 64, 512, 512, 256, 128, 1]):\n",
    "        super(DeepMapping_AVD, self).__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.loss_fn = loss_fn\n",
    "        self.loc_net = LocNetRegAVD(out_dims=3) # <x,z,theta> y=0\n",
    "        self.occup_net = MLP(dim)\n",
    "\n",
    "    def forward(self, obs_local,valid_points):\n",
    "        # obs_local: <BxHxWx3> \n",
    "        # valid_points: <BxHxW>\n",
    "        \n",
    "        self.obs_local = deepcopy(obs_local)\n",
    "        self.valid_points = valid_points\n",
    "        self.pose_est = self.loc_net(self.obs_local)\n",
    "\n",
    "        bs = obs_local.shape[0]\n",
    "        self.obs_local = self.obs_local.view(bs,-1,3)\n",
    "        self.valid_points = self.valid_points.view(bs,-1)\n",
    "        \n",
    "        self.obs_global_est = transform_to_global_AVD(\n",
    "            self.pose_est, self.obs_local)\n",
    "\n",
    "        if self.training:\n",
    "            self.unoccupied_local = sample_unoccupied_point(\n",
    "                self.obs_local, self.n_samples)\n",
    "            self.unoccupied_global = transform_to_global_AVD(\n",
    "                self.pose_est, self.unoccupied_local)\n",
    "\n",
    "            inputs, self.gt = get_M_net_inputs_labels(\n",
    "                self.obs_global_est, self.unoccupied_global)\n",
    "            self.occp_prob = self.occup_net(inputs)\n",
    "            loss = self.compute_loss()\n",
    "            return loss\n",
    "\n",
    "    def compute_loss(self):\n",
    "        valid_unoccupied_points = self.valid_points.repeat(1, self.n_samples)\n",
    "        bce_weight = torch.cat(\n",
    "            (self.valid_points, valid_unoccupied_points), 1).float()\n",
    "        # <Bx(n+1)Lx1> same as occp_prob and gt\n",
    "        bce_weight = bce_weight.unsqueeze(-1)\n",
    "\n",
    "        if self.loss_fn.__name__ == 'bce_ch':\n",
    "            loss = self.loss_fn(self.occp_prob, self.gt, self.obs_global_est,\n",
    "                                self.valid_points, bce_weight, seq=2, gamma=0.9)  # BCE_CH\n",
    "        elif self.loss_fn.__name__ == 'bce':\n",
    "            loss = self.loss_fn(self.occp_prob, self.gt, bce_weight)  # BCE\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8,
     18,
     24,
     33,
     58,
     82,
     98
    ]
   },
   "outputs": [],
   "source": [
    "def get_and_init_FC_layer(din, dout):\n",
    "    li = nn.Linear(din, dout)\n",
    "    nn.init.xavier_uniform_(\n",
    "       li.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "    li.bias.data.fill_(0.)\n",
    "    return li\n",
    "\n",
    "\n",
    "def get_MLP_layers(dims, doLastRelu):\n",
    "    layers = []\n",
    "    for i in range(1, len(dims)):\n",
    "        layers.append(get_and_init_FC_layer(dims[i - 1], dims[i]))\n",
    "        if i == len(dims) - 1 and not doLastRelu:\n",
    "            continue\n",
    "        layers.append(nn.ReLU())\n",
    "    return layers\n",
    "\n",
    "\n",
    "class PointwiseMLP(nn.Sequential):\n",
    "    def __init__(self, dims, doLastRelu=False):\n",
    "        layers = get_MLP_layers(dims, doLastRelu)\n",
    "        super(PointwiseMLP, self).__init__(*layers)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = PointwiseMLP(dims, doLastRelu=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp.forward(x)\n",
    "\n",
    "\n",
    "class ObsFeat2D(nn.Module):\n",
    "    \"\"\"Feature extractor for 1D organized point clouds\"\"\"\n",
    "\n",
    "    def __init__(self, n_points, n_out=1024):\n",
    "        super(ObsFeat2D, self).__init__()\n",
    "        self.n_out = n_out\n",
    "        k = 3\n",
    "        p = int(np.floor(k / 2)) + 2\n",
    "        self.conv1 = nn.Conv1d(2, 64, kernel_size=k, padding=p, dilation=3)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=k, padding=p, dilation=3)\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            128, self.n_out, kernel_size=k, padding=p, dilation=3)\n",
    "        self.mp = nn.MaxPool1d(n_points)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert(x.shape[1] == 2), \"the input size must be <Bx2xL> \"\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp(x)\n",
    "        x = x.view(-1, self.n_out)  # <Bx1024>\n",
    "        return x\n",
    "\n",
    "\n",
    "class ObsFeatAVD(nn.Module):\n",
    "    \"\"\"Feature extractor for 2D organized point clouds\"\"\"\n",
    "    def __init__(self, n_out=1024):\n",
    "        super(ObsFeatAVD, self).__init__()\n",
    "        self.n_out = n_out\n",
    "        k = 3\n",
    "        p = int(np.floor(k / 2)) + 2\n",
    "        self.conv1 = nn.Conv2d(3,64,kernel_size=k,padding=p,dilation=3)\n",
    "        self.conv2 = nn.Conv2d(64,128,kernel_size=k,padding=p,dilation=3)\n",
    "        self.conv3 = nn.Conv2d(128,256,kernel_size=k,padding=p,dilation=3)\n",
    "        self.conv4 = nn.Conv2d(256,self.n_out,kernel_size=k,padding=p,dilation=3)\n",
    "        self.amp = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert(x.shape[1]==3),\"the input size must be <Bx3xHxW> \"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = self.amp(x) \n",
    "        x = x.view(-1,self.n_out) #<Bxn_out>\n",
    "        return x\n",
    "\n",
    "\n",
    "class LocNetReg2D(nn.Module):\n",
    "    def __init__(self, n_points, out_dims):\n",
    "        super(LocNetReg2D, self).__init__()\n",
    "        self.obs_feat_extractor = ObsFeat2D(n_points)\n",
    "        n_in = self.obs_feat_extractor.n_out\n",
    "        self.fc = MLP([n_in, 512, 256, out_dims])\n",
    "\n",
    "    def forward(self, obs):\n",
    "        obs = obs.transpose(1, 2)\n",
    "        obs_feat = self.obs_feat_extractor(obs)\n",
    "        obs = obs.transpose(1, 2)\n",
    "\n",
    "        x = self.fc(obs_feat)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LocNetRegAVD(nn.Module):\n",
    "    def __init__(self, out_dims):\n",
    "        super(LocNetRegAVD, self).__init__()\n",
    "        self.obs_feat_extractor = ObsFeatAVD()\n",
    "        n_in = self.obs_feat_extractor.n_out\n",
    "        self.fc = MLP([n_in, 512, 256, out_dims])\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # obs: <BxHxWx3>\n",
    "        bs = obs.shape[0]\n",
    "        obs = obs.permute(0,3,1,2) # <Bx3xHxW>\n",
    "        obs_feat = self.obs_feat_extractor(obs)\n",
    "        obs = obs.permute(0,2,3,1)\n",
    "\n",
    "        x = self.fc(obs_feat)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "import os\n",
    "import argparse\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import utils\n",
    "import loss\n",
    "# from models import DeepMapping2D\n",
    "# from dataset_loader import SimulatedPointCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     34
    ]
   },
   "outputs": [],
   "source": [
    "print = functools.partial(print,flush=True)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(999)parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',type=str,default='test',help='experiment name')\n",
    "parser.add_argument('-m','--metric',type=str,default='point',choices=['point','plane'] ,help='minimization metric')\n",
    "parser.add_argument('-d','--data_dir',type=str,default='../data/2D/',help='dataset path')\n",
    "parser.add_argument('-r','--radius',type=float,default=0.02)\n",
    "opt = parser.parse_args()\n",
    "print(opt.radius)\n",
    "\n",
    "checkpoint_dir = os.path.join('../results/2D',opt.name)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "utils.save_opt(checkpoint_dir,opt)\n",
    "\n",
    "dataset = SimulatedPointCloud(opt.data_dir)\n",
    "local_pcds = dataset.pcds[:]\n",
    "n_pc = len(local_pcds)\n",
    "\n",
    "#\"\"\"\n",
    "# remove invalid points\n",
    "local_pcds = [utils.remove_invalid_pcd(x) for x in local_pcds]\n",
    "\n",
    "if opt.metric == 'point':\n",
    "    metric = open3d.TransformationEstimationPointToPoint() \n",
    "else:\n",
    "    metric = open3d.TransformationEstimationPointToPlane() \n",
    "    for idx in range(n_pc):\n",
    "        open3d.estimate_normals(local_pcds[idx],search_param = open3d.KDTreeSearchParamHybrid(radius=opt.radius,max_nn=10))\n",
    "\n",
    "\n",
    "pose_est = np.zeros((n_pc,3),dtype=np.float32)\n",
    "print('running icp')\n",
    "for idx in range(n_pc-1):\n",
    "    dst = local_pcds[idx]\n",
    "    src = local_pcds[idx+1]\n",
    "    result_icp = open3d.registration_icp(src,dst,opt.radius,estimation_method=metric)\n",
    "\n",
    "    R0 = result_icp.transformation[:2,:2]\n",
    "    t0 = result_icp.transformation[:2,3:]\n",
    "    if idx == 0: \n",
    "        R_cum = R0\n",
    "        t_cum = t0\n",
    "    else:\n",
    "        R_cum = np.matmul(R_cum , R0)\n",
    "        t_cum = np.matmul(R_cum,t0) + t_cum\n",
    "    \n",
    "    pose_est[idx+1,:2] = t_cum.T\n",
    "    pose_est[idx+1,2] = np.arctan2(R_cum[1,0],R_cum[0,0]) \n",
    "\n",
    "save_name = os.path.join(checkpoint_dir,'pose_est.npy')\n",
    "np.save(save_name,pose_est)\n",
    "\n",
    "# plot point cloud in global frame\n",
    "\n",
    "print('saving results')\n",
    "global_pcds = utils.transform_to_global_open3d(pose_est,local_pcds)\n",
    "utils.save_global_point_cloud_open3d(global_pcds,pose_est,checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     40
    ]
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',type=str,default='test',help='experiment name')\n",
    "parser.add_argument('-e','--n_epochs',type=int,default=1000,help='number of epochs')\n",
    "parser.add_argument('-b','--batch_size',type=int,default=32,help='batch_size')\n",
    "parser.add_argument('-l','--loss',type=str,default='bce_ch',help='loss function')\n",
    "parser.add_argument('-n','--n_samples',type=int,default=19,help='number of sampled unoccupied points along rays')\n",
    "parser.add_argument('--lr',type=float,default=0.001,help='learning rate')\n",
    "parser.add_argument('-d','--data_dir',type=str,default='../data/2D/',help='dataset path')\n",
    "parser.add_argument('-m','--model', type=str, default=None,help='pretrained model name')\n",
    "parser.add_argument('-i','--init', type=str, default=None,help='init pose')\n",
    "parser.add_argument('--log_interval',type=int,default=10,help='logging interval of saving results')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "checkpoint_dir = os.path.join('../results/2D',opt.name)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "utils.save_opt(checkpoint_dir,opt)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('loading dataset')\n",
    "if opt.init is not None:\n",
    "    init_pose_np = np.load(opt.init)\n",
    "    init_pose = torch.from_numpy(init_pose_np)\n",
    "else:\n",
    "    init_pose = None\n",
    "dataset = SimulatedPointCloud(opt.data_dir,init_pose)\n",
    "loader = DataLoader(dataset,batch_size=opt.batch_size,shuffle=False)\n",
    "\n",
    "loss_fn = eval('loss.'+opt.loss)\n",
    "\n",
    "print('creating model')\n",
    "model = DeepMapping2D(loss_fn=loss_fn,n_obs=dataset.n_obs, n_samples=opt.n_samples).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=opt.lr)\n",
    "\n",
    "if opt.model is not None:\n",
    "    utils.load_checkpoint(opt.model,model,optimizer)\n",
    "\n",
    "print('start training')\n",
    "for epoch in range(opt.n_epochs):\n",
    "\n",
    "    training_loss= 0.0\n",
    "    model.train()\n",
    "\n",
    "    for index,(obs_batch,valid_pt) in enumerate(loader):\n",
    "        obs_batch = obs_batch.to(device)\n",
    "        valid_pt = valid_pt.to(device)\n",
    "        loss = model(obs_batch,valid_pt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "    \n",
    "    training_loss_epoch = training_loss/len(loader)\n",
    "\n",
    "    if (epoch+1) % opt.log_interval == 0:\n",
    "        print('[{}/{}], training loss: {:.4f}'.format(\n",
    "            epoch+1,opt.n_epochs,training_loss_epoch))\n",
    "\n",
    "        obs_global_est_np = []\n",
    "        pose_est_np = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for index,(obs_batch,valid_pt) in enumerate(loader):\n",
    "                obs_batch = obs_batch.to(device)\n",
    "                valid_pt = valid_pt.to(device)\n",
    "                model(obs_batch,valid_pt)\n",
    "\n",
    "                obs_global_est_np.append(model.obs_global_est.cpu().detach().numpy())\n",
    "                pose_est_np.append(model.pose_est.cpu().detach().numpy())\n",
    "            \n",
    "            pose_est_np = np.concatenate(pose_est_np)\n",
    "            if init_pose is not None:\n",
    "                pose_est_np = utils.cat_pose_2D(init_pose_np,pose_est_np)\n",
    "\n",
    "            save_name = os.path.join(checkpoint_dir,'model_best.pth')\n",
    "            utils.save_checkpoint(save_name,model,optimizer)\n",
    "\n",
    "            obs_global_est_np = np.concatenate(obs_global_est_np)\n",
    "            kwargs = {'e':epoch+1}\n",
    "            valid_pt_np = dataset.valid_points.cpu().detach().numpy()\n",
    "            utils.plot_global_point_cloud(obs_global_est_np,pose_est_np,valid_pt_np,checkpoint_dir,**kwargs)\n",
    "\n",
    "            #save_name = os.path.join(checkpoint_dir,'obs_global_est.npy')\n",
    "            #np.save(save_name,obs_global_est_np)\n",
    "\n",
    "            save_name = os.path.join(checkpoint_dir,'pose_est.npy')\n",
    "            np.save(save_name,pose_est_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "import os\n",
    "import argparse\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print = functools.partial(print,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-c','--checkpoint_dir',type=str,required=True,help='path to results folder')\n",
    "opt = parser.parse_args()\n",
    "saved_json_file = os.path.join(opt.checkpoint_dir,'opt.json')\n",
    "train_opt = utils.load_opt_from_json(saved_json_file)\n",
    "name = train_opt['name']\n",
    "data_dir = train_opt['data_dir']\n",
    "\n",
    "# load ground truth poses\n",
    "gt_file = os.path.join(data_dir,'gt_pose.mat')\n",
    "gt_pose = sio.loadmat(gt_file)\n",
    "gt_pose = gt_pose['pose']\n",
    "gt_location = gt_pose[:,:2]\n",
    "\n",
    "# load predicted poses\n",
    "pred_file = os.path.join(opt.checkpoint_dir,'pose_est.npy')\n",
    "pred_pose = np.load(pred_file)\n",
    "pred_location = pred_pose[:,:2] * 512 # denormalization, tbd\n",
    "\n",
    "# compute absolute trajectory error (ATE)\n",
    "ate,aligned_location = utils.compute_ate(pred_location,gt_location) \n",
    "print('{}, ate: {}'.format(name,ate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "import os\n",
    "import argparse\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import utils\n",
    "# from dataset_loader import SimulatedPointCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print = functools.partial(print,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     16
    ]
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',type=str,default='test',help='experiment name')\n",
    "parser.add_argument('-m','--metric',type=str,default='point',choices=['point','plane'] ,help='minimization metric')\n",
    "parser.add_argument('-d','--data_dir',type=str,default='../data/2D/',help='dataset path')\n",
    "opt = parser.parse_args()\n",
    "\n",
    "checkpoint_dir = os.path.join('../results/2D',opt.name)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "utils.save_opt(checkpoint_dir,opt)\n",
    "\n",
    "dataset = SimulatedPointCloud(opt.data_dir)\n",
    "n_pc = len(dataset)\n",
    "\n",
    "pose_est = np.zeros((n_pc,3),dtype=np.float32)\n",
    "print('running icp')\n",
    "for idx in range(n_pc-1):\n",
    "    dst,valid_dst = dataset[idx] \n",
    "    src,valid_src = dataset[idx+1]\n",
    "    \n",
    "    dst = dst[valid_dst,:].numpy()\n",
    "    src = src[valid_src,:].numpy()\n",
    "\n",
    "    _,R0,t0 = utils.icp(src,dst,metrics=opt.metric)\n",
    "    if idx == 0: \n",
    "        R_cum = R0\n",
    "        t_cum = t0\n",
    "    else:\n",
    "        R_cum = np.matmul(R_cum , R0)\n",
    "        t_cum = np.matmul(R_cum,t0) + t_cum\n",
    "    \n",
    "    pose_est[idx+1,:2] = t_cum.T\n",
    "    pose_est[idx+1,2] = np.arctan2(R_cum[1,0],R_cum[0,0]) \n",
    "\n",
    "save_name = os.path.join(checkpoint_dir,'pose_est.npy')\n",
    "np.save(save_name,pose_est)\n",
    "\n",
    "print('saving results')\n",
    "pose_est = torch.from_numpy(pose_est)\n",
    "local_pc,valid_id = dataset[:]\n",
    "global_pc = utils.transform_to_global_2D(pose_est,local_pc)\n",
    "utils.plot_global_point_cloud(global_pc,pose_est,valid_id,checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_path\n",
    "import os\n",
    "import argparse\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import open3d\n",
    "\n",
    "# import utils\n",
    "# from dataset_loader import SimulatedPointCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print = functools.partial(print,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     31
    ]
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',type=str,default='test',help='experiment name')\n",
    "parser.add_argument('-m','--metric',type=str,default='point',choices=['point','plane'] ,help='minimization metric')\n",
    "parser.add_argument('-d','--data_dir',type=str,default='../data/2D/',help='dataset path')\n",
    "parser.add_argument('-r','--radius',type=float,default=0.02)\n",
    "opt = parser.parse_args()\n",
    "print(opt.radius)\n",
    "\n",
    "checkpoint_dir = os.path.join('../results/2D',opt.name)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "utils.save_opt(checkpoint_dir,opt)\n",
    "\n",
    "dataset = SimulatedPointCloud(opt.data_dir)\n",
    "local_pcds = dataset.pcds[:]\n",
    "n_pc = len(local_pcds)\n",
    "\n",
    "#\"\"\"\n",
    "# remove invalid points\n",
    "local_pcds = [utils.remove_invalid_pcd(x) for x in local_pcds]\n",
    "\n",
    "if opt.metric == 'point':\n",
    "    metric = open3d.TransformationEstimationPointToPoint() \n",
    "else:\n",
    "    metric = open3d.TransformationEstimationPointToPlane() \n",
    "    for idx in range(n_pc):\n",
    "        open3d.estimate_normals(local_pcds[idx],search_param = open3d.KDTreeSearchParamHybrid(radius=opt.radius,max_nn=10))\n",
    "\n",
    "\n",
    "pose_est = np.zeros((n_pc,3),dtype=np.float32)\n",
    "print('running icp')\n",
    "for idx in range(n_pc-1):\n",
    "    dst = local_pcds[idx]\n",
    "    src = local_pcds[idx+1]\n",
    "    result_icp = open3d.registration_icp(src,dst,opt.radius,estimation_method=metric)\n",
    "\n",
    "    R0 = result_icp.transformation[:2,:2]\n",
    "    t0 = result_icp.transformation[:2,3:]\n",
    "    if idx == 0: \n",
    "        R_cum = R0\n",
    "        t_cum = t0\n",
    "    else:\n",
    "        R_cum = np.matmul(R_cum , R0)\n",
    "        t_cum = np.matmul(R_cum,t0) + t_cum\n",
    "    \n",
    "    pose_est[idx+1,:2] = t_cum.T\n",
    "    pose_est[idx+1,2] = np.arctan2(R_cum[1,0],R_cum[0,0]) \n",
    "\n",
    "save_name = os.path.join(checkpoint_dir,'pose_est.npy')\n",
    "np.save(save_name,pose_est)\n",
    "\n",
    "# plot point cloud in global frame\n",
    "\n",
    "print('saving results')\n",
    "global_pcds = utils.transform_to_global_open3d(pose_est,local_pcds)\n",
    "utils.save_global_point_cloud_open3d(global_pcds,pose_est,checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
