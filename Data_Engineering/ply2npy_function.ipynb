{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T06:42:30.726779Z",
     "start_time": "2020-08-29T06:42:29.489342Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import gc\n",
    "import zipfile\n",
    "from multiprocessing import Pool#, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T06:42:30.818659Z",
     "start_time": "2020-08-29T06:42:30.734220Z"
    },
    "code_folding": [
     1,
     13,
     19,
     64,
     88,
     97,
     125,
     156,
     228,
     243,
     259
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lucas preprocessing functions\n",
    "def get_quadrant(point):\n",
    "    if point[0] >= 0. and point[1] >= 0. :\n",
    "        return 0\n",
    "    elif point[0] <= 0. and point[1] >= 0. : \n",
    "        return 1\n",
    "    elif point[0] <= 0. and point[1] <= 0. : \n",
    "        return 2\n",
    "    elif point[0] >= 0. and point[1] <= 0. : \n",
    "        return 3\n",
    "    else :\n",
    "        raise Exception('invalid input %s', point) \n",
    "\n",
    "def passed_origin(x_t, x_t1):\n",
    "    if get_quadrant(x_t1) == 3 and get_quadrant(x_t) == 0: \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "def fit_quadrant(points, quadrant, desired_amt):\n",
    "\n",
    "\n",
    "    points = np.asarray(points)\n",
    "    slots = []\n",
    "    slot_size = np.pi / (2 * desired_amt)\n",
    "    for i in range(int(desired_amt)) : slots.append([])\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 :\n",
    "        points = points[::-1] \n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    for point in points :\n",
    "        angle = np.arctan(point[1] / (point[0]+0.000001))\n",
    "        index = min(int(angle / slot_size), desired_amt - 1)\n",
    "        slots[int(index)].append(point)\n",
    "\n",
    "    for i in range(len(slots)):\n",
    "        if len(slots[i]) == 0 : \n",
    "            slots[i] = np.array([0., 0., 0., 0.])\n",
    "        else :\n",
    "            full_slot = np.asarray(slots[i])\n",
    "            slots[i] = full_slot.mean(axis=0)\n",
    "\n",
    "    points = np.asarray(slots)\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 : \n",
    "        points = points[::-1]\n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    return points\n",
    "\n",
    "def parse_velo(velo):\n",
    "    # points closer to the origin (0,0,0) are at the end of the point cloud.\n",
    "    # invert the point cloud such that we begin near the origin. \n",
    "\n",
    "    # returns: a H x 4 x ? array, split into quadrants\n",
    "    velo = velo[::-1]\n",
    "    lines = []\n",
    "    current_point = velo[0]\n",
    "    current_quadrant = get_quadrant(current_point)\n",
    "    current_line = [[], [], [], []]\n",
    "    quadrant_switches = 0\n",
    "    for point in velo :\n",
    "        point_quadrant = get_quadrant(point)\n",
    "\n",
    "        if passed_origin(current_point, point):\n",
    "            lines.append(current_line)\n",
    "            current_line = [[], [], [], []]\n",
    "\n",
    "        current_line[point_quadrant].append(point)\n",
    "        current_quadrant = point_quadrant\n",
    "        current_point = point\n",
    "\n",
    "    return lines\n",
    "\n",
    "def setmatch(lines,lenLines):\n",
    "    arr=[[np.array([0,0,0,0]),np.array([0,0,0,0])]]\n",
    "    if len(lines) > lenLines:\n",
    "        return lines[:lenLines]\n",
    "    else:\n",
    "        for i in range(abs(len(lines)-lenLines)):\n",
    "            lines.append(arr)\n",
    "    return lines\n",
    "\n",
    "def process_velo(velo, points_per_layer, stop=False):\n",
    "\n",
    "    lenLines=RANGE_IMAGE_HEIGHT\n",
    "    lines = parse_velo(velo)\n",
    "    inverse = quad_to_pc_inv(lines)\n",
    "#     lines = lines[2:-1]\n",
    "#     print(lines[])\n",
    "#     print((lines[0]))\n",
    "#     raise SystemError\n",
    "    if(len(lines)!=lenLines):\n",
    "        lines=setmatch(lines,lenLines)\n",
    "#     print(len(lines), flush=True)\n",
    "    if len(lines) != RANGE_IMAGE_HEIGHT : raise Exception('invalid nb un of lines')\n",
    "    out_tensor = np.zeros((RANGE_IMAGE_HEIGHT, points_per_layer, 4))\n",
    "    if stop:\n",
    "        import pdb; pdb.set_trace()\n",
    "        x = 1\n",
    "    for j in range(len(lines)):\n",
    "        line = lines[j]\n",
    "        out_line = np.zeros((points_per_layer, 4))\n",
    "        for i in range(len(line)):\n",
    "            if(len(line[i])==0):\n",
    "                line[i]=[np.array([0.0,0.0,0.0,0.0])]\n",
    "            gridded = fit_quadrant(line[i], i, points_per_layer / 4)\n",
    "            out_tensor[j][i*int(points_per_layer/4):(i+1)*int(points_per_layer/4), :] = gridded[::-1]\n",
    "\n",
    "    return out_tensor, inverse\n",
    "\n",
    "def quad_to_pc_inv(lines, th=3.):\n",
    "    # lines is a 63 x 4 array, where each slot has an array of 4d/3d points\n",
    "    # goal : get an array of points that fills empty spaces\n",
    "    points = []\n",
    "    for i in range(len(lines)) :\n",
    "        line = lines[i] \n",
    "        distance = []\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                distance.append(x**2 + y**2)\n",
    "        distance = np.array(distance)\n",
    "        std = distance.std()\n",
    "        sorted_indices = np.argsort(distance)\n",
    "        median_index = sorted_indices[int(sorted_indices.shape[0]*0.95)]\n",
    "        median = distance[median_index]\n",
    "\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                dist = x ** 2 + y ** 2 \n",
    "                if dist < median and (median/dist-1.) > th:#*std : \n",
    "                    # blocked point --> scale to get real pt\n",
    "                    scale = np.sqrt(median / dist)\n",
    "                    scaled = scale * point\n",
    "                    points.append(scaled)\n",
    "\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "# Our cpu-parallel functions\n",
    "def parallel_pcd2begin_npy(pcd_fname):\n",
    "    pcd_file_path = os.path.join(PCD_PATH, pcd_fname)\n",
    "    pcd = o3d.io.read_point_cloud(pcd_file_path)\n",
    "    pcd_arr = np.asarray(pcd.points)\n",
    "    clr_arr = np.asarray(pcd.colors)[:,0].reshape(-1,1)\n",
    "    if IS_DYNAMIC:\n",
    "        pcd_arr = np.append(pcd_arr, clr_arr, axis=1)\n",
    "    else:\n",
    "        pcd_arr = np.append(pcd_arr, np.zeros((pcd_arr.shape[0],1)), axis=1)\n",
    "\n",
    "    npy_fname = pcd_fname[:-4] + \".npy\"\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_fname)\n",
    "    pcd_arr.dump(open(npy_file_path, 'wb'))\n",
    "\n",
    "def parallel_npy2processed(npy_file):\n",
    "    gc.collect()\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_file)\n",
    "    raw_lidar = np.load(npy_file_path, allow_pickle=True)\n",
    "    processed_lidar, _ = process_velo(raw_lidar, RANGE_IMAGE_WIDTH)\n",
    "    return processed_lidar\n",
    "\n",
    "# Code execution begins here\n",
    "def ply2npy(pcd_folder_path, is_dyn):\n",
    "    global PCD_PATH, IS_DYNAMIC, INITIAL_NPY_PATH, RANGE_IMAGE_HEIGHT, RANGE_IMAGE_WIDTH, EXTRACTED_ARRAY_FNAME    \n",
    "    RANGE_IMAGE_HEIGHT = 64\n",
    "    RANGE_IMAGE_WIDTH = 1024\n",
    "    EXTRACTED_ARRAY_FNAME = \"arr_0.npy\"\n",
    "    PCD_PATH = pcd_folder_path\n",
    "    IS_DYNAMIC = is_dyn\n",
    "    \n",
    "    # 0. Set the folder and intermediate folder paths here\n",
    "    PCD_PARENT_PATH, PCD_FOLDER = os.path.split(PCD_PATH)\n",
    "    \n",
    "    if not os.path.exists(PCD_PATH):\n",
    "        print(\"Did not find : {}\".format(PCD_PATH))\n",
    "        assert False\n",
    "    else:\n",
    "        print(\"Found folder : {}\".format(PCD_PATH))\n",
    "    \n",
    "    print(\"0. Setting paths\")\n",
    "    INITIAL_NPY_FOLDER = PCD_FOLDER + \"_begin_npy\"\n",
    "    INITIAL_NPY_PATH = os.path.join(PCD_PARENT_PATH, INITIAL_NPY_FOLDER)\n",
    "    if not os.path.exists(INITIAL_NPY_PATH):\n",
    "        os.makedirs(INITIAL_NPY_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(INITIAL_NPY_PATH)\n",
    "        os.makedirs(INITIAL_NPY_PATH)\n",
    "\n",
    "    NPZ_FOLDER = PCD_FOLDER + \"_npz\"\n",
    "    NPZ_PATH = os.path.join(PCD_PARENT_PATH, NPZ_FOLDER)\n",
    "    if not os.path.exists(NPZ_PATH):\n",
    "        os.makedirs(NPZ_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(NPZ_PATH)\n",
    "        os.makedirs(NPZ_PATH)\n",
    "\n",
    "    OUT_NPY_FOLDER = PCD_FOLDER + \"_out_npy\"\n",
    "    OUT_NPY_PATH = os.path.join(PCD_PARENT_PATH, OUT_NPY_FOLDER)\n",
    "    if not os.path.exists(OUT_NPY_PATH):\n",
    "        os.makedirs(OUT_NPY_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(OUT_NPY_PATH)\n",
    "        os.makedirs(OUT_NPY_PATH)\n",
    "        \n",
    "    def getint(name):\n",
    "        return int(name.split('.')[0])\n",
    "\n",
    "    # 1. Load ply as npy\n",
    "    print(\"1. Load ply to npy\")\n",
    "    parallel_npy_args = sorted(os.listdir(PCD_PATH), key=getint)\n",
    "#     process_npy_pool = Pool(cpu_count()-1)\n",
    "    process_npy_pool = Pool(16)\n",
    "    __ = [each for each in tqdm(process_npy_pool.imap(parallel_pcd2begin_npy,\n",
    "                                                           parallel_npy_args),\n",
    "                                         total = len(parallel_npy_args))]\n",
    "    process_npy_pool.terminate()\n",
    "    gc.collect()\n",
    "\n",
    "    # 2. Convert npy to range image npz\n",
    "    print(\"2. Convert npy to range image npz\")\n",
    "    npy_folder_size = len(os.listdir(INITIAL_NPY_PATH))\n",
    "    file_list = sorted(os.listdir(INITIAL_NPY_PATH), key=getint)\n",
    "    full_npy_file_list = [np.array(file_list)]\n",
    "\n",
    "    print(\"No of npzs (should be 1): {}\".format(len(full_npy_file_list)))\n",
    "\n",
    "    npz_file_idx = 0\n",
    "    for some_npy_file_list in full_npy_file_list:\n",
    "#         print(len(some_npy_file_list))\n",
    "        parallel_processed_args = some_npy_file_list\n",
    "#         process_processed_pool = Pool(cpu_count()-1)\n",
    "        process_processed_pool = Pool(16)\n",
    "        one_run_npy_file = [each for each in tqdm(process_processed_pool.imap(parallel_npy2processed,\n",
    "                                                               parallel_processed_args), total=len(parallel_processed_args))]\n",
    "        process_processed_pool.terminate()\n",
    "        gc.collect()\n",
    "\n",
    "        npz_file_path = os.path.join(NPZ_PATH, str(npz_file_idx))\n",
    "        np.savez(npz_file_path, one_run_npy_file)\n",
    "        npz_file_idx += 1\n",
    "\n",
    "    # 3. Convert npz to loadable npy\n",
    "    print(\"3. Convert npz to loadable npy\")\n",
    "    for npz_fname in tqdm(sorted(os.listdir(NPZ_PATH), key=getint)):\n",
    "        npz_path = os.path.join(NPZ_PATH, npz_fname)\n",
    "        with zipfile.ZipFile(npz_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(OUT_NPY_PATH)\n",
    "\n",
    "        out_npy_fname = npz_fname[:-4] + \".npy\"\n",
    "        src_fname = os.path.join(OUT_NPY_PATH, EXTRACTED_ARRAY_FNAME)\n",
    "        dst_fname = os.path.join(OUT_NPY_PATH, out_npy_fname)\n",
    "        os.rename(src_fname, dst_fname)\n",
    "        \n",
    "    shutil.rmtree(INITIAL_NPY_PATH)\n",
    "    shutil.rmtree(NPZ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T06:52:49.142031Z",
     "start_time": "2020-08-29T06:42:30.820824Z"
    }
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "pcd_path = ''\n",
    "is_dynamic = False\n",
    "ply2npy(pcd_path, is_dynamic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
