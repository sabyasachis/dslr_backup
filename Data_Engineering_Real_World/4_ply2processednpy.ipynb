{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:46:38.170002Z",
     "start_time": "2020-02-26T19:46:33.697610Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import gc\n",
    "import zipfile\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import copy\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:46:38.176758Z",
     "start_time": "2020-02-26T19:46:38.172386Z"
    }
   },
   "outputs": [],
   "source": [
    "# pcd_folder='/home/sabyasachi/Projects/ati/data/data/datasets/Carla/lidarParam1/pair_corrupt/dynamic/'\n",
    "# npy_folder='/home/sabyasachi/Projects/ati/data/data/datasets/Carla/lidarParam1/pair_corrupt/dynamic_NPY/'\n",
    "\n",
    "BASE_PATH = '/home/saby/Projects/ati/data/data/datasets/Real_World'\n",
    "PAIR_FOLDER = \"pair_transform\"\n",
    "# Do for both\n",
    "# PCD_FOLDER = \"static\"\n",
    "PCD_FOLDER = \"dynamic\"\n",
    "EXTRACTED_ARRAY_FNAME = \"arr_0.npy\"\n",
    "\n",
    "BATCH_SIZE = 14000\n",
    "# BATCH_SIZE = 2048\n",
    "RANGE_IMAGE_HEIGHT = 16\n",
    "RANGE_IMAGE_WIDTH = 1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:46:38.189343Z",
     "start_time": "2020-02-26T19:46:38.180035Z"
    }
   },
   "outputs": [],
   "source": [
    "PCD_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, PCD_FOLDER)\n",
    "if not os.path.exists(PCD_PATH):\n",
    "    print(\"Did not find : {}\".format(PCD_PATH))\n",
    "\n",
    "INITIAL_NPY_FOLDER = PCD_FOLDER + \"_begin_npy\"\n",
    "INITIAL_NPY_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, INITIAL_NPY_FOLDER)\n",
    "if not os.path.exists(INITIAL_NPY_PATH):\n",
    "    os.makedirs(INITIAL_NPY_PATH)\n",
    "else:\n",
    "    shutil.rmtree(INITIAL_NPY_PATH)\n",
    "    os.makedirs(INITIAL_NPY_PATH)\n",
    "\n",
    "NPZ_FOLDER = PCD_FOLDER + \"_npz\"\n",
    "NPZ_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, NPZ_FOLDER)\n",
    "if not os.path.exists(NPZ_PATH):\n",
    "    os.makedirs(NPZ_PATH)\n",
    "else:\n",
    "    shutil.rmtree(NPZ_PATH)\n",
    "    os.makedirs(NPZ_PATH)\n",
    "\n",
    "OUT_NPY_FOLDER = PCD_FOLDER + \"_out_npy\"\n",
    "OUT_NPY_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, OUT_NPY_FOLDER)\n",
    "if not os.path.exists(OUT_NPY_PATH):\n",
    "    os.makedirs(OUT_NPY_PATH)\n",
    "else:\n",
    "    shutil.rmtree(OUT_NPY_PATH)\n",
    "    os.makedirs(OUT_NPY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing functions from the paper source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:46:38.229067Z",
     "start_time": "2020-02-26T19:46:38.192980Z"
    },
    "code_folding": [
     0,
     13,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def get_quadrant(point):\n",
    "    if point[0] >= 0. and point[1] >= 0. :\n",
    "        return 0\n",
    "    elif point[0] <= 0. and point[1] >= 0. : \n",
    "        return 1\n",
    "    elif point[0] <= 0. and point[1] <= 0. : \n",
    "        return 2\n",
    "    elif point[0] >= 0. and point[1] <= 0. : \n",
    "        return 3\n",
    "    else :\n",
    "        raise Exception('invalid input %s', point) \n",
    "\n",
    "\n",
    "def passed_origin(x_t, x_t1):\n",
    "    if get_quadrant(x_t1) == 3 and get_quadrant(x_t) == 0: \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "\n",
    "def fit_quadrant(points, quadrant, desired_amt):\n",
    "    \n",
    "    \n",
    "    points = np.asarray(points)\n",
    "    slots = []\n",
    "    slot_size = np.pi / (2 * desired_amt)\n",
    "    for i in range(int(desired_amt)) : slots.append([])\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 :\n",
    "        points = points[::-1] \n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    for point in points :\n",
    "        angle = np.arctan(point[1] / (point[0]+0.000001))\n",
    "        index = min(int(angle / slot_size), desired_amt - 1)\n",
    "        slots[int(index)].append(point)\n",
    "\n",
    "    for i in range(len(slots)):\n",
    "        if len(slots[i]) == 0 : \n",
    "            slots[i] = np.array([0., 0., 0., 0.])\n",
    "        else :\n",
    "            full_slot = np.asarray(slots[i])\n",
    "            slots[i] = full_slot.mean(axis=0)\n",
    "\n",
    "    points = np.asarray(slots)\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 : \n",
    "        points = points[::-1]\n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    return points\n",
    "\n",
    "def parse_velo(velo):\n",
    "    # points closer to the origin (0,0,0) are at the end of the point cloud.\n",
    "    # invert the point cloud such that we begin near the origin. \n",
    "    \n",
    "    # returns: a H x 4 x ? array, split into quadrants\n",
    "    velo = velo[::-1]\n",
    "    lines = []\n",
    "    current_point = velo[0]\n",
    "    current_quadrant = get_quadrant(current_point)\n",
    "    current_line = [[], [], [], []]\n",
    "    quadrant_switches = 0\n",
    "    for point in velo :\n",
    "        point_quadrant = get_quadrant(point)\n",
    "        \n",
    "        if passed_origin(current_point, point):\n",
    "            lines.append(current_line)\n",
    "            current_line = [[], [], [], []]\n",
    "\n",
    "        current_line[point_quadrant].append(point)\n",
    "        current_quadrant = point_quadrant\n",
    "        current_point = point\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def setmatch(lines,lenLines):\n",
    "    arr=[[np.array([0,0,0,0]),np.array([0,0,0,0])]]\n",
    "    if len(lines) > lenLines:\n",
    "        return lines[:lenLines]\n",
    "    else:\n",
    "        for i in range(abs(len(lines)-lenLines)):\n",
    "            lines.append(arr)\n",
    "    return lines\n",
    "\n",
    "def process_velo(velo, points_per_layer, stop=False):\n",
    "    \n",
    "    lenLines=RANGE_IMAGE_HEIGHT\n",
    "    lines = parse_velo(velo)\n",
    "    inverse = quad_to_pc_inv(lines)\n",
    "#     lines = lines[2:-1]\n",
    "#     print(lines[])\n",
    "#     print((lines[0]))\n",
    "#     raise SystemError\n",
    "    if(len(lines)!=lenLines):\n",
    "        lines=setmatch(lines,lenLines)\n",
    "#     print(len(lines), flush=True)\n",
    "    if len(lines) != RANGE_IMAGE_HEIGHT : raise Exception('invalid nb un of lines')\n",
    "    out_tensor = np.zeros((RANGE_IMAGE_HEIGHT, points_per_layer, 4))\n",
    "    if stop:\n",
    "        import pdb; pdb.set_trace()\n",
    "        x = 1\n",
    "    for j in range(len(lines)):\n",
    "        line = lines[j]\n",
    "        out_line = np.zeros((points_per_layer, 4))\n",
    "        for i in range(len(line)):\n",
    "            if(len(line[i])==0):\n",
    "                line[i]=[np.array([0.0,0.0,0.0,0.0])]\n",
    "            gridded = fit_quadrant(line[i], i, points_per_layer / 4)\n",
    "            out_tensor[j][i*int(points_per_layer/4):(i+1)*int(points_per_layer/4), :] = gridded[::-1]\n",
    "\n",
    "    return out_tensor, inverse\n",
    "\n",
    "\n",
    "def quad_to_pc_inv(lines, th=3.):\n",
    "    # lines is a 63 x 4 array, where each slot has an array of 4d/3d points\n",
    "    # goal : get an array of points that fills empty spaces\n",
    "    points = []\n",
    "    for i in range(len(lines)) :\n",
    "        line = lines[i] \n",
    "        distance = []\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                distance.append(x**2 + y**2)\n",
    "        distance = np.array(distance)\n",
    "        std = distance.std()\n",
    "        sorted_indices = np.argsort(distance)\n",
    "        median_index = sorted_indices[int(sorted_indices.shape[0]*0.95)]\n",
    "        median = distance[median_index]\n",
    "\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                dist = x ** 2 + y ** 2 \n",
    "                if dist < median and (median/dist-1.) > th:#*std : \n",
    "                    # blocked point --> scale to get real pt\n",
    "                    scale = np.sqrt(median / dist)\n",
    "                    scaled = scale * point\n",
    "                    points.append(scaled)\n",
    "\n",
    "\n",
    "    return np.array(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:46:38.234569Z",
     "start_time": "2020-02-26T19:46:38.231008Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCD to NPY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:46:38.241424Z",
     "start_time": "2020-02-26T19:46:38.236588Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_pcd2begin_npy(pcd_fname):\n",
    "    pcd_file_path = os.path.join(PCD_PATH, pcd_fname)\n",
    "    pcd = o3d.io.read_point_cloud(pcd_file_path)\n",
    "    pcd_arr = np.asarray(pcd.points)\n",
    "    pcd_arr = np.append(pcd_arr, np.zeros((pcd_arr.shape[0],1)), axis=1)\n",
    "    \n",
    "    npy_fname = pcd_fname[:-4] + \".npy\"\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_fname)\n",
    "    pcd_arr.dump(open(npy_file_path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:54:05.499447Z",
     "start_time": "2020-02-26T19:46:38.243621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saby/anaconda3/envs/ati/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e1247a4fea44aaaf72a6e879c82a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_npy_args = sorted(os.listdir(PCD_PATH), key=getint)\n",
    "process_npy_pool = Pool(cpu_count()-1)\n",
    "__ = [each for each in tqdm_notebook(process_npy_pool.imap(parallel_pcd2begin_npy,\n",
    "                                                       parallel_npy_args),\n",
    "                                     total = len(parallel_npy_args))]\n",
    "process_npy_pool.terminate()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPY to NPZ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:54:05.518508Z",
     "start_time": "2020-02-26T19:54:05.503311Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_pcd2begin_npy(pcd_fname):\n",
    "    pcd_file_path = os.path.join(PCD_PATH, pcd_fname)\n",
    "    pcd = o3d.io.read_point_cloud(pcd_file_path)\n",
    "    pcd_arr = np.asarray(pcd.points)\n",
    "#     clr_arr = np.asarray(pcd.colors)[:,0].reshape(-1,1)\n",
    "#     pcd_arr = np.append(pcd_arr, clr_arr, axis=1)\n",
    "    pcd_arr = np.append(pcd_arr, np.zeros((pcd_arr.shape[0],1)), axis=1)\n",
    "    \n",
    "    npy_fname = pcd_fname[:-4] + \".npy\"\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_fname)\n",
    "    pcd_arr.dump(open(npy_file_path, 'wb'))\n",
    "\n",
    "def appendSpherical_np(xyz):\n",
    "#     ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    r_arr = np.sqrt(xy + xyz[:,2]**2)\n",
    "    phi_arr = np.rad2deg(np.arctan2(np.sqrt(xy), xyz[:,2])) -90 # for elevation angle defined from Z-axis down\n",
    "    theta_arr = np.rad2deg(np.arctan2(xyz[:,1], xyz[:,0]))\n",
    "    return r_arr, theta_arr, phi_arr\n",
    "\n",
    "def correct_point_ordering(ati_lidar, TRANSFORM_LIKE_CARLA=True):\n",
    "    # Put everything in dataframe\n",
    "    df_ati_lidar = pd.DataFrame(ati_lidar).rename(columns={0:'x', 1:'y', 2:'z', 3:'i'})\n",
    "    r_arr, theta_arr, phi_arr = appendSpherical_np(ati_lidar[:,:3])\n",
    "    df_ati_lidar['r'] = r_arr\n",
    "    df_ati_lidar['theta'] = theta_arr\n",
    "    df_ati_lidar['phi'] = phi_arr\n",
    "    \n",
    "    # Get correct phi (vertical angles)\n",
    "    phi_arr = phi_arr.reshape(-1,1)    \n",
    "    d_list, idx_list = nn_phi.kneighbors(np.concatenate((phi_arr, np.zeros(phi_arr.shape)), axis=1))\n",
    "    df_ati_lidar['new_phi'] = laser_angles_[idx_list][:,0]\n",
    "    # df_ati_lidar['neg_new_phi'] = -laser_angles_[idx_list][:,0]\n",
    "    \n",
    "    # Sort as per carla order\n",
    "    df_ati_lidar_sort = df_ati_lidar.sort_values(by=['new_phi', 'theta'], ascending=True)\n",
    "    ati_lidar_sort = df_ati_lidar_sort.values[:,:3]\n",
    "    \n",
    "    if TRANSFORM_LIKE_CARLA:\n",
    "        x_carla = copy.deepcopy(ati_lidar_sort[:,1])\n",
    "        y_carla = -copy.deepcopy(ati_lidar_sort[:,0])\n",
    "        z_carla = -copy.deepcopy(ati_lidar_sort[:,2])\n",
    "        ati_lidar_sort[:,0] = x_carla\n",
    "        ati_lidar_sort[:,1] = y_carla\n",
    "        ati_lidar_sort[:,2] = z_carla\n",
    "    ati_lidar_sort = np.concatenate((ati_lidar_sort, ati_lidar[:,3].reshape((-1,1))), axis=1)\n",
    "    return ati_lidar_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:54:13.468014Z",
     "start_time": "2020-02-26T19:54:05.520331Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_npy2processed(npy_file):\n",
    "    gc.collect()\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_file)\n",
    "    raw_lidar = np.load(npy_file_path, allow_pickle=True)\n",
    "    ati_lidar_sort = correct_point_ordering(raw_lidar)\n",
    "#     processed_lidar, _ = process_velo(raw_lidar, RANGE_IMAGE_WIDTH)\n",
    "    processed_lidar, _ = process_velo(ati_lidar_sort, RANGE_IMAGE_WIDTH)\n",
    "    return processed_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:54:17.155218Z",
     "start_time": "2020-02-26T19:54:13.471183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_phi = NearestNeighbors(n_neighbors=1)\n",
    "# laser_angles = [-15, 1, -13, 3, -11, 5, -9, 7, -7, 9, -5, 11, -3, 13, -1, 15] # in degrees\n",
    "laser_angles = [-15, -13, -11, -9, -7, -5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15] # in degrees\n",
    "laser_angles_ = np.array(laser_angles)\n",
    "laser_angles_arr = np.array([np.array([angle,0]) for angle in laser_angles])\n",
    "nn_phi.fit(laser_angles_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T19:54:20.276541Z",
     "start_time": "2020-02-26T19:54:17.158086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "npy_folder_size = len(os.listdir(INITIAL_NPY_PATH))\n",
    "leftout_size = npy_folder_size % BATCH_SIZE\n",
    "n_batches = int(npy_folder_size / BATCH_SIZE)\n",
    "file_list = sorted(os.listdir(INITIAL_NPY_PATH), key=getint)\n",
    "full_npy_file_list = np.split(np.array(file_list)[:-leftout_size], n_batches)\n",
    "# To consider last small batch\n",
    "full_npy_file_list += [np.array(file_list[-leftout_size:])]\n",
    "\n",
    "print(len(full_npy_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T20:10:47.981945Z",
     "start_time": "2020-02-26T19:54:20.278671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saby/anaconda3/envs/ati/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e2d263356f4aa18db79d78da927e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29972e1abe64a97b4b830c6a4c9e2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "npz_file_idx = 0\n",
    "for some_npy_file_list in full_npy_file_list:\n",
    "    print(len(some_npy_file_list))\n",
    "    parallel_processed_args = some_npy_file_list\n",
    "    process_processed_pool = Pool(cpu_count()-1)\n",
    "    one_run_npy_file = [each for each in tqdm_notebook(process_processed_pool.imap(parallel_npy2processed,\n",
    "                                                           parallel_processed_args), total=len(parallel_processed_args))]\n",
    "    process_processed_pool.terminate()\n",
    "    gc.collect()\n",
    "    \n",
    "    npz_file_path = os.path.join(NPZ_PATH, str(npz_file_idx))\n",
    "    np.savez(npz_file_path, one_run_npy_file)\n",
    "    npz_file_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPZ extracted serially to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T20:11:32.171742Z",
     "start_time": "2020-02-26T20:10:47.983793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saby/anaconda3/envs/ati/lib/python3.6/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d99bedb00d468a80712583c6d8d01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for npz_fname in tqdm_notebook(sorted(os.listdir(NPZ_PATH), key=getint)):\n",
    "    npz_path = os.path.join(NPZ_PATH, npz_fname)\n",
    "    with zipfile.ZipFile(npz_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(OUT_NPY_PATH)\n",
    "    \n",
    "    out_npy_fname = npz_fname[:-4] + \".npy\"\n",
    "    src_fname = os.path.join(OUT_NPY_PATH, EXTRACTED_ARRAY_FNAME)\n",
    "    dst_fname = os.path.join(OUT_NPY_PATH, out_npy_fname)\n",
    "    os.rename(src_fname, dst_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T20:11:36.233255Z",
     "start_time": "2020-02-26T20:11:32.173263Z"
    }
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree(PCD_PATH)\n",
    "shutil.rmtree(INITIAL_NPY_PATH)\n",
    "shutil.rmtree(NPZ_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
