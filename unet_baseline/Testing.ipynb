{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:47.648417Z",
     "start_time": "2020-02-17T17:46:46.589707Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import * \n",
    "from utils import *\n",
    "import open3d as o3d\n",
    "from models import *\n",
    "from collections import OrderedDict\n",
    "import os, shutil, gc\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:47.656144Z",
     "start_time": "2020-02-17T17:46:47.650140Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:47.668054Z",
     "start_time": "2020-02-17T17:46:47.657777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--debug'], dest='debug', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='VAE training of LiDAR')\n",
    "parser.add_argument('--batch_size',         type=int,   default=16,             help='size of minibatch used during training')\n",
    "parser.add_argument('--use_selu',           type=int,   default=0,              help='replaces batch_norm + act with SELU')\n",
    "parser.add_argument('--base_dir',           type=str,   default='runs/test',    help='root of experiment directory')\n",
    "parser.add_argument('--no_polar',           type=int,   default=0,              help='if True, the representation used is (X,Y,Z), instead of (D, Z), where D=sqrt(X^2+Y^2)')\n",
    "parser.add_argument('--lr',                 type=float, default=1e-3,           help='learning rate value')\n",
    "parser.add_argument('--z_dim',              type=int,   default=1024,            help='size of the bottleneck dimension in the VAE, or the latent noise size in GAN')\n",
    "parser.add_argument('--autoencoder',        type=int,   default=1,              help='if True, we do not enforce the KL regularization cost in the VAE')\n",
    "parser.add_argument('--atlas_baseline',     type=int,   default=0,              help='If true, Atlas model used. Also determines the number of primitives used in the model')\n",
    "parser.add_argument('--panos_baseline',     type=int,   default=0,              help='If True, Model by Panos Achlioptas used')\n",
    "parser.add_argument('--kl_warmup_epochs',   type=int,   default=150,            help='number of epochs before fully enforcing the KL loss')\n",
    "parser.add_argument('--debug', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:47.673781Z",
     "start_time": "2020-02-17T17:46:47.670194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(atlas_baseline=0, autoencoder=1, base_dir='runs/test', batch_size=16, debug=False, kl_warmup_epochs=150, lr=0.001, no_polar=0, panos_baseline=0, use_selu=0, z_dim=1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:47.677657Z",
     "start_time": "2020-02-17T17:46:47.675377Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = \"/home/saby/Projects/ati/ati_motors/adversarial_based/static_reconstruction_method/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.577244Z",
     "start_time": "2020-02-17T17:46:47.679277Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL_FOLDER_NAME = \"second_attempt_triple_data_restarted_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_150.pth\"\n",
    "# model = VAE(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = False\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_filtered_32f_triple_data_restarted_again2_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_245.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_filtered_64f_triple_data_restarted_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_105.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_ground_weighted_filtered_64f_triple_data_continued_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_260.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fourth_attempt_ground_weighted_filtered_polar_new_unet_64f_2048\"\n",
    "# MODEL_FILE_NAME = \"gen_300.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_no_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_498.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_sem_ground_weighted_filtered_polar_old_unet_32f_1024_continued\"\n",
    "# MODEL_FILE_NAME = \"gen_145.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_slam_weighted_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_115.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_inpainting_weighted_no_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_280.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "###################################\n",
    "MODEL_FOLDER_NAME = \"first_new_attempt_new_unet_64f\"\n",
    "MODEL_FILE_NAME = \"gen_125.pth\"\n",
    "model = Unet_filtered(args, n_filters=64).cuda()\n",
    "LEARN_TO_FILTER = True\n",
    "MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"first_new_attempt_new_unet_64f_no_dropout\"\n",
    "# MODEL_FILE_NAME = \"gen_84.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"\"\n",
    "# MODEL_FILE_NAME = \"gen_.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.582329Z",
     "start_time": "2020-02-17T17:46:49.578961Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TEST_PATH = os.path.join(MODEL_BASE_PATH, MODEL_FOLDER_NAME, 'models', MODEL_FILE_NAME)\n",
    "if not os.path.exists(MODEL_TEST_PATH):\n",
    "    print(\"No Model file found at : {}\".format(MODEL_TEST_PATH))\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.864857Z",
     "start_time": "2020-02-17T17:46:49.584574Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/saby/Projects/ati/ati_motors/adversarial_based/static_reconstruction_method/first_new_attempt_new_unet_64f/models/gen_125.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unet_filtered(\n",
       "  (unet): Unet(\n",
       "    (encoder_conv1): Doubleconv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Dropout(p=0.4, inplace=False)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (7): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (encoder_down1): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Dropout(p=0.4, inplace=False)\n",
       "            (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (7): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down2): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Dropout(p=0.4, inplace=False)\n",
       "            (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (7): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down3): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Dropout(p=0.4, inplace=False)\n",
       "            (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (7): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down4): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Dropout(p=0.4, inplace=False)\n",
       "            (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (7): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down5): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (encoder_conv2): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Dropout(p=0.4, inplace=False)\n",
       "      (4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (7): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (decoder_up1): Sequential(\n",
       "      (0): ConvTranspose2d(2048, 1024, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (decoder_conv3): Doubleconv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Dropout(p=0.4, inplace=False)\n",
       "        (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (7): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decoder_up2): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(1024, 512, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.4, inplace=False)\n",
       "          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (7): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_up3): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(512, 256, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.4, inplace=False)\n",
       "          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (7): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_up4): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(256, 128, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.4, inplace=False)\n",
       "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (7): Dropout(p=0.4, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_up5): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(128, 64, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Out(\n",
       "      (out): Sequential(\n",
       "        (0): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(68, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "print(\"Loading model from {}\".format(MODEL_TEST_PATH))\n",
    "network=torch.load(MODEL_TEST_PATH)\n",
    "\n",
    "if MODEL_USED_DATA_PARALLEL:\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = network\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    model.load_state_dict(network)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T07:49:43.545790Z",
     "start_time": "2020-02-13T07:49:43.541412Z"
    }
   },
   "source": [
    "### Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.868896Z",
     "start_time": "2020-02-17T17:46:49.866478Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = \"/home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing\"\n",
    "DATA_TEST_FOLDER_LIST = [\"8\", \"24\", \"48\"]\n",
    "SAVE_PCD_NPY = True\n",
    "TEST_NPY_FOLDER = \"_out_out_npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.872307Z",
     "start_time": "2020-02-17T17:46:49.870139Z"
    }
   },
   "outputs": [],
   "source": [
    "LIDAR_RANGE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.882723Z",
     "start_time": "2020-02-17T17:46:49.873745Z"
    }
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])\n",
    "    \n",
    "def draw_pcd(pcd, where='opn_nb'):\n",
    "    if where is 'opn_nb':\n",
    "        visualizer = o3d.JVisualizer()\n",
    "        visualizer.add_geometry(pcd)\n",
    "        visualizer.show()\n",
    "    elif where is 'opn_view':\n",
    "        o3d.visualization.draw_geometries([pcd], width=1280, height=800)\n",
    "    elif where is 'mat_3d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1], pts[:,2])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    elif where is 'mat_2d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "def draw_registration_result(src_pcd, dst_pcd, x_pt, y_pt, theta):    \n",
    "    src_pcd_tmp = copy.deepcopy(src_pcd)\n",
    "    dst_pcd_tmp = copy.deepcopy(dst_pcd)\n",
    "    \n",
    "    src_pcd_tmp.paint_uniform_color([1, 0, 0])  # red source\n",
    "    dst_pcd_tmp.paint_uniform_color([0, 0, 1])  # blue target\n",
    "    \n",
    "    transform_mat = pose2matrix([x_pt, y_pt, 0], [0,0,theta])\n",
    "    dst_pcd_tmp.transform(transform_mat)\n",
    "    \n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(src_pcd_tmp)\n",
    "    visualizer.add_geometry(dst_pcd_tmp)\n",
    "    visualizer.show()\n",
    "    \n",
    "process_input = from_polar if args.no_polar else lambda x : x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:46:49.891904Z",
     "start_time": "2020-02-17T17:46:49.885278Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_dynamic_recon(dynamic, recon, mask):\n",
    "    # bin_mask = (mask[:,0] - mask[:,1]).round().view((mask.shape[0], 1, mask.shape[2], mask.shape[3]))\n",
    "    bin_mask = mask[:,1].round().view((mask.shape[0], 1, mask.shape[2], mask.shape[3]))\n",
    "    masked_dynamic = (dynamic * (1-mask))\n",
    "    masked_recon = (dynamic * (1-mask)) + (mask * recon)\n",
    "    return masked_dynamic, masked_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T17:51:59.197114Z",
     "start_time": "2020-02-17T17:46:49.893368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    Test folder : 8\n",
      "processing 0.npy\n",
      "Finding crop masks\n",
      "Masking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2827 [00:00<00:10, 272.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove zeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2827/2827 [00:08<00:00, 333.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Saving pcds to /home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing/8/first_new_attempt_new_unet_64f_gen_125_pcd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saby/anaconda3/envs/ati/lib/python3.6/site-packages/ipykernel_launcher.py:46: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c95852133c745f9adb6917813824b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=177.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n",
      "Saving to /home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing/8/first_new_attempt_new_unet_64f_gen_125_pcd_out_npy/0.npy\n",
      "done\n",
      "\n",
      "\n",
      "\n",
      "    Test folder : 24\n",
      "processing 0.npy\n",
      "Finding crop masks\n",
      "Masking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 35/3056 [00:00<00:08, 347.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove zeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3056/3056 [00:08<00:00, 352.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Saving pcds to /home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing/24/first_new_attempt_new_unet_64f_gen_125_pcd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2fb09a31b941298a2738d3b887d09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=191.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n",
      "Saving to /home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing/24/first_new_attempt_new_unet_64f_gen_125_pcd_out_npy/0.npy\n",
      "done\n",
      "\n",
      "\n",
      "\n",
      "    Test folder : 48\n",
      "processing 0.npy\n",
      "Finding crop masks\n",
      "Masking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/2579 [00:00<00:08, 304.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove zeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2579/2579 [00:06<00:00, 377.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Saving pcds to /home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing/48/first_new_attempt_new_unet_64f_gen_125_pcd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c432e4384b4843138f292e1f043ecc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n",
      "Saving to /home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing/48/first_new_attempt_new_unet_64f_gen_125_pcd_out_npy/0.npy\n",
      "done\n",
      "Done for all folders\n"
     ]
    }
   ],
   "source": [
    "for DATA_TEST_FOLDER in DATA_TEST_FOLDER_LIST:\n",
    "    print(\"\\n\\n\\n    Test folder : {}\".format(DATA_TEST_FOLDER))\n",
    "    ######## Set paths\n",
    "    OUTPUT_PCD_FOLDER = MODEL_FOLDER_NAME + \"_\" + MODEL_FILE_NAME.split(\".\")[0] + \"_pcd\" \n",
    "    if SAVE_PCD_NPY:\n",
    "        OUTPUT_NPY_FOLDER = OUTPUT_PCD_FOLDER + \"_out_npy\"\n",
    "\n",
    "    TEST_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, TEST_NPY_FOLDER)\n",
    "    OUTPUT_PCD_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, OUTPUT_PCD_FOLDER)\n",
    "    if SAVE_PCD_NPY:\n",
    "        OUTPUT_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, OUTPUT_NPY_FOLDER)\n",
    "\n",
    "    test_files  = sorted(os.listdir(TEST_NPY_FOLDER_PATH), key=getint)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PCD_FOLDER_PATH):\n",
    "        os.makedirs(OUTPUT_PCD_FOLDER_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(OUTPUT_PCD_FOLDER_PATH)\n",
    "        os.makedirs(OUTPUT_PCD_FOLDER_PATH)\n",
    "\n",
    "    if SAVE_PCD_NPY:\n",
    "        if not os.path.exists(OUTPUT_NPY_FOLDER_PATH):\n",
    "            os.makedirs(OUTPUT_NPY_FOLDER_PATH)\n",
    "        else:\n",
    "            shutil.rmtree(OUTPUT_NPY_FOLDER_PATH)\n",
    "            os.makedirs(OUTPUT_NPY_FOLDER_PATH)\n",
    "\n",
    "    ply_idx = 1\n",
    "    if SAVE_PCD_NPY:\n",
    "        npy_idx = 0\n",
    "\n",
    "    for test_file in test_files:\n",
    "        ###### Load corresponding dataset batch\n",
    "        print(\"processing {}\".format(test_file))\n",
    "        dataset_val = np.load(os.path.join(TEST_NPY_FOLDER_PATH, test_file))\n",
    "        dataset_val = preprocess(dataset_val, LIDAR_RANGE)\n",
    "        dataset_val = dataset_val.astype('float32')\n",
    "        val_loader  = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size,\n",
    "                            shuffle=False, num_workers=12, drop_last=False)\n",
    "\n",
    "        print(\"done\")\n",
    "        print(\"Saving pcds to {}\".format(OUTPUT_PCD_FOLDER_PATH))\n",
    "        recons=[]\n",
    "        total_recon = []\n",
    "        ##### For all batches of data\n",
    "        for i, img_data in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):\n",
    "            dynamic_img = img_data.cuda()\n",
    "\n",
    "            if LEARN_TO_FILTER:\n",
    "                recon, xmask = model(process_input(dynamic_img))\n",
    "                masked_dynamic, masked_recon = masked_dynamic_recon(dynamic_img, recon, xmask)\n",
    "                recon=masked_recon\n",
    "            else:\n",
    "                recon = model(process_input(dynamic_img))\n",
    "\n",
    "            recons=recon\n",
    "            recons_temp=np.array(recons.detach().cpu())\n",
    "            \n",
    "            ###### Save all pcds\n",
    "            for frame_num in range(recons_temp.shape[0]):\n",
    "                frame = from_polar(recons[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "                frame_actual = np.array([frame_image for frame_image in frame])\n",
    "                frame_flat = frame_actual.reshape((3,-1))\n",
    "                frame_crop = frame_flat#[:,(frame_flat[2]  > 0.005)]\n",
    "                some_pcd = o3d.geometry.PointCloud()\n",
    "                some_arr = frame_crop.T * LIDAR_RANGE\n",
    "                some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "                pcd_fname = str(ply_idx) + \".ply\"\n",
    "                single_pcd_path = os.path.join(OUTPUT_PCD_FOLDER_PATH, pcd_fname)\n",
    "                o3d.io.write_point_cloud(single_pcd_path, some_pcd)\n",
    "                ply_idx += 1\n",
    "            gc.collect()\n",
    "\n",
    "            ##### Append model outputs array\n",
    "            if SAVE_PCD_NPY:\n",
    "                recon_arr = from_polar(recon).detach().cpu().numpy()\n",
    "                # add color mask as zeros for now\n",
    "                if LEARN_TO_FILTER:\n",
    "                    bin_mask = xmask[:,0].round().view((xmask.shape[0], 1, xmask.shape[2], xmask.shape[3]))\n",
    "                    bin_mask = bin_mask.detach().cpu().numpy()\n",
    "                    color_arr = bin_mask\n",
    "                else:\n",
    "                    color_arr = np.zeros((recon_arr.shape[0], 1, recon_arr.shape[2], recon_arr.shape[3]))\n",
    "\n",
    "\n",
    "                recon_arr_4d = np.concatenate((recon_arr, color_arr), axis=1)\n",
    "                if i == 0:\n",
    "                    total_recon = recon_arr_4d\n",
    "                else:\n",
    "                    total_recon = np.concatenate((total_recon, recon_arr_4d), axis=0)\n",
    "                gc.collect()\n",
    "        print(\"done\")\n",
    "        \n",
    "        ##### Save model outputs array npy if necessary\n",
    "        if SAVE_PCD_NPY:\n",
    "            total_recon = total_recon.transpose(0,2,3,1)\n",
    "            npy_name = str(npy_idx) + \".npy\"\n",
    "            npy_path = os.path.join(OUTPUT_NPY_FOLDER_PATH, npy_name)\n",
    "            print(\"Saving to {}\".format(npy_path))\n",
    "            np.save(npy_path, total_recon)\n",
    "            npy_idx += 1\n",
    "            print(\"done\")\n",
    "print(\"Done for all folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T15:00:11.602946Z",
     "start_time": "2020-02-09T15:00:11.595882Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
