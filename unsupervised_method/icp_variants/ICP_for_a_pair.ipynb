{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.720155Z",
     "start_time": "2019-12-09T12:36:28.385987Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, shutil\n",
    "import gc\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import open3d\n",
    "import transforms3d\n",
    "import open3d as o3d\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "from open3d import read_point_cloud\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.727550Z",
     "start_time": "2019-12-09T12:36:29.722162Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.756694Z",
     "start_time": "2019-12-09T12:36:29.729347Z"
    }
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.808573Z",
     "start_time": "2019-12-09T12:36:29.759419Z"
    }
   },
   "outputs": [],
   "source": [
    "# VOXEL_SZ = 0.2\n",
    "# Z_MIN = 0\n",
    "# INVERT_Z = False\n",
    "# USE_GT = False\n",
    "# EVERY_NTH_COUNT = 10\n",
    "# PCD_TYPE = \".pcd\"\n",
    "# pcd_folder = \"complete_extracted\"\n",
    "\n",
    "# VOXEL_SZ = 0.2\n",
    "# Z_MIN = -2\n",
    "# Z_MIN = 0\n",
    "# INVERT_Z = True\n",
    "# USE_GT = True\n",
    "# EVERY_NTH_COUNT = 1\n",
    "# PCD_TYPE = \".ply\"\n",
    "pcd_folder = \"_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.812647Z",
     "start_time": "2019-12-09T12:36:29.810654Z"
    }
   },
   "outputs": [],
   "source": [
    "# pcd_folder_path = \"/home/sabyasachi/Projects/ati/data/data/datasets/IISC/2019-06-12/10-00-14-P1-6-auto-ccw_5loops_0.6_no_numba/\"\n",
    "pcd_folder_path = \"/home/sabyasachi/Projects/ati/data/data/datasets/Carla/small_map/110k/static/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.820857Z",
     "start_time": "2019-12-09T12:36:29.814228Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_path = os.path.join(pcd_folder_path, pcd_folder)\n",
    "\n",
    "pcd_files = sorted(os.listdir(pcd_path), key=getint)\n",
    "# FIRST_PCD = 100\n",
    "# FIRST_PCD = int(pcd_files[0][:-4])\n",
    "# FINAL_PCD = int(pcd_files[-1][:-4])\n",
    "\n",
    "# OUTPUT_DIR = \"./temp_save_parallel_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.824716Z",
     "start_time": "2019-12-09T12:36:29.822412Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx = np.random.choice(len(pcd_files))\n",
    "idx =2925\n",
    "prev_pcd_file = pcd_files[idx]\n",
    "next_pcd_file = pcd_files[idx+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.830863Z",
     "start_time": "2019-12-09T12:36:29.827292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My I/O fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.853374Z",
     "start_time": "2019-12-09T12:36:29.832775Z"
    },
    "code_folding": [
     46,
     52,
     58
    ]
   },
   "outputs": [],
   "source": [
    "def filter_pcd(old_pcd,\n",
    "               apply_downsample = False,\n",
    "               downsample_voxel_size = 0.2,\n",
    "               \n",
    "               apply_outlier_removal = False,\n",
    "               downsample_radius = 1,\n",
    "               downsample_neighbors = 20,\n",
    "               \n",
    "               apply_crop = True,\n",
    "               crop_min_arr = np.array([-100,-100,-100]),\n",
    "               crop_max_arr = np.array([100,100,2]),\n",
    "               \n",
    "               apply_cluster = False,\n",
    "               cluster_neighbours = 30,\n",
    "               cluster_labels = 2):\n",
    "    np.random.seed(0)\n",
    "    pcd = copy.deepcopy(old_pcd)\n",
    "    \n",
    "    if apply_outlier_removal:\n",
    "        denser_pcd, ind = o3d.geometry.radius_outlier_removal(pcd,\n",
    "                                                              nb_points = downsample_neighbors,\n",
    "                                                              radius    = downsample_radius)\n",
    "        pcd = denser_pcd\n",
    "    \n",
    "    if apply_downsample:\n",
    "        voxel_down_pcd = o3d.geometry.voxel_down_sample(pcd, voxel_size = downsample_voxel_size)\n",
    "        pcd = voxel_down_pcd\n",
    "    \n",
    "    if apply_crop:\n",
    "        cropped_pcd = o3d.geometry.crop_point_cloud(pcd, crop_min_arr, crop_max_arr)\n",
    "        pcd = cropped_pcd\n",
    "\n",
    "    if apply_cluster:\n",
    "        few_pts = np.asarray(pcd.points)\n",
    "        try:\n",
    "            few_pts_reduced = LocallyLinearEmbedding(n_neighbors=cluster_neighbours, n_components=2).fit_transform(few_pts)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                few_pts_reduced = LocallyLinearEmbedding(n_neighbors=cluster_neighbours, n_components=2, eigen_solver='dense').fit_transform(few_pts)\n",
    "            except Exception as e:\n",
    "                few_pts_reduced = few_pts\n",
    "        clf = MeanShift().fit(few_pts_reduced)\n",
    "        pcd.points = o3d.utility.Vector3dVector(few_pts[clf.labels_ < cluster_labels])\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def make_2d(pcd):\n",
    "    new_pcd = copy.deepcopy(pcd)\n",
    "    new_pts = np.concatenate([np.asarray(pcd.points)[:,:-1],np.zeros((len(pcd.points),1))], axis=1)\n",
    "    new_pcd.points = o3d.utility.Vector3dVector(new_pts)\n",
    "    return new_pcd\n",
    "\n",
    "def read_pcd(pcd_id):\n",
    "#     prefix = \"\".join([\"0\" for _ in range(3 - len(str(pcd_id)))])\n",
    "    pcd_file = str(pcd_id) + PCD_TYPE\n",
    "    pcd = o3d.io.read_point_cloud(os.path.join(pcd_path, pcd_file))\n",
    "    return pcd\n",
    "\n",
    "def draw_pcd(pcd, where='mat_2d'):    \n",
    "    if where is 'opn_nb':\n",
    "        visualizer = o3d.JVisualizer()\n",
    "        visualizer.add_geometry(pcd)\n",
    "        visualizer.show()\n",
    "    elif where is 'opn_view':\n",
    "        o3d.visualization.draw_geometries([pcd], width=1280, height=800)\n",
    "    elif where is 'mat_3d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1], pts[:,2])\n",
    "        plt.show()\n",
    "    elif where is 'mat_2d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1], s=1)\n",
    "        plt.show()\n",
    "        \n",
    "def pose2matrix(translation_list, rotation_angle_list):\n",
    "    trans_vec = np.array(translation_list)\n",
    "    rot_ang = [np.deg2rad(ang) for ang in rotation_angle_list ]\n",
    "    rot_mat = transforms3d.euler.euler2mat(rot_ang[0], rot_ang[1], rot_ang[2])\n",
    "    zoom = np.ones(3)\n",
    "    transform_mat = transforms3d.affines.compose(trans_vec, rot_mat, zoom)\n",
    "    return transform_mat\n",
    "\n",
    "def draw_registration_result_2d(src_pcd, dst_pcd, x_pt, y_pt, theta):    \n",
    "    src_pcd_tmp = copy.deepcopy(src_pcd)\n",
    "    dst_pcd_tmp = copy.deepcopy(dst_pcd)\n",
    "    \n",
    "    src_pcd_tmp.paint_uniform_color([1, 0, 0])  # red source\n",
    "    dst_pcd_tmp.paint_uniform_color([0, 0, 1])  # blue target\n",
    "    \n",
    "    transform_mat = pose2matrix([x_pt, y_pt, 0], [0,0,theta])\n",
    "    dst_pcd_tmp.transform(transform_mat)\n",
    "    \n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(src_pcd_tmp)\n",
    "    visualizer.add_geometry(dst_pcd_tmp)\n",
    "    visualizer.show()\n",
    "    \n",
    "def draw_registration_result_3d(src, dst, trans_arr, rot_arr):\n",
    "    source = copy.deepcopy(src)\n",
    "    target = copy.deepcopy(dst)\n",
    "    \n",
    "    transform_mat = pose2matrix(trans_arr, rot_arr)\n",
    "    \n",
    "    source.paint_uniform_color([1, 0, 0]) # red\n",
    "    target.paint_uniform_color([0, 0, 1]) # blue\n",
    "    source.transform(transform_mat)\n",
    "    \n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(source)\n",
    "    visualizer.add_geometry(target)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### DeepMapping ICP fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.904608Z",
     "start_time": "2019-12-09T12:36:29.855226Z"
    },
    "code_folding": [
     0,
     19,
     53,
     87,
     100,
     124,
     166,
     245,
     266,
     278,
     284,
     305
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transform_to_global_2D(pose, obs_local):\n",
    "    \"\"\" \n",
    "    transform local point cloud to global frame\n",
    "    row-based matrix product\n",
    "    pose: <Bx3> each row represents <x,y,theta>\n",
    "    obs_local: <BxLx2> \n",
    "    \"\"\"\n",
    "    L = obs_local.shape[1]\n",
    "    # c0 is the loc of sensor in global coord. frame c0: <Bx2>\n",
    "    c0, theta0 = pose[:, 0:2], pose[:, 2]\n",
    "    c0 = c0.unsqueeze(1).expand(-1, L, -1)  # <BxLx2>\n",
    "\n",
    "    cos = torch.cos(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    sin = torch.sin(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    R_transpose = torch.cat((cos, sin, -sin, cos), dim=1).reshape(-1, 2, 2)\n",
    "\n",
    "    obs_global = torch.bmm(obs_local, R_transpose) + c0\n",
    "    return obs_global\n",
    "\n",
    "def transform_to_global_AVD(pose, obs_local):\n",
    "    \"\"\"\n",
    "    transform obs local coordinate to global corrdinate frame\n",
    "    :param pose: <Bx3> <x,z,theta> y = 0\n",
    "    :param obs_local: <BxLx3> (unorganized) or <BxHxWx3> (organized)\n",
    "    :return obs_global: <BxLx3> (unorganized) or <BxHxWx3> (organized)\n",
    "    \"\"\"\n",
    "    is_organized = 1 if len(obs_local.shape) == 4 else 0\n",
    "    b = obs_local.shape[0]\n",
    "    if is_organized:\n",
    "        H,W = obs_local.shape[1:3]\n",
    "        obs_local = obs_local.view(b,-1,3) # <BxLx3>\n",
    "    \n",
    "    L = obs_local.shape[1]\n",
    "\n",
    "    c0, theta0 = pose[:,0:2],pose[:,2] # c0 is the loc of sensor in global coord frame c0 <Bx2> <x,z>\n",
    "\n",
    "    zero = torch.zeros_like(c0[:,:1])\n",
    "    c0 = torch.cat((c0,zero),-1) # <Bx3> <x,z,y=0>\n",
    "    c0 = c0[:,[0,2,1]] # <Bx3> <x,y=0,z>\n",
    "    c0 = c0.unsqueeze(1).expand(-1,L,-1) # <BxLx3>\n",
    "    \n",
    "    cos = torch.cos(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    sin = torch.sin(theta0).unsqueeze(-1).unsqueeze(-1)\n",
    "    zero = torch.zeros_like(sin)\n",
    "    one = torch.ones_like(sin)\n",
    "    \n",
    "    R_y_transpose = torch.cat((cos,zero,-sin,zero,one,zero,sin,zero,cos),dim=1).reshape(-1,3,3)\n",
    "    obs_global = torch.bmm(obs_local,R_y_transpose) + c0\n",
    "    if is_organized:\n",
    "        obs_global = obs_global.view(b,H,W,3)\n",
    "    return obs_global\n",
    "\n",
    "\n",
    "def rigid_transform_kD(A, B):\n",
    "    \"\"\"\n",
    "    Find optimal transformation between two sets of corresponding points\n",
    "    Adapted from: http://nghiaho.com/uploads/code/rigid_transform_3D.py_\n",
    "    Args:\n",
    "        A.B: <Nxk> each row represent a k-D points\n",
    "    Returns:\n",
    "        R: kxk\n",
    "        t: kx1\n",
    "        B = R*A+t\n",
    "    \"\"\"\n",
    "    assert len(A) == len(B)\n",
    "    N,k = A.shape\n",
    "    \n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    \n",
    "    # centre the points\n",
    "    AA = A - np.tile(centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "\n",
    "    H = np.matmul(np.transpose(AA) , BB)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = np.matmul(Vt.T , U.T)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[k-1,:] *= -1\n",
    "        R = np.matmul(Vt.T , U.T)\n",
    "\n",
    "    t = np.matmul(-R,centroid_A.T) + centroid_B.T\n",
    "    t = np.expand_dims(t,-1)\n",
    "    return R, t\n",
    "\n",
    "def estimate_normal_eig(data):\n",
    "    \"\"\"\n",
    "    Computes the vector normal to the k-dimensional sample points\n",
    "    \"\"\"\n",
    "    data -= np.mean(data,axis=0)\n",
    "    data = data.T\n",
    "    A = np.cov(data)\n",
    "    w,v = np.linalg.eig(A)\n",
    "    idx = np.argmin(w)\n",
    "    v = v[:,idx]\n",
    "    v /= np.linalg.norm(v,2)\n",
    "    return v\n",
    "    \n",
    "def surface_normal(pc,n_neighbors=6):\n",
    "    \"\"\"\n",
    "    Estimate point cloud surface normal\n",
    "    Args:\n",
    "        pc: Nxk matrix representing k-dimensional point cloud\n",
    "    \"\"\"\n",
    "    \n",
    "    n_points,k = pc.shape\n",
    "    v = np.zeros_like(pc)\n",
    "    \n",
    "    # nn search\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto').fit(pc)\n",
    "    _, indices = nbrs.kneighbors(pc)\n",
    "    neighbor_points = pc[indices]\n",
    "    for i in range(n_points):\n",
    "        # estimate surface normal\n",
    "        v_tmp = estimate_normal_eig(neighbor_points[i,])\n",
    "        v_tmp[abs(v_tmp)<1e-5] = 0\n",
    "        if v_tmp[0] < 0:\n",
    "            v_tmp *= -1\n",
    "        v[i,:] = v_tmp\n",
    "    return v\n",
    "\n",
    "\n",
    "def point2plane_metrics_2D(p,q,v):\n",
    "    \"\"\"\n",
    "    Point-to-plane minimization\n",
    "    Chen, Y. and G. Medioni. “Object Modelling by Registration of Multiple Range Images.” \n",
    "    Image Vision Computing. Butterworth-Heinemann . Vol. 10, Issue 3, April 1992, pp. 145-155.\n",
    "    \n",
    "    Args:\n",
    "        p: Nx2 matrix, moving point locations\n",
    "        q: Nx2 matrix, fixed point locations\n",
    "        v:Nx2 matrix, fixed point normal\n",
    "    Returns:\n",
    "        R: 2x2 matrix\n",
    "        t: 2x1 matrix\n",
    "    \"\"\"\n",
    "    assert q.shape[1] == p.shape[1] == v.shape[1] == 2, 'points must be 2D'\n",
    "    \n",
    "    p,q,v = np.array(p),np.array(q),np.array(v)\n",
    "    c = np.expand_dims(np.cross(p,v),-1)\n",
    "    cn = np.concatenate((c,v),axis=1)  # [ci,nix,niy]\n",
    "    C = np.matmul(cn.T,cn)\n",
    "    if np.linalg.cond(C)>=1/sys.float_info.epsilon:\n",
    "        # handle singular matrix\n",
    "        raise ArithmeticError('Singular matrix')\n",
    "    \n",
    "#     print(C.shape)\n",
    "    qp = q-p\n",
    "    b = np.array([\n",
    "        [(qp*cn[:,0:1]*v).sum()],\n",
    "        [(qp*cn[:,1:2]*v).sum()],\n",
    "        [(qp*cn[:,2:]*v).sum()],\n",
    "    ])\n",
    "\n",
    "    X = np.linalg.solve(C, b)\n",
    "    cos_ = np.cos(X[0])[0]\n",
    "    sin_ = np.sin(X[0])[0]\n",
    "    R = np.array([\n",
    "        [cos_,-sin_],\n",
    "        [sin_,cos_]\n",
    "    ])\n",
    "    t = np.array(X[1:])\n",
    "    return R,t\n",
    "\n",
    "def icp(src,dst,nv=None,n_iter=100,init_pose=[0,0,0],torlerance=1e-6,metrics='point',verbose=False):\n",
    "    '''\n",
    "    Currently only works for 2D case\n",
    "    Args:\n",
    "        src: <Nx2> 2-dim moving points\n",
    "        dst: <Nx2> 2-dim fixed points\n",
    "        n_iter: a positive integer to specify the maxium nuber of iterations\n",
    "        init_pose: [tx,ty,theta] initial transformation\n",
    "        torlerance: the tolerance of registration error\n",
    "        metrics: 'point' or 'plane'\n",
    "        \n",
    "    Return:\n",
    "        src: transformed src points\n",
    "        R: rotation matrix\n",
    "        t: translation vector\n",
    "        R*src + t\n",
    "    '''\n",
    "    n_src = src.shape[0]\n",
    "    if metrics == 'plane' and nv is None:\n",
    "        nv = surface_normal(dst)\n",
    "\n",
    "    #src = np.matrix(src)\n",
    "    #dst = np.matrix(dst)\n",
    "    #Initialise with the initial pose estimation\n",
    "    R_init = np.array([[np.cos(init_pose[2]),-np.sin(init_pose[2])],\n",
    "                   [np.sin(init_pose[2]), np.cos(init_pose[2])] \n",
    "                      ])\n",
    "    t_init = np.array([[init_pose[0]],\n",
    "                   [init_pose[1]]\n",
    "                      ])  \n",
    "    \n",
    "    #src =  R_init*src.T + t_init\n",
    "    src = np.matmul(R_init,src.T) + t_init\n",
    "    src = src.T\n",
    "    \n",
    "    R,t = R_init,t_init\n",
    "\n",
    "    prev_err = np.inf\n",
    "    current_err = prev_err\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(dst)\n",
    "    for i in range(n_iter):\n",
    "        # Find the nearest neighbours\n",
    "        _, indices = nbrs.kneighbors(src)\n",
    "\n",
    "        # Compute the transformation\n",
    "        if metrics == 'point':\n",
    "            R0,t0 = rigid_transform_kD(src,dst[indices[:,0]])\n",
    "        elif metrics=='plane':\n",
    "            try:\n",
    "                R0,t0 = point2plane_metrics_2D(src,dst[indices[:,0]], nv[indices[:,0]]) \n",
    "            except ArithmeticError:\n",
    "                print('Singular matrix')\n",
    "                return src,R,t, current_err\n",
    "        else:\n",
    "            raise ValueError('metrics: {} not recognized.'.format(metrics))\n",
    "        # Update dst and compute error\n",
    "        src = np.matmul(R0,src.T) + t0\n",
    "        src = src.T\n",
    "\n",
    "        R = np.matmul(R0,R)\n",
    "        t = np.matmul(R0,t) + t0\n",
    "        #R = R0*R\n",
    "        #t = R0*t + t0\n",
    "        current_err = np.sqrt((np.array(src-dst[indices[:,0]])**2).sum()/n_src)\n",
    "\n",
    "#         if verbose:\n",
    "#             print('iter: {}, error: {}'.format(i,current_err))\n",
    "            \n",
    "        if  np.abs(current_err - prev_err) < torlerance:\n",
    "            break\n",
    "        else:\n",
    "            prev_err = current_err\n",
    "            \n",
    "    if verbose:\n",
    "        print('iter: {}, error: {}'.format(i,current_err), flush=True)\n",
    "        \n",
    "    return src,R,t, current_err\n",
    "\n",
    "\n",
    "def compute_ate(output,target):\n",
    "    \"\"\"\n",
    "    compute absolute trajectory error for avd dataset\n",
    "    Args:\n",
    "        output: <Nx3> predicted trajectory positions, where N is #scans\n",
    "        target: <Nx3> ground truth trajectory positions\n",
    "    Returns:\n",
    "        trans_error: <N> absolute trajectory error for each pose\n",
    "        output_aligned: <Nx3> aligned position in ground truth coord\n",
    "    \"\"\"\n",
    "    R,t = rigid_transform_kD(output,target)\n",
    "    output_aligned = np.matmul(R , output.T) + t\n",
    "    output_aligned = output_aligned.T\n",
    "\n",
    "    align_error = np.array(output_aligned - target)\n",
    "    trans_error = np.sqrt(np.sum(align_error**2,1))\n",
    "    \n",
    "    ate = np.sqrt(np.dot(trans_error,trans_error) / len(trans_error))\n",
    "\n",
    "    return ate,output_aligned\n",
    "\n",
    "def remove_invalid_pcd(pcd):\n",
    "    \"\"\"\n",
    "    remove invalid in valid points that have all-zero coordinates\n",
    "    pcd: open3d pcd objective\n",
    "    \"\"\"\n",
    "    pcd_np = np.asarray(pcd.points) # <Nx3>\n",
    "    non_zero_coord = np.abs(pcd_np) > 1e-6 # <Nx3>\n",
    "    valid_ind = np.sum(non_zero_coord,axis=-1)>0 #<N>\n",
    "    valid_ind = list(np.nonzero(valid_ind)[0])\n",
    "    valid_pcd = open3d.select_down_sample(pcd,valid_ind)\n",
    "    return valid_pcd\n",
    "\n",
    "def ang2mat(theta):\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    R = np.array([[c,-s],[s,c]])\n",
    "    return R\n",
    "\n",
    "def cat_pose_2D(pose0,pose1):\n",
    "    \"\"\"\n",
    "    pose0, pose1: <Nx3>, numpy array\n",
    "    each row: <x,y,theta>\n",
    "    \"\"\"\n",
    "    assert(pose0.shape==pose1.shape)\n",
    "    n_pose = pose0.shape[0]\n",
    "    pose_out = np.zeros_like(pose0) \n",
    "    for i in range(n_pose):\n",
    "        R0 = ang2mat(pose0[i,-1])\n",
    "        R1 = ang2mat(pose1[i,-1])\n",
    "        t0 = np.expand_dims(pose0[i,:2],-1)\n",
    "        t1 = np.expand_dims(pose1[i,:2],-1)\n",
    "        \n",
    "        R = np.matmul(R1,R0)\n",
    "        theta = np.arctan2(R[1,0],R[0,0])\n",
    "        t = np.matmul(R1,t0) + t1\n",
    "        pose_out[i,:2] = t.T\n",
    "        pose_out[i,2] = theta\n",
    "    return pose_out\n",
    "\n",
    "def convert_depth_map_to_pc(depth,fxy,cxy,max_depth=7000,depth_scale=2000):\n",
    "    \"\"\"\n",
    "    create point cloud from depth map and camera instrinsic\n",
    "    depth: <hxw> numpy array\n",
    "    fxy: [fx,fy]\n",
    "    cxy: [cx,cy]\n",
    "    \"\"\"\n",
    "    fx,fy = fxy \n",
    "    cx,cy = cxy\n",
    "    h,w = depth.shape\n",
    "    \n",
    "    c,r = np.meshgrid(range(1,w+1), range(1,h+1))\n",
    "    invalid = depth >= max_depth\n",
    "    depth[invalid] = 0\n",
    "\n",
    "    z = depth / float(depth_scale)\n",
    "    x = z * (c-cx) / fx\n",
    "    y = z * (r-cy) / fycolor\n",
    "    xyz = np.dstack((x,y,z)).astype(np.float32)\n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.914497Z",
     "start_time": "2019-12-09T12:36:29.906347Z"
    },
    "code_folding": [
     0,
     16,
     27
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transform_to_global_open3d(pose,local_pcd):\n",
    "    pcd = copy.deepcopy(local_pcd)\n",
    "    n_pcd = len(pcd)\n",
    "    for i in range(n_pcd):\n",
    "        tx,ty,theta = pose[i,:]\n",
    "        cos,sin = np.cos(theta),np.sin(theta)\n",
    "        trans = np.array([\n",
    "                        [cos,-sin,0,tx],\n",
    "                        [sin,cos,0,ty],\n",
    "                        [0,0,1,0],\n",
    "                        [0,0,0,1],\n",
    "                        ])\n",
    "        pcd[i].transform(trans) \n",
    "    return pcd\n",
    "\n",
    "\n",
    "def np_to_pcd(xyz):\n",
    "    \"\"\"\n",
    "    convert numpy array to point cloud object in open3d\n",
    "    \"\"\"\n",
    "    xyz = xyz.reshape(-1,3)\n",
    "    pcd = o3d.PointCloud()\n",
    "    pcd.points = o3d.Vector3dVector(xyz)\n",
    "    pcd.paint_uniform_color(np.random.rand(3,))\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def load_obs_global_est(file_name):\n",
    "    \"\"\"\n",
    "    load saved obs_global_est.npy file and convert to point cloud object\n",
    "    \"\"\"\n",
    "    obs_global_est = np.load(file_name)\n",
    "    n_pc = obs_global_est.shape[0]\n",
    "    pcds = o3d.PointCloud()\n",
    "\n",
    "    for i in range(n_pc):\n",
    "        xyz = obs_global_est[i,:,:]\n",
    "        current_pcd = np_to_pcd(xyz)\n",
    "        pcds += current_pcd\n",
    "    return pcds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.926600Z",
     "start_time": "2019-12-09T12:36:29.916083Z"
    },
    "code_folding": [
     0,
     28
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_global_point_cloud(point_cloud, pose, valid_points, save_dir, **kwargs):\n",
    "    if torch.is_tensor(point_cloud):\n",
    "        point_cloud = point_cloud.cpu().detach().numpy()\n",
    "    if torch.is_tensor(pose):\n",
    "        pose = pose.cpu().detach().numpy()\n",
    "    if torch.is_tensor(valid_points):\n",
    "        valid_points = valid_points.cpu().detach().numpy()\n",
    "\n",
    "    file_name = 'global_map_pose'\n",
    "    if kwargs is not None:\n",
    "        for k, v in kwargs.items():\n",
    "            file_name = file_name + '_' + str(k) + '_' + str(v)\n",
    "    save_name = os.path.join(save_dir, file_name)\n",
    "\n",
    "    bs = point_cloud.shape[0]\n",
    "    for i in range(bs):\n",
    "        current_pc = point_cloud[i, :, :]\n",
    "        idx = valid_points[i, ] > 0\n",
    "        current_pc = current_pc[idx]\n",
    "\n",
    "        plt.plot(current_pc[:, 0], current_pc[:, 1], '.')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    plt.plot(pose[:, 0], pose[:, 1], color='black')\n",
    "#     plt.savefig(save_name)\n",
    "    plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "def save_global_point_cloud_open3d(point_cloud,pose,save_dir):\n",
    "    file_name = 'global_map_pose'\n",
    "    save_name = os.path.join(save_dir, file_name)\n",
    "\n",
    "    n_pcd = len(point_cloud)\n",
    "    for i in range(n_pcd):\n",
    "        current_pc = np.asarray(point_cloud[i].points)\n",
    "        plt.plot(current_pc[:, 0], current_pc[:, 1], '.',markersize=1)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    plt.plot(pose[:, 0], pose[:, 1], color='black')\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.943608Z",
     "start_time": "2019-12-09T12:36:29.928832Z"
    },
    "code_folding": [
     0,
     14
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_valid_points(local_point_cloud):\n",
    "    \"\"\"\n",
    "    find valid points in local point cloud\n",
    "        invalid points have all zeros local coordinates\n",
    "    local_point_cloud: <BxNxk> \n",
    "    valid_points: <BxN> indices  of valid point (0/1)\n",
    "    \"\"\"\n",
    "    eps = 1e-6\n",
    "    non_zero_coord = torch.abs(local_point_cloud) > eps\n",
    "    valid_points = torch.sum(non_zero_coord, dim=-1)\n",
    "    valid_points = valid_points > 0\n",
    "    return valid_points\n",
    "\n",
    "\n",
    "class SimulatedPointCloud(Dataset):\n",
    "    def __init__(self, root, trans_by_pose=None):\n",
    "        # trans_by_pose: <Bx3> pose\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self._trans_by_pose = trans_by_pose\n",
    "        file_list = glob.glob(os.path.join(self.root, '*pcd'))\n",
    "        self.file_list = sorted(file_list)\n",
    "\n",
    "\n",
    "#        self.pcds = [] # a list of open3d pcd objects \n",
    "        point_clouds = [] #a list of tensor <Lx2>\n",
    "        for file in self.file_list:\n",
    "            pcd = read_point_cloud(file)\n",
    "#            self.pcds.append(pcd)\n",
    "            current_point_cloud = np.asarray(pcd.points, dtype=np.float32)[:, 0:2]        \n",
    "            point_clouds.append(current_point_cloud)\n",
    "\n",
    "        point_clouds = np.asarray(point_clouds)\n",
    "        try:\n",
    "            self.point_clouds = torch.from_numpy(point_clouds) # <NxLx2>\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            # Handling the uniform size change across all point clouds\n",
    "            NEW_SIZE = max([current_point_cloud.shape[0] for current_point_cloud in point_clouds]) + 1\n",
    "            print('Aligning pt clouds to equal size of {}'.format(NEW_SIZE))\n",
    "\n",
    "            np.random.seed(0)\n",
    "            new_point_clouds = []\n",
    "            for current_point_cloud in point_clouds:\n",
    "                old_size = current_point_cloud.shape[0]\n",
    "                delta_size = NEW_SIZE - old_size\n",
    "                idx_list = np.random.randint(low=0, high=old_size, size=delta_size)\n",
    "                delta_point_cloud = np.array([current_point_cloud[idx] for idx in idx_list])\n",
    "                new_point_cloud = np.concatenate([current_point_cloud, delta_point_cloud])\n",
    "                new_point_clouds.append(new_point_cloud)\n",
    "            point_clouds = np.asarray(new_point_clouds)\n",
    "            self.point_clouds = torch.from_numpy(point_clouds) # <NxLx2>\n",
    "\n",
    "        self.valid_points = find_valid_points(self.point_clouds) # <NxL>\n",
    "\n",
    "        # number of points in each point cloud\n",
    "        self.n_obs = self.point_clouds.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pcd = self.point_clouds[index,:,:]  # <Lx2>\n",
    "        valid_points = self.valid_points[index,:]\n",
    "        if self._trans_by_pose is not None:\n",
    "            pcd = pcd.unsqueeze(0)  # <1XLx2>\n",
    "            pose = self._trans_by_pose[index, :].unsqueeze(0)  # <1x3>\n",
    "            pcd = utils.transform_to_global_2D(pose, pcd).squeeze(0)\n",
    "        return pcd,valid_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.point_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Create the dataset (and save it for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T12:32:13.302026Z",
     "start_time": "2019-12-03T12:32:13.293592Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "def parallel_dataset_thread(parallel_arg):\n",
    "    pcd_idx = parallel_arg[0]\n",
    "    file_idx = parallel_arg[1]\n",
    "    \n",
    "    # Read pcd\n",
    "    some_pcd = read_pcd(pcd_idx)\n",
    "    \n",
    "    # Remove zero points and invert Z for carla pcds\n",
    "    some_arr = np.asarray(some_pcd.points)\n",
    "    some_arr = np.array([(x,y,z) for x, y, z in some_arr if not (x == 0 and y == 0 and z == 0)])\n",
    "    if INVERT_Z:\n",
    "        some_arr = np.array([(x,y,-z) for x, y, z in some_arr])\n",
    "    some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "    \n",
    "    # Remove outliers and crop ground circle points\n",
    "    some_pcd = filter_pcd(some_pcd,\n",
    "                          apply_downsample = False,\n",
    "                          apply_outlier_removal = False,\n",
    "                          apply_crop = True,\n",
    "                          apply_cluster = False)\n",
    "    \n",
    "    # Make it 2d\n",
    "    some_pcd = make_2d(some_pcd)\n",
    "    \n",
    "    # Downsample\n",
    "    for _ in range(3):\n",
    "        some_pcd = filter_pcd(some_pcd,\n",
    "                              apply_downsample = True,\n",
    "                              apply_outlier_removal = False,\n",
    "                              apply_crop = False,\n",
    "                              apply_cluster = False)\n",
    "    \n",
    "    # Set filename\n",
    "    prefix = \"\".join([\"0\" for _ in range(3 - len(str(file_idx)))])\n",
    "    single_pcd_fname = prefix + str(file_idx) + \".pcd\"\n",
    "    single_pcd_path = os.path.join(out_dir, single_pcd_fname)\n",
    "    \n",
    "    # Save pcd\n",
    "    o3d.io.write_point_cloud(single_pcd_path, some_pcd)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T12:32:35.396868Z",
     "start_time": "2019-12-03T12:32:13.304867Z"
    },
    "hidden": true
   },
   "source": [
    "iter_arr = np.arange(start=FIRST_PCD, stop=FINAL_PCD+1, step=EVERY_NTH_COUNT)\n",
    "parallel_dataset_args = [(pcd_idx, file_idx) for pcd_idx, file_idx in zip(iter_arr, range(iter_arr.shape[0]))]\n",
    "process_dataset_pool = Pool(cpu_count()-1)\n",
    "# process_pool = Pool(1)\n",
    "__ = [each for each in tqdm_notebook(process_dataset_pool.imap(parallel_dataset_thread,\n",
    "                                                               parallel_dataset_args),\n",
    "                                             total = len(parallel_dataset_args))]\n",
    "process_dataset_pool.terminate()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T12:32:35.401332Z",
     "start_time": "2019-12-03T12:32:35.398841Z"
    },
    "hidden": true
   },
   "source": [
    "pcd_path = out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLAM them using ICP 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.958364Z",
     "start_time": "2019-12-09T12:36:29.945359Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_pcd = o3d.io.read_point_cloud(os.path.join(pcd_path, prev_pcd_file))\n",
    "next_pcd = o3d.io.read_point_cloud(os.path.join(pcd_path, next_pcd_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.967036Z",
     "start_time": "2019-12-09T12:36:29.960039Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_pcd_down = filter_pcd(prev_pcd, apply_downsample= True)\n",
    "next_pcd_down = filter_pcd(next_pcd, apply_downsample= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.971023Z",
     "start_time": "2019-12-09T12:36:29.968712Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_pts = np.asarray(prev_pcd_down.points)\n",
    "next_pts = np.asarray(next_pcd_down.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:29.979383Z",
     "start_time": "2019-12-09T12:36:29.972599Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_icp(src_arr, dst_arr):\n",
    "    _,rot_mat_xy,trans_xy, err_xy = icp(src_arr[:,[0,1]], dst_arr[:,[0,1]], metrics='plane')\n",
    "    _,rot_mat_yz,trans_yz, err_yz = icp(src_arr[:,[1,2]], dst_arr[:,[1,2]], metrics='plane')\n",
    "    _,rot_mat_zx,trans_zx, err_zx = icp(src_arr[:,[2,0]], dst_arr[:,[2,0]], metrics='plane')\n",
    "\n",
    "    trans_x = (trans_xy[0][0] + trans_zx[1][0]) / 2\n",
    "    trans_y = (trans_xy[1][0] + trans_yz[0][0]) / 2\n",
    "    trans_z = (trans_yz[1][0] + trans_zx[0][0]) / 2\n",
    "    trans_arr = np.array([trans_x, trans_y, trans_z])\n",
    "\n",
    "    rot_roll = np.rad2deg(np.arccos(rot_mat_yz[0,0]))\n",
    "    rot_pitch = np.rad2deg(np.arccos(rot_mat_zx[0,0]))\n",
    "    rot_yaw = np.rad2deg(np.arccos(rot_mat_xy[0,0]))\n",
    "    rot_arr = np.array([rot_roll, rot_pitch, rot_yaw])\n",
    "    \n",
    "    return trans_arr, rot_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:30.871041Z",
     "start_time": "2019-12-09T12:36:29.981073Z"
    }
   },
   "outputs": [],
   "source": [
    "translation, rotation = do_icp(prev_pts, next_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:30.876605Z",
     "start_time": "2019-12-09T12:36:30.872573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.15983181, 2.27928193, 0.17893139]),\n",
       " array([1.61507218, 0.23803658, 5.17958449]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate registration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:31.427901Z",
     "start_time": "2019-12-09T12:36:30.878460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No registration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6df2332d5d8406db93d4f5f61d0fcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 2 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"No registration\")\n",
    "draw_registration_result_3d(prev_pcd, next_pcd, np.zeros(3), np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:31.896052Z",
     "start_time": "2019-12-09T12:36:31.429536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With ICP 3d registration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977d00cb0d454405b2a13f61c42b5fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 2 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"With ICP 3d registration\")\n",
    "draw_registration_result_3d(prev_pcd, next_pcd, translation, rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:32.199562Z",
     "start_time": "2019-12-09T12:36:31.897635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.32540346, 4.92089291, 0.        ]),\n",
       " array([0.        , 0.        , 5.17958449]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,rot_mat_xy,trans_xy, err_xy = icp(prev_pts[:,[0,1]], next_pts[:,[0,1]], metrics='plane')\n",
    "rot_yaw = np.rad2deg(np.arccos(rot_mat_xy[0,0]))\n",
    "np.array([trans_xy[0][0], trans_xy[1][0], 0]), np.array([0, 0, rot_yaw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:32.762411Z",
     "start_time": "2019-12-09T12:36:32.203961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With ICP 2d registration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c20f6fd55284c59b90dd4f30e0d3dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 2 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"With ICP 2d registration\")\n",
    "draw_registration_result_3d(prev_pcd, next_pcd, np.array([trans_xy[0][0], trans_xy[1][0], 0]), np.array([0, 0, rot_yaw]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLAM them using ICP 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:47.888721Z",
     "start_time": "2019-12-09T12:36:47.870698Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    pcd_down = o3d.geometry.voxel_down_sample(pcd, voxel_size)\n",
    "    radius_normal = voxel_size * 2\n",
    "    o3d.geometry.estimate_normals(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    radius_feature = voxel_size * 5\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def read_pcd(src_pcd, dst_pcd):\n",
    "    source = o3d.io.read_point_cloud(src_pcd)\n",
    "    target = o3d.io.read_point_cloud(dst_pcd)\n",
    "    return source, target\n",
    "\n",
    "def prepare_dataset(source, target, voxel_size):\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, distance_threshold,\n",
    "        o3d.registration.TransformationEstimationPointToPoint(False), 4, [\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.registration.RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result\n",
    "\n",
    "def refine_registration(source, target, voxel_size, trans_init):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "#     result = o3d.registration.registration_icp(\n",
    "#                 source, target, distance_threshold, trans_init,\n",
    "#                 o3d.registration.TransformationEstimationPointToPoint())\n",
    "    result = o3d.registration.registration_icp(\n",
    "                source, target, distance_threshold, trans_init,\n",
    "                o3d.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "\n",
    "def get_pose(source, target):\n",
    "    \n",
    "    source = filter_pcd(source)\n",
    "    \n",
    "    target = filter_pcd(target)\n",
    "\n",
    "    voxel_size = 0.2\n",
    "    source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(source, target, voxel_size)\n",
    "\n",
    "    result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                                source_fpfh, target_fpfh,\n",
    "                                                voxel_size)\n",
    "\n",
    "    result_icp = refine_registration(source, target, voxel_size, result_ransac.transformation)\n",
    "    return result_icp.transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:52.082472Z",
     "start_time": "2019-12-09T12:36:48.320044Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_mat = get_pose(prev_pcd, next_pcd)\n",
    "trans_vec, rot_mat, scale_mat, shear_mat = transforms3d.affines.decompose44(transform_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:52.088740Z",
     "start_time": "2019-12-09T12:36:52.084647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0074692 , 5.83964427, 0.0279323 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:52.094205Z",
     "start_time": "2019-12-09T12:36:52.090636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99995632, -0.00651476,  0.00670217],\n",
       "       [ 0.00647948,  0.99996511,  0.00527295],\n",
       "       [-0.00673628, -0.00522929,  0.99996364]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:52.099079Z",
     "start_time": "2019-12-09T12:36:52.096013Z"
    }
   },
   "outputs": [],
   "source": [
    "roll, pitch, yaw = transforms3d.euler.mat2euler(rot_mat, axes='sxyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:52.106541Z",
     "start_time": "2019-12-09T12:36:52.101053Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_registration_result(src, dst, transformation):\n",
    "    source = copy.deepcopy(src)\n",
    "    target = copy.deepcopy(dst)\n",
    "    \n",
    "    source.paint_uniform_color([1, 0, 0]) # red\n",
    "    target.paint_uniform_color([0, 0, 1]) # blue\n",
    "    source.transform(transformation)\n",
    "#     o3d.visualization.draw_geometries([source_temp, target_temp], width=1280, height=800)\n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(source)\n",
    "    visualizer.add_geometry(target)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T12:36:52.634331Z",
     "start_time": "2019-12-09T12:36:52.108497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488aeb5a3b5c4a8fbd98740ad5661667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 2 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_registration_result(prev_pcd, next_pcd, transform_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
