{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:27.278528Z",
     "start_time": "2020-06-04T23:24:26.670968Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import gc\n",
    "import zipfile\n",
    "# from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:27.283916Z",
     "start_time": "2020-06-04T23:24:27.280370Z"
    }
   },
   "outputs": [],
   "source": [
    "# pcd_folder='/home/sabyasachi/Projects/ati/data/data/datasets/Carla/lidarParam1/pair_corrupt/dynamic/'\n",
    "# npy_folder='/home/sabyasachi/Projects/ati/data/data/datasets/Carla/lidarParam1/pair_corrupt/dynamic_NPY/'\n",
    "\n",
    "# BASE_PATH = '/home/saby/Projects/ati/data/data/datasets/Carla/64beam-Data/dynamic'\n",
    "# STATIC_FOLDER = \"\"\n",
    "# PCD_FOLDER = \"_out\"\n",
    "# RANGE_IMAGE_HEIGHT = 64\n",
    "# RANGE_IMAGE_WIDTH = 1024\n",
    "# WITH_COLOR = False\n",
    "# CHOOSE_SUBFOLDER = True\n",
    "\n",
    "# BASE_PATH = '/home/saby/Projects/ati/data/data/datasets/KITTI/data_odometry_labels/dataset/'\n",
    "# STATIC_FOLDER = \"sequences\"\n",
    "# PCD_FOLDER = \"_segment\"\n",
    "# RANGE_IMAGE_HEIGHT = 64\n",
    "# RANGE_IMAGE_WIDTH = 1024\n",
    "# WITH_COLOR = True\n",
    "# CHOOSE_SUBFOLDER = True\n",
    "\n",
    "BASE_PATH = '/home/saby/Projects/ati/data/data/datasets/Real_World/dynamic'\n",
    "STATIC_FOLDER = \"\"\n",
    "PCD_FOLDER = \"_out\"\n",
    "RANGE_IMAGE_HEIGHT = 16\n",
    "RANGE_IMAGE_WIDTH = 1850\n",
    "WITH_COLOR = False\n",
    "CHOOSE_SUBFOLDER = True\n",
    "\n",
    "EXTRACTED_ARRAY_FNAME = \"arr_0.npy\"\n",
    "\n",
    "\n",
    "# BATCH_SIZE = 80000\n",
    "# BATCH_SIZE = 2048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing functions from the paper source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:27.310121Z",
     "start_time": "2020-06-04T23:24:27.285853Z"
    },
    "code_folding": [
     0,
     13,
     20,
     65,
     90,
     130
    ]
   },
   "outputs": [],
   "source": [
    "def get_quadrant(point):\n",
    "    if point[0] >= 0. and point[1] >= 0. :\n",
    "        return 0\n",
    "    elif point[0] <= 0. and point[1] >= 0. : \n",
    "        return 1\n",
    "    elif point[0] <= 0. and point[1] <= 0. : \n",
    "        return 2\n",
    "    elif point[0] >= 0. and point[1] <= 0. : \n",
    "        return 3\n",
    "    else :\n",
    "        raise Exception('invalid input %s', point) \n",
    "\n",
    "\n",
    "def passed_origin(x_t, x_t1):\n",
    "    if get_quadrant(x_t1) == 3 and get_quadrant(x_t) == 0: \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "\n",
    "def fit_quadrant(points, quadrant, desired_amt):\n",
    "    \n",
    "    \n",
    "    points = np.asarray(points)\n",
    "    slots = []\n",
    "    slot_size = np.pi / (2 * desired_amt)\n",
    "    for i in range(int(desired_amt)) : slots.append([])\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 :\n",
    "        points = points[::-1] \n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    for point in points :\n",
    "        angle = np.arctan(point[1] / (point[0]+0.000001))\n",
    "        index = min(int(angle / slot_size), desired_amt - 1)\n",
    "        slots[int(index)].append(point)\n",
    "\n",
    "    for i in range(len(slots)):\n",
    "        if len(slots[i]) == 0 : \n",
    "            slots[i] = np.array([0., 0., 0., 0.])\n",
    "        else :\n",
    "            full_slot = np.asarray(slots[i])\n",
    "            slots[i] = full_slot.mean(axis=0)\n",
    "\n",
    "    points = np.asarray(slots)\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 : \n",
    "        points = points[::-1]\n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    return points\n",
    "\n",
    "def parse_velo(velo):\n",
    "    # points closer to the origin (0,0,0) are at the end of the point cloud.\n",
    "    # invert the point cloud such that we begin near the origin. \n",
    "    \n",
    "    # returns: a H x 4 x ? array, split into quadrants\n",
    "    velo = velo[::-1]\n",
    "    lines = []\n",
    "    current_point = velo[0]\n",
    "    current_quadrant = get_quadrant(current_point)\n",
    "    current_line = [[], [], [], []]\n",
    "    quadrant_switches = 0\n",
    "    for point in velo :\n",
    "        point_quadrant = get_quadrant(point)\n",
    "        \n",
    "        if passed_origin(current_point, point):\n",
    "            lines.append(current_line)\n",
    "            current_line = [[], [], [], []]\n",
    "\n",
    "        current_line[point_quadrant].append(point)\n",
    "        current_quadrant = point_quadrant\n",
    "        current_point = point\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def setmatch(lines,lenLines):\n",
    "    arr=[[np.array([0,0,0,0]),np.array([0,0,0,0])]]\n",
    "    if len(lines) > lenLines:\n",
    "        return lines[:lenLines]\n",
    "    else:\n",
    "        for i in range(abs(len(lines)-lenLines)):\n",
    "            lines.append(arr)\n",
    "    return lines\n",
    "\n",
    "def process_velo(velo, points_per_layer, stop=False):\n",
    "    \n",
    "    lenLines=RANGE_IMAGE_HEIGHT\n",
    "    lines = parse_velo(velo)\n",
    "    inverse = quad_to_pc_inv(lines)\n",
    "#     lines = lines[2:-1]\n",
    "#     print(lines[])\n",
    "#     print((lines[0]))\n",
    "#     raise SystemError\n",
    "    if(len(lines)!=lenLines):\n",
    "        lines=setmatch(lines,lenLines)\n",
    "#     print(len(lines), flush=True)\n",
    "    if len(lines) != RANGE_IMAGE_HEIGHT : raise Exception('invalid nb un of lines')\n",
    "    out_tensor = np.zeros((RANGE_IMAGE_HEIGHT, points_per_layer, 4))\n",
    "    if stop:\n",
    "        import pdb; pdb.set_trace()\n",
    "        x = 1\n",
    "    for j in range(len(lines)):\n",
    "        line = lines[j]\n",
    "        out_line = np.zeros((points_per_layer, 4))\n",
    "        for i in range(len(line)):\n",
    "            if(len(line[i])==0):\n",
    "                line[i]=[np.array([0.0,0.0,0.0,0.0])]\n",
    "            gridded = fit_quadrant(line[i], i, points_per_layer / 4)\n",
    "            out_tensor[j][i*int(points_per_layer/4):(i+1)*int(points_per_layer/4), :] = gridded[::-1]\n",
    "\n",
    "    return out_tensor, inverse\n",
    "\n",
    "\n",
    "def quad_to_pc_inv(lines, th=3.):\n",
    "    # lines is a 63 x 4 array, where each slot has an array of 4d/3d points\n",
    "    # goal : get an array of points that fills empty spaces\n",
    "    points = []\n",
    "    for i in range(len(lines)) :\n",
    "        line = lines[i] \n",
    "        distance = []\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                distance.append(x**2 + y**2)\n",
    "        distance = np.array(distance)\n",
    "        std = distance.std()\n",
    "        sorted_indices = np.argsort(distance)\n",
    "        median_index = sorted_indices[int(sorted_indices.shape[0]*0.95)]\n",
    "        median = distance[median_index]\n",
    "\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                dist = x ** 2 + y ** 2 \n",
    "                if dist < median and (median/dist-1.) > th:#*std : \n",
    "                    # blocked point --> scale to get real pt\n",
    "                    scale = np.sqrt(median / dist)\n",
    "                    scaled = scale * point\n",
    "                    points.append(scaled)\n",
    "\n",
    "\n",
    "    return np.array(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:27.317117Z",
     "start_time": "2020-06-04T23:24:27.312789Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])\n",
    "\n",
    "# def getint(name):\n",
    "#     return int(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:27.327405Z",
     "start_time": "2020-06-04T23:24:27.318981Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_pcd2begin_npy(pcd_fname):\n",
    "    pcd_file_path = os.path.join(PCD_PATH, pcd_fname)\n",
    "    pcd = o3d.io.read_point_cloud(pcd_file_path)\n",
    "    pcd_arr = np.asarray(pcd.points)\n",
    "    if WITH_COLOR:\n",
    "        clr_arr = np.asarray(pcd.colors)[:,0].reshape(-1,1)\n",
    "        pcd_arr = np.append(pcd_arr, clr_arr, axis=1)\n",
    "    else:\n",
    "        pcd_arr = np.append(pcd_arr, np.zeros((pcd_arr.shape[0],1)), axis=1)\n",
    "    \n",
    "    npy_fname = pcd_fname[:-4] + \".npy\"\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_fname)\n",
    "    pcd_arr.dump(open(npy_file_path, 'wb'))\n",
    "    return pcd_arr.shape[0]\n",
    "\n",
    "def parallel_npy2processed(npy_file):\n",
    "    gc.collect()\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_file)\n",
    "    raw_lidar = np.load(npy_file_path, allow_pickle=True)\n",
    "    processed_lidar, _ = process_velo(raw_lidar, RANGE_IMAGE_WIDTH)\n",
    "    return processed_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCD to NPY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:44.675015Z",
     "start_time": "2020-06-04T23:24:27.329720Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saby/anaconda3/envs/ati/lib/python3.6/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb4313ccb964dc1b332103bc8d5b67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "for ijk in tqdm_notebook(range(100)):\n",
    "    if CHOOSE_SUBFOLDER:\n",
    "        sub_folder = np.random.choice(os.listdir(os.path.join(BASE_PATH, STATIC_FOLDER)))#, key=getint):\n",
    "    else:\n",
    "        sub_folder = \"\"\n",
    "    #     if int(sub_folder) > 10:\n",
    "    #         continue\n",
    "#     print(sub_folder)\n",
    "    ckp1 = time.time()\n",
    "#     print(\"in meta pre process\")\n",
    "    PCD_PATH = os.path.join(BASE_PATH, STATIC_FOLDER, sub_folder, PCD_FOLDER)\n",
    "    if not os.path.exists(PCD_PATH):\n",
    "#         print(\"Did not find : {}\".format(PCD_PATH))\n",
    "        continue\n",
    "\n",
    "    INITIAL_NPY_FOLDER = PCD_FOLDER + \"_begin_npy\"\n",
    "    INITIAL_NPY_PATH = os.path.join(BASE_PATH, STATIC_FOLDER, sub_folder, INITIAL_NPY_FOLDER)\n",
    "    if not os.path.exists(INITIAL_NPY_PATH):\n",
    "        os.makedirs(INITIAL_NPY_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(INITIAL_NPY_PATH)\n",
    "        os.makedirs(INITIAL_NPY_PATH)\n",
    "\n",
    "    NPZ_FOLDER = PCD_FOLDER + \"_npz\"\n",
    "    NPZ_PATH = os.path.join(BASE_PATH, STATIC_FOLDER, sub_folder, NPZ_FOLDER)\n",
    "    if not os.path.exists(NPZ_PATH):\n",
    "        os.makedirs(NPZ_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(NPZ_PATH)\n",
    "        os.makedirs(NPZ_PATH)\n",
    "\n",
    "    OUT_NPY_FOLDER = PCD_FOLDER + \"_out_npy\"\n",
    "    OUT_NPY_PATH = os.path.join(BASE_PATH, STATIC_FOLDER, sub_folder, OUT_NPY_FOLDER)\n",
    "    if not os.path.exists(OUT_NPY_PATH):\n",
    "        os.makedirs(OUT_NPY_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(OUT_NPY_PATH)\n",
    "        os.makedirs(OUT_NPY_PATH)\n",
    "\n",
    "    ckp2 = time.time()\n",
    "\n",
    "#     print(\"pcd 2 npy\")\n",
    "    this_arg = np.random.choice(os.listdir(PCD_PATH))\n",
    "#     print(this_arg)\n",
    "    n_ip_pts = parallel_pcd2begin_npy(this_arg)\n",
    "    gc.collect()\n",
    "\n",
    "    ckp3 = time.time()\n",
    "\n",
    "#     print(\"npy 2 npz\")\n",
    "    file_list = os.listdir(INITIAL_NPY_PATH)\n",
    "    one_run_npy_file = [parallel_npy2processed(file_list[0])]\n",
    "    gc.collect()\n",
    "    npz_file_idx = 0\n",
    "    npz_file_path = os.path.join(NPZ_PATH, str(npz_file_idx))\n",
    "    np.savez(npz_file_path, one_run_npy_file)\n",
    "\n",
    "    ckp4 = time.time()\n",
    "\n",
    "#     print(\"npz 2 npy\")\n",
    "    npz_fname = os.listdir(NPZ_PATH)[0]\n",
    "    npz_path = os.path.join(NPZ_PATH, npz_fname)\n",
    "    with zipfile.ZipFile(npz_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(OUT_NPY_PATH)\n",
    "    out_npy_fname = npz_fname[:-4] + \".npy\"\n",
    "    src_fname = os.path.join(OUT_NPY_PATH, EXTRACTED_ARRAY_FNAME)\n",
    "    dst_fname = os.path.join(OUT_NPY_PATH, out_npy_fname)\n",
    "    os.rename(src_fname, dst_fname)\n",
    "\n",
    "    ckp5 = time.time()\n",
    "\n",
    "#     print(\"post process\")\n",
    "    shutil.rmtree(INITIAL_NPY_PATH)\n",
    "    shutil.rmtree(NPZ_PATH)\n",
    "    ckp6 = time.time()\n",
    "\n",
    "    time_list.append({\"pcd2npy_begin\":ckp3-ckp2, \"npy2npz_main_\":ckp4-ckp3, \"npz2npy_final\":ckp5-ckp4, \"total________\":ckp5-ckp2, \"n_input_pts__\":n_ip_pts})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T23:24:44.711143Z",
     "start_time": "2020-06-04T23:24:44.676519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcd2npy_begin</th>\n",
       "      <th>npy2npz_main_</th>\n",
       "      <th>npz2npy_final</th>\n",
       "      <th>total________</th>\n",
       "      <th>n_input_pts__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.063546</td>\n",
       "      <td>0.106278</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.170615</td>\n",
       "      <td>27674.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>142.728085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.054494</td>\n",
       "      <td>0.104049</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.160511</td>\n",
       "      <td>27383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.060417</td>\n",
       "      <td>0.105468</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.167739</td>\n",
       "      <td>27576.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.062753</td>\n",
       "      <td>0.105947</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.169241</td>\n",
       "      <td>27679.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.106619</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.173221</td>\n",
       "      <td>27761.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.082864</td>\n",
       "      <td>0.113348</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.197407</td>\n",
       "      <td>28023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pcd2npy_begin  npy2npz_main_  npz2npy_final  total________  \\\n",
       "count     100.000000     100.000000     100.000000     100.000000   \n",
       "mean        0.063546       0.106278       0.000792       0.170615   \n",
       "std         0.005035       0.001423       0.000045       0.006008   \n",
       "min         0.054494       0.104049       0.000766       0.160511   \n",
       "25%         0.060417       0.105468       0.000772       0.167739   \n",
       "50%         0.062753       0.105947       0.000784       0.169241   \n",
       "75%         0.065809       0.106619       0.000795       0.173221   \n",
       "max         0.082864       0.113348       0.001195       0.197407   \n",
       "\n",
       "       n_input_pts__  \n",
       "count     100.000000  \n",
       "mean    27674.130000  \n",
       "std       142.728085  \n",
       "min     27383.000000  \n",
       "25%     27576.000000  \n",
       "50%     27679.500000  \n",
       "75%     27761.750000  \n",
       "max     28023.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(time_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T15:22:15.155831Z",
     "start_time": "2020-02-21T15:22:12.891756Z"
    }
   },
   "source": [
    "DST_FOLDER = STATIC_FOLDER + \"_training_data\"\n",
    "DATA_FOLDER = \"npy_data\"\n",
    "\n",
    "DST_DATA_FOLDER_PATH = os.path.join(BASE_PATH, DST_FOLDER, DATA_FOLDER)\n",
    "if not os.path.exists(DST_DATA_FOLDER_PATH):\n",
    "    os.makedirs(DST_DATA_FOLDER_PATH)\n",
    "else:\n",
    "    shutil.rmtree(DST_DATA_FOLDER_PATH)\n",
    "    os.makedirs(DST_DATA_FOLDER_PATH)\n",
    "\n",
    "for sub_folder in tqdm_notebook(sorted(os.listdir(os.path.join(BASE_PATH, STATIC_FOLDER)), key=getint)):\n",
    "#     print(\"Sub folder: {}\".format(sub_folder))\n",
    "    OUT_NPY_FOLDER = PCD_FOLDER + \"_out_npy\"\n",
    "    \n",
    "    extracted_file = \"0.npy\"\n",
    "    extracted_file_path = os.path.join(BASE_PATH, STATIC_FOLDER, sub_folder, OUT_NPY_FOLDER, extracted_file)\n",
    "    if not os.path.exists(extracted_file_path):\n",
    "        print(\"Did not find : {}\".format(extracted_file_path))\n",
    "        \n",
    "    dst_file_name = sub_folder + \".npy\"\n",
    "    dst_file_path = os.path.join(DST_DATA_FOLDER_PATH, dst_file_name)\n",
    "    shutil.copy(extracted_file_path, dst_file_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T12:36:50.298051Z",
     "start_time": "2019-12-20T12:36:50.063113Z"
    }
   },
   "source": [
    "GT_FILE = \"groundTruth.csv\"\n",
    "GT_FOLDER = \"gt\"\n",
    "\n",
    "DST_GT_FOLDER_PATH = os.path.join(BASE_PATH, DST_FOLDER, GT_FOLDER)\n",
    "if not os.path.exists(DST_GT_FOLDER_PATH):\n",
    "    os.makedirs(DST_GT_FOLDER_PATH)\n",
    "else:\n",
    "    shutil.rmtree(DST_GT_FOLDER_PATH)\n",
    "    os.makedirs(DST_GT_FOLDER_PATH)\n",
    "    \n",
    "for sub_folder in tqdm_notebook(sorted(os.listdir(os.path.join(BASE_PATH, STATIC_FOLDER)), key=getint)):\n",
    "#     print(\"Sub folder: {}\".format(sub_folder))\n",
    "    \n",
    "    gt_file_path = os.path.join(BASE_PATH, STATIC_FOLDER, sub_folder, GT_FILE)\n",
    "    if not os.path.exists(gt_file_path):\n",
    "        print(\"Did not find : {}\".format(extracted_file_path))\n",
    "        \n",
    "    dst_file_name = sub_folder + \"_gt.csv\"\n",
    "    dst_file_path = os.path.join(DST_GT_FOLDER_PATH, dst_file_name)\n",
    "    shutil.copy(gt_file_path, dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
