{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:44.259209Z",
     "start_time": "2020-02-28T08:44:43.351551Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "# from utils import * \n",
    "from utils import *\n",
    "import open3d as o3d\n",
    "from models import *\n",
    "from collections import OrderedDict\n",
    "import os, shutil, gc\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:44.266893Z",
     "start_time": "2020-02-28T08:44:44.261240Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:44.277968Z",
     "start_time": "2020-02-28T08:44:44.268362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--debug'], dest='debug', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='VAE training of LiDAR')\n",
    "parser.add_argument('--batch_size',         type=int,   default=16,             help='size of minibatch used during training')\n",
    "parser.add_argument('--use_selu',           type=int,   default=0,              help='replaces batch_norm + act with SELU')\n",
    "parser.add_argument('--base_dir',           type=str,   default='runs/test',    help='root of experiment directory')\n",
    "parser.add_argument('--no_polar',           type=int,   default=0,              help='if True, the representation used is (X,Y,Z), instead of (D, Z), where D=sqrt(X^2+Y^2)')\n",
    "parser.add_argument('--lr',                 type=float, default=1e-3,           help='learning rate value')\n",
    "parser.add_argument('--z_dim',              type=int,   default=1024,            help='size of the bottleneck dimension in the VAE, or the latent noise size in GAN')\n",
    "parser.add_argument('--autoencoder',        type=int,   default=1,              help='if True, we do not enforce the KL regularization cost in the VAE')\n",
    "parser.add_argument('--atlas_baseline',     type=int,   default=0,              help='If true, Atlas model used. Also determines the number of primitives used in the model')\n",
    "parser.add_argument('--panos_baseline',     type=int,   default=0,              help='If True, Model by Panos Achlioptas used')\n",
    "parser.add_argument('--kl_warmup_epochs',   type=int,   default=150,            help='number of epochs before fully enforcing the KL loss')\n",
    "parser.add_argument('--debug', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:44.282768Z",
     "start_time": "2020-02-28T08:44:44.279307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(atlas_baseline=0, autoencoder=1, base_dir='runs/test', batch_size=16, debug=False, kl_warmup_epochs=150, lr=0.001, no_polar=0, panos_baseline=0, use_selu=0, z_dim=1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:44.286146Z",
     "start_time": "2020-02-28T08:44:44.284015Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = \"/home/saby/Projects/ati/ati_motors/adversarial_based/static_reconstruction_method/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:46.620510Z",
     "start_time": "2020-02-28T08:44:44.287566Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_FOLDER_NAME = \"learning_to_filter_64beam_64f\"\n",
    "MODEL_FILE_NAME = \"gen_62.pth\"\n",
    "model = Unet_filtered(args, n_filters=64).cuda()\n",
    "LEARN_TO_FILTER = True\n",
    "MODEL_USED_DATA_PARALLEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:46.625902Z",
     "start_time": "2020-02-28T08:44:46.623652Z"
    }
   },
   "outputs": [],
   "source": [
    "LIDAR_RANGE = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:46.658242Z",
     "start_time": "2020-02-28T08:44:46.627491Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TEST_PATH = os.path.join(MODEL_BASE_PATH, MODEL_FOLDER_NAME, 'models', MODEL_FILE_NAME)\n",
    "if not os.path.exists(MODEL_TEST_PATH):\n",
    "    print(\"No Model file found at : {}\".format(MODEL_TEST_PATH))\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:46.891969Z",
     "start_time": "2020-02-28T08:44:46.660300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/saby/Projects/ati/ati_motors/adversarial_based/static_reconstruction_method/learning_to_filter_64beam_64f/models/gen_62.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unet_filtered(\n",
       "  (unet): Unet(\n",
       "    (encoder_conv1): Doubleconv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_down1): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down2): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down3): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down4): DownBlock(\n",
       "      (down_double_conv): Sequential(\n",
       "        (0): Down(\n",
       "          (down): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Doubleconv(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "            (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_down5): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (decoder_up1): Sequential(\n",
       "      (0): ConvTranspose2d(2048, 1024, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (decoder_conv3): Doubleconv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_up2): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(1024, 512, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_up3): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(512, 256, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_up4): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(256, 128, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_up5): UpBlock(\n",
       "      (up): Up(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(128, 64, kernel_size=(4, 6), stride=(2, 4), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv): Doubleconv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Out(\n",
       "      (out): Sequential(\n",
       "        (0): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(68, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "print(\"Loading model from {}\".format(MODEL_TEST_PATH))\n",
    "network=torch.load(MODEL_TEST_PATH)\n",
    "\n",
    "if MODEL_USED_DATA_PARALLEL:\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = network\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    model.load_state_dict(network)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:46.901930Z",
     "start_time": "2020-02-28T08:44:46.893336Z"
    }
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])\n",
    "    \n",
    "def draw_pcd(pcd, where='opn_nb'):\n",
    "    if where is 'opn_nb':\n",
    "        visualizer = o3d.JVisualizer()\n",
    "        visualizer.add_geometry(pcd)\n",
    "        visualizer.show()\n",
    "    elif where is 'opn_view':\n",
    "        o3d.visualization.draw_geometries([pcd], width=1280, height=800)\n",
    "    elif where is 'mat_3d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1], pts[:,2])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    elif where is 'mat_2d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "def draw_registration_result(src_pcd, dst_pcd, x_pt, y_pt, theta):    \n",
    "    src_pcd_tmp = copy.deepcopy(src_pcd)\n",
    "    dst_pcd_tmp = copy.deepcopy(dst_pcd)\n",
    "    \n",
    "    src_pcd_tmp.paint_uniform_color([1, 0, 0])  # red source\n",
    "    dst_pcd_tmp.paint_uniform_color([0, 0, 1])  # blue target\n",
    "    \n",
    "    transform_mat = pose2matrix([x_pt, y_pt, 0], [0,0,theta])\n",
    "    dst_pcd_tmp.transform(transform_mat)\n",
    "    \n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(src_pcd_tmp)\n",
    "    visualizer.add_geometry(dst_pcd_tmp)\n",
    "    visualizer.show()\n",
    "    \n",
    "process_input = from_polar if args.no_polar else lambda x : x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:46.907849Z",
     "start_time": "2020-02-28T08:44:46.903542Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_dynamic_recon(dynamic, recon, mask):\n",
    "    # Assuming channel 1 to be dynamic\n",
    "    # if channel 1 rounds to 0 (static) then take points from dynamic (because these are static points in dynamic frame)\n",
    "    # else if channel 1 rounds to 1 (dynamic) then take points from reconstructed static (because these are dynamic points in dynamic frame)\n",
    "    shape_tuple = (mask.shape[0], 1, mask.shape[2], mask.shape[3])\n",
    "    bin_mask_orig = mask[:,1].round().view(shape_tuple)\n",
    "    bin_mask = torch.cat([bin_mask_orig, bin_mask_orig], axis=1)\n",
    "\n",
    "    new_recon = (dynamic * (1-bin_mask)) + (bin_mask * recon)\n",
    "    new_dynamic = dynamic * (1-bin_mask)\n",
    "    return new_recon, bin_mask_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:47.753504Z",
     "start_time": "2020-02-28T08:44:46.909228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1762, 2, 64, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_NPY_PATH = \"../training_data/small_map/64beam/dynamic_prepreprocess_dir/3.npy\"\n",
    "with open(TEST_NPY_PATH, 'rb') as pkl_file:\n",
    "        test_arr = pickle.load(pkl_file)\n",
    "\n",
    "test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:47.757809Z",
     "start_time": "2020-02-28T08:44:47.755103Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_arr, batch_size=args.batch_size,\n",
    "                            shuffle=False, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:49.223197Z",
     "start_time": "2020-02-28T08:44:47.759103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saby/anaconda3/envs/ati/lib/python3.6/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328c0bdf326b4d76a9ea447cadcd0a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=111.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, img_data in tqdm_notebook(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    if i != 0:\n",
    "        continue\n",
    "    dynamic_img = img_data.cuda()\n",
    "\n",
    "    recon, xmask = model(process_input(dynamic_img))\n",
    "    masked_recon, bin_mask = masked_dynamic_recon(dynamic_img, recon, xmask)\n",
    "    recon=masked_recon\n",
    "\n",
    "    recons=recon\n",
    "    recons_temp=np.array(recons.detach().cpu())\n",
    "\n",
    "    ###### Save all pcds\n",
    "#     for frame_num in range(recons_temp.shape[0]):\n",
    "#         frame = from_polar(recons[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "#         frame_actual = np.array([frame_image for frame_image in frame])\n",
    "#         frame_flat = frame_actual.reshape((3,-1))\n",
    "#         frame_crop = frame_flat#[:,(frame_flat[2]  > 0.005)]\n",
    "#         some_pcd = o3d.geometry.PointCloud()\n",
    "#         some_arr = frame_crop.T * LIDAR_RANGE\n",
    "#         some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "#         pcd_fname = str(ply_idx) + \".ply\"\n",
    "#         single_pcd_path = os.path.join(OUTPUT_PCD_FOLDER_PATH, pcd_fname)\n",
    "#         o3d.io.write_point_cloud(single_pcd_path, some_pcd)\n",
    "#         ply_idx += 1\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:49.233050Z",
     "start_time": "2020-02-28T08:44:49.225116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 65536)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_num = 10\n",
    "frame = from_polar(dynamic_img[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "frame_actual = np.array([frame_image for frame_image in frame])\n",
    "frame_flat = frame_actual.reshape((3,-1))\n",
    "frame_crop = frame_flat#[:,(frame_flat[2]  > 0.005)]\n",
    "frame_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:49.237900Z",
     "start_time": "2020-02-28T08:44:49.234322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 1024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = bin_mask.detach().cpu().numpy()[0]\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:49.243939Z",
     "start_time": "2020-02-28T08:44:49.239547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65536, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_arr = np.concatenate((mask, np.zeros(mask.shape), np.zeros(mask.shape)), axis=0).reshape((3,-1)).T\n",
    "color_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:49.315337Z",
     "start_time": "2020-02-28T08:44:49.245328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry::PointCloud with 65536 points."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_pcd = o3d.geometry.PointCloud()\n",
    "some_arr = frame_crop.T * LIDAR_RANGE\n",
    "some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "some_pcd.colors = o3d.utility.Vector3dVector(color_arr)\n",
    "some_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:44:50.649704Z",
     "start_time": "2020-02-28T08:44:49.316546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65a6c96e2414c888cc164b9ac769306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_pcd(some_pcd, where='opn_nb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
