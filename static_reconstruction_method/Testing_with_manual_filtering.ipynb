{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:10:30.382443Z",
     "start_time": "2020-02-17T07:10:30.376163Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import * \n",
    "from utils import *\n",
    "import open3d as o3d\n",
    "from models import *\n",
    "from collections import OrderedDict\n",
    "import os, shutil, gc\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:44:30.550638Z",
     "start_time": "2020-02-17T06:44:30.541692Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:44:31.292618Z",
     "start_time": "2020-02-17T06:44:31.275589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--debug'], dest='debug', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='VAE training of LiDAR')\n",
    "parser.add_argument('--batch_size',         type=int,   default=4,             help='size of minibatch used during training')\n",
    "parser.add_argument('--use_selu',           type=int,   default=0,              help='replaces batch_norm + act with SELU')\n",
    "parser.add_argument('--base_dir',           type=str,   default='runs/test',    help='root of experiment directory')\n",
    "parser.add_argument('--no_polar',           type=int,   default=0,              help='if True, the representation used is (X,Y,Z), instead of (D, Z), where D=sqrt(X^2+Y^2)')\n",
    "parser.add_argument('--lr',                 type=float, default=1e-3,           help='learning rate value')\n",
    "parser.add_argument('--z_dim',              type=int,   default=1024,            help='size of the bottleneck dimension in the VAE, or the latent noise size in GAN')\n",
    "parser.add_argument('--autoencoder',        type=int,   default=1,              help='if True, we do not enforce the KL regularization cost in the VAE')\n",
    "parser.add_argument('--atlas_baseline',     type=int,   default=0,              help='If true, Atlas model used. Also determines the number of primitives used in the model')\n",
    "parser.add_argument('--panos_baseline',     type=int,   default=0,              help='If True, Model by Panos Achlioptas used')\n",
    "parser.add_argument('--kl_warmup_epochs',   type=int,   default=150,            help='number of epochs before fully enforcing the KL loss')\n",
    "parser.add_argument('--debug', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:44:33.440950Z",
     "start_time": "2020-02-17T06:44:33.435796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(atlas_baseline=0, autoencoder=1, base_dir='runs/test', batch_size=4, debug=False, kl_warmup_epochs=150, lr=0.001, no_polar=0, panos_baseline=0, use_selu=0, z_dim=1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:32.531090Z",
     "start_time": "2020-02-17T06:45:32.527902Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = \"/home/saby/Projects/ati/ati_motors/adversarial_based/trained_models/development_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:33.394860Z",
     "start_time": "2020-02-17T06:45:32.932354Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL_FOLDER_NAME = \"second_attempt_triple_data_restarted_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_150.pth\"\n",
    "# model = VAE(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = False\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_filtered_32f_triple_data_restarted_again2_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_245.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_filtered_64f_triple_data_restarted_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_105.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_ground_weighted_filtered_64f_triple_data_continued_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_260.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fourth_attempt_ground_weighted_filtered_polar_new_unet_64f_2048\"\n",
    "# MODEL_FILE_NAME = \"gen_300.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_no_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_498.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_sem_ground_weighted_filtered_polar_old_unet_32f_1024_continued\"\n",
    "# MODEL_FILE_NAME = \"gen_145.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "MODEL_FOLDER_NAME = \"fifth_attempt_slam_weighted_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "MODEL_FILE_NAME = \"gen_115.pth\"\n",
    "model = VAE_filtered(args, n_filters=32).cuda()\n",
    "LEARN_TO_FILTER = True\n",
    "MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_inpainting_weighted_no_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_280.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"\"\n",
    "# MODEL_FILE_NAME = \"gen_.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:33.401244Z",
     "start_time": "2020-02-17T06:45:33.397035Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TEST_PATH = os.path.join(MODEL_BASE_PATH, MODEL_FOLDER_NAME, 'models', MODEL_FILE_NAME)\n",
    "if not os.path.exists(MODEL_TEST_PATH):\n",
    "    print(\"No Model file found at : {}\".format(MODEL_TEST_PATH))\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:36.428171Z",
     "start_time": "2020-02-17T06:45:35.367709Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/saby/Projects/ati/ati_motors/adversarial_based/trained_models/development_runs/fifth_attempt_slam_weighted_sem_ground_weighted_filtered_polar_old_unet_32f_1024/models/gen_115.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE_filtered(\n",
       "  (unet): VAE(\n",
       "    (encoder_conv2d_a): Sequential(\n",
       "      (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_b): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_A): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_B): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_1): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_2): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_c): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_d): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_C): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_D): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_batchnorm2d_4): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (encoder_leakyrelu_5): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_e): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_f): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_E): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_F): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_6): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_batchnorm2d_7): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (encoder_leakyrelu_8): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_g): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_h): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_G): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_leakyrelu_H): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_9): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (encoder_batchnorm2d_10): Sequential(\n",
       "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (encoder_leakyrelu_11): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (encoder_conv2d_12): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 64), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_convtranspose2d_13): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 256, kernel_size=(1, 64), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_batchnorm2d_14): Sequential(\n",
       "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (decoder_relu_15): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_i): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_j): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_convtranspose2d_16): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_batchnorm2d_17): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (decoder_relu_18): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_k): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_l): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_K): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_L): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_convtranspose2d_19): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_batchnorm2d_20): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (decoder_relu_21): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_m): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_n): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_M): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_N): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_convtranspose2d_22): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_batchnorm2d_23): Sequential(\n",
       "      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (decoder_relu_24): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_o): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_p): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_O): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_P): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_convtranspose2d_25): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_26): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_q): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (decoder_relu_R): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "    )\n",
       "    (decoder_conv2d_Q): Sequential(\n",
       "      (0): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (tanh_27): Sequential(\n",
       "      (0): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(36, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "print(\"Loading model from {}\".format(MODEL_TEST_PATH))\n",
    "network=torch.load(MODEL_TEST_PATH)\n",
    "\n",
    "if MODEL_USED_DATA_PARALLEL:\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = network\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    model.load_state_dict(network)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T07:49:43.545790Z",
     "start_time": "2020-02-13T07:49:43.541412Z"
    }
   },
   "source": [
    "### Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:39.646908Z",
     "start_time": "2020-02-17T06:45:39.642547Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = \"/home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing\"\n",
    "DATA_TEST_FOLDER_LIST = [\"8\", \"24\", \"48\"]\n",
    "FILTER_THRESHOLD_LIST = [0.1, 0.5, 1, 2]\n",
    "SAVE_PCD_NPY = False\n",
    "TEST_NPY_FOLDER = \"_out_out_npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:40.881331Z",
     "start_time": "2020-02-17T06:45:40.878103Z"
    }
   },
   "outputs": [],
   "source": [
    "LIDAR_RANGE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:45.292785Z",
     "start_time": "2020-02-17T06:45:45.277474Z"
    }
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])\n",
    "    \n",
    "def draw_pcd(pcd, where='opn_nb'):\n",
    "    if where is 'opn_nb':\n",
    "        visualizer = o3d.JVisualizer()\n",
    "        visualizer.add_geometry(pcd)\n",
    "        visualizer.show()\n",
    "    elif where is 'opn_view':\n",
    "        o3d.visualization.draw_geometries([pcd], width=1280, height=800)\n",
    "    elif where is 'mat_3d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1], pts[:,2])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    elif where is 'mat_2d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "def draw_registration_result(src_pcd, dst_pcd, x_pt, y_pt, theta):    \n",
    "    src_pcd_tmp = copy.deepcopy(src_pcd)\n",
    "    dst_pcd_tmp = copy.deepcopy(dst_pcd)\n",
    "    \n",
    "    src_pcd_tmp.paint_uniform_color([1, 0, 0])  # red source\n",
    "    dst_pcd_tmp.paint_uniform_color([0, 0, 1])  # blue target\n",
    "    \n",
    "    transform_mat = pose2matrix([x_pt, y_pt, 0], [0,0,theta])\n",
    "    dst_pcd_tmp.transform(transform_mat)\n",
    "    \n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(src_pcd_tmp)\n",
    "    visualizer.add_geometry(dst_pcd_tmp)\n",
    "    visualizer.show()\n",
    "    \n",
    "process_input = from_polar if args.no_polar else lambda x : x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:45:47.421631Z",
     "start_time": "2020-02-17T06:45:47.408752Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_dynamic_recon(dynamic, recon, mask):\n",
    "    # bin_mask = (mask[:,0] - mask[:,1]).round().view((mask.shape[0], 1, mask.shape[2], mask.shape[3]))\n",
    "    bin_mask = mask[:,1].round().view((mask.shape[0], 1, mask.shape[2], mask.shape[3]))\n",
    "    masked_dynamic = (dynamic * (1-mask))\n",
    "    masked_recon = (dynamic * (1-mask)) + (mask * recon)\n",
    "    return masked_dynamic, masked_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T12:32:23.313323Z",
     "start_time": "2020-02-16T12:27:38.520491Z"
    }
   },
   "outputs": [],
   "source": [
    "for DATA_TEST_FOLDER in DATA_TEST_FOLDER_LIST:\n",
    "    print(\"\\n\\n\\n    Test folder : {}\".format(DATA_TEST_FOLDER))\n",
    "    for FILTER_THRESHOLD in FILTER_THRESHOLD_LIST:\n",
    "        print(\"Filter threshold : {}\".format())\n",
    "        ######## Set paths\n",
    "        OUTPUT_PCD_FOLDER = MODEL_FOLDER_NAME + \"_\" + MODEL_FILE_NAME.split(\".\")[0] + \"_pcd\" + \"_manual_filtered_\" + str(FILTER_THRESHOLD)\n",
    "        if SAVE_PCD_NPY:\n",
    "            OUTPUT_NPY_FOLDER = OUTPUT_PCD_FOLDER + \"_out_npy\"\n",
    "\n",
    "        TEST_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, TEST_NPY_FOLDER)\n",
    "        OUTPUT_PCD_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, OUTPUT_PCD_FOLDER)\n",
    "        if SAVE_PCD_NPY:\n",
    "            OUTPUT_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, OUTPUT_NPY_FOLDER)\n",
    "\n",
    "        test_files  = sorted(os.listdir(TEST_NPY_FOLDER_PATH), key=getint)\n",
    "\n",
    "        if not os.path.exists(OUTPUT_PCD_FOLDER_PATH):\n",
    "            os.makedirs(OUTPUT_PCD_FOLDER_PATH)\n",
    "        else:\n",
    "            shutil.rmtree(OUTPUT_PCD_FOLDER_PATH)\n",
    "            os.makedirs(OUTPUT_PCD_FOLDER_PATH)\n",
    "\n",
    "        if SAVE_PCD_NPY:\n",
    "            if not os.path.exists(OUTPUT_NPY_FOLDER_PATH):\n",
    "                os.makedirs(OUTPUT_NPY_FOLDER_PATH)\n",
    "            else:\n",
    "                shutil.rmtree(OUTPUT_NPY_FOLDER_PATH)\n",
    "                os.makedirs(OUTPUT_NPY_FOLDER_PATH)\n",
    "\n",
    "        ply_idx = 1\n",
    "        if SAVE_PCD_NPY:\n",
    "            npy_idx = 0\n",
    "        \n",
    "        recon_flag = 0.0\n",
    "        total_flag = 0.0\n",
    "        for test_file in test_files:\n",
    "            ###### Load corresponding dataset batch\n",
    "            print(\"processing {}\".format(test_file))\n",
    "            dataset_val = np.load(os.path.join(TEST_NPY_FOLDER_PATH, test_file))\n",
    "            dataset_val = preprocess(dataset_val, LIDAR_RANGE)\n",
    "            dataset_val = dataset_val.astype('float32')\n",
    "            val_loader  = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size,\n",
    "                                shuffle=False, num_workers=12, drop_last=False)\n",
    "\n",
    "            print(\"done\")\n",
    "            print(\"Saving pcds to {}\".format(OUTPUT_PCD_FOLDER_PATH))\n",
    "            recons=[]\n",
    "            total_recon = []\n",
    "            ##### For all batches of data\n",
    "            for i, img_data in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):\n",
    "                dynamic_img = img_data.cuda()\n",
    "\n",
    "                if LEARN_TO_FILTER:\n",
    "                    recon, xmask = model(process_input(dynamic_img))\n",
    "                    masked_dynamic, masked_recon = masked_dynamic_recon(dynamic_img, recon, xmask)\n",
    "                    recon=masked_recon\n",
    "                else:\n",
    "                    recon = model(process_input(dynamic_img))\n",
    "\n",
    "                recons=recon\n",
    "                recons_temp=np.array(recons.detach().cpu())\n",
    "\n",
    "                ###### Save all pcds\n",
    "                if SAVE_PCD_NPY:\n",
    "                    filtered_mask_arr_list = []\n",
    "                for frame_num in range(recons_temp.shape[0]):\n",
    "                    frame = from_polar(recons[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "                    dynamic_frame = from_polar(dynamic_img[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "\n",
    "                    frame = frame * LIDAR_RANGE\n",
    "                    dynamic_frame = dynamic_frame * LIDAR_RANGE\n",
    "\n",
    "                    filtered_arr = np.zeros((frame.shape))\n",
    "                    filtered_mask_arr = np.zeros((1,frame.shape[1],frame.shape[2]))\n",
    "                    for i in range(frame.shape[1]):\n",
    "                        for j in range(frame.shape[2]):\n",
    "                            dist = np.linalg.norm(frame[:,i,j] - dynamic_frame[:,i,j])\n",
    "                            if dist > FILTER_THRESHOLD:\n",
    "                                filtered_arr[:,i,j] = frame[:,i,j]\n",
    "                                filtered_mask_arr[:,i,j] = 1\n",
    "                                recon_flag += 1\n",
    "                            else:\n",
    "                                filtered_arr[:,i,j] = dynamic_frame[:,i,j]\n",
    "                                filtered_mask_arr[:,i,j] = 0\n",
    "                            total_flag += 1\n",
    "                    if SAVE_PCD_NPY:\n",
    "                        filtered_mask_arr_list.append(filtered_mask_arr)\n",
    "\n",
    "                    some_pcd = o3d.geometry.PointCloud()\n",
    "                    some_arr = filtered_arr.reshape((3,-1)).T\n",
    "                    some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "                    shape_tuple = filtered_mask_arr.shape\n",
    "                    color_arr = np.concatenate((filtered_mask_arr, np.zeros(shape_tuple), np.zeros(shape_tuple)), axis=0)\n",
    "                    some_pcd.colors = o3d.utility.Vector3dVector(color_arr.reshape((3,-1)).T)\n",
    "                    pcd_fname = str(ply_idx) + \".ply\"\n",
    "                    single_pcd_path = os.path.join(OUTPUT_PCD_FOLDER_PATH, pcd_fname)\n",
    "                    o3d.io.write_point_cloud(single_pcd_path, some_pcd)\n",
    "                    ply_idx += 1\n",
    "                gc.collect()\n",
    "\n",
    "                ##### Append model outputs array\n",
    "                if SAVE_PCD_NPY:\n",
    "                    recon_arr = from_polar(recon).detach().cpu().numpy()\n",
    "                    # add color mask as zeros for now\n",
    "#                     if LEARN_TO_FILTER:\n",
    "#                         bin_mask = xmask[:,0].round().view((xmask.shape[0], 1, xmask.shape[2], xmask.shape[3]))\n",
    "#                         bin_mask = bin_mask.detach().cpu().numpy()\n",
    "#                         color_arr = bin_mask\n",
    "#                     else:\n",
    "#                         color_arr = np.zeros((recon_arr.shape[0], 1, recon_arr.shape[2], recon_arr.shape[3]))\n",
    "                    color_arr = np.array(filtered_mask_arr_list)\n",
    "\n",
    "                    recon_arr_4d = np.concatenate((recon_arr, color_arr), axis=1)\n",
    "                    if i == 0:\n",
    "                        total_recon = recon_arr_4d\n",
    "                    else:\n",
    "                        total_recon = np.concatenate((total_recon, recon_arr_4d), axis=0)\n",
    "                    gc.collect()\n",
    "            print(\"done\")\n",
    "\n",
    "            ##### Save model outputs array npy if necessary\n",
    "            if SAVE_PCD_NPY:\n",
    "                total_recon = total_recon.transpose(0,2,3,1)\n",
    "                npy_name = str(npy_idx) + \".npy\"\n",
    "                npy_path = os.path.join(OUTPUT_NPY_FOLDER_PATH, npy_name)\n",
    "                print(\"Saving to {}\".format(npy_path))\n",
    "                np.save(npy_path, total_recon)\n",
    "                npy_idx += 1\n",
    "                print(\"done\")\n",
    "        print(\"For threshold {} - Fraction of reconstructed points : {}\".format(FILTER_THRESHOLD, recon_flag / total_flag))\n",
    "    print(\"Done for all filters for folder {}\".format(DATA_TEST_FOLDER))\n",
    "print(\"Done for all folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:51:58.062195Z",
     "start_time": "2020-02-17T06:51:58.058525Z"
    }
   },
   "source": [
    "TEST_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, \"8\", TEST_NPY_FOLDER)\n",
    "test_file = os.listdir(TEST_NPY_FOLDER_PATH)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:53:05.198376Z",
     "start_time": "2020-02-17T06:51:58.945066Z"
    }
   },
   "source": [
    "print(\"processing {}\".format(test_file))\n",
    "dataset_val = np.load(os.path.join(TEST_NPY_FOLDER_PATH, test_file))\n",
    "dataset_val = preprocess(dataset_val, LIDAR_RANGE)\n",
    "dataset_val = dataset_val.astype('float32')\n",
    "val_loader  = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size,\n",
    "                    shuffle=False, num_workers=12, drop_last=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:58:47.422411Z",
     "start_time": "2020-02-17T06:58:46.537628Z"
    }
   },
   "source": [
    "img_data = list(val_loader)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:59:08.258494Z",
     "start_time": "2020-02-17T06:59:07.037998Z"
    }
   },
   "source": [
    "dynamic_img = img_data.cuda()\n",
    "\n",
    "if LEARN_TO_FILTER:\n",
    "    recon, xmask = model(process_input(dynamic_img))\n",
    "    masked_dynamic, masked_recon = masked_dynamic_recon(dynamic_img, recon, xmask)\n",
    "    recon=masked_recon\n",
    "else:\n",
    "    recon = model(process_input(dynamic_img))\n",
    "\n",
    "recons=recon\n",
    "recons_temp=np.array(recons.detach().cpu())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:59:49.904079Z",
     "start_time": "2020-02-17T06:59:49.879534Z"
    }
   },
   "source": [
    "frame_num = 0\n",
    "frame = from_polar(recons[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "dynamic_frame = from_polar(dynamic_img[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "\n",
    "frame = frame * LIDAR_RANGE\n",
    "dynamic_frame = dynamic_frame * LIDAR_RANGE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T06:59:53.071601Z",
     "start_time": "2020-02-17T06:59:53.066658Z"
    }
   },
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:08:12.112590Z",
     "start_time": "2020-02-17T07:08:11.331036Z"
    }
   },
   "source": [
    "###### Load corresponding dataset batch\n",
    "\n",
    "# print(\"Saving pcds to {}\".format(OUTPUT_PCD_FOLDER_PATH))\n",
    "recons=[]\n",
    "total_recon = []\n",
    "##### For all batches of data\n",
    "for i, img_data in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):\n",
    "    dynamic_img = img_data.cuda()\n",
    "\n",
    "    if LEARN_TO_FILTER:\n",
    "        recon, xmask = model(process_input(dynamic_img))\n",
    "        masked_dynamic, masked_recon = masked_dynamic_recon(dynamic_img, recon, xmask)\n",
    "        recon=masked_recon\n",
    "    else:\n",
    "        recon = model(process_input(dynamic_img))\n",
    "\n",
    "    recons=recon\n",
    "    recons_temp=np.array(recons.detach().cpu())\n",
    "    recon_flag = 0.0\n",
    "    total_flag = 0.0\n",
    "    ###### Save all pcds\n",
    "    for frame_num in range(recons_temp.shape[0]):\n",
    "        frame = from_polar(recons[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "        dynamic_frame = from_polar(dynamic_img[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "\n",
    "        frame = frame * LIDAR_RANGE\n",
    "        dynamic_frame = dynamic_frame * LIDAR_RANGE\n",
    "\n",
    "        filtered_arr = np.zeros((frame.shape))\n",
    "        filtered_mask_arr = np.zeros((1,frame.shape[1],frame.shape[2]))\n",
    "        for i in range(frame.shape[1]):\n",
    "            for j in range(frame.shape[2]):\n",
    "                dist = np.linalg.norm(frame[:,i,j] - dynamic_frame[:,i,j])\n",
    "                if dist > 0.5:\n",
    "                    filtered_arr[:,i,j] = frame[:,i,j]\n",
    "                    filtered_mask_arr[:,i,j] = 1\n",
    "                    recon_flag += 1\n",
    "                else:\n",
    "                    filtered_arr[:,i,j] = dynamic_frame[:,i,j]\n",
    "                    filtered_mask_arr[:,i,j] = 0\n",
    "                total_flag += 1\n",
    "        break\n",
    "    break\n",
    "\n",
    "        some_pcd = o3d.geometry.PointCloud()\n",
    "        some_arr = filtered_arr.reshape((3,-1)).T\n",
    "        some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "        shape_tuple = filtered_mask_arr.shape\n",
    "        color_arr = np.concatenate((filtered_mask_arr, np.zeros(shape_tuple), np.zeros(shape_tuple)), axis=0)\n",
    "        some_pcd.colors = o3d.utility.Vector3dVector(color_arr.reshape((3,-1)).T)\n",
    "        pcd_fname = str(ply_idx) + \".ply\"\n",
    "        single_pcd_path = os.path.join(OUTPUT_PCD_FOLDER_PATH, pcd_fname)\n",
    "        o3d.io.write_point_cloud(single_pcd_path, some_pcd)\n",
    "        ply_idx += 1\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:08:30.771528Z",
     "start_time": "2020-02-17T07:08:30.766773Z"
    }
   },
   "source": [
    "filtered_mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:09:33.571780Z",
     "start_time": "2020-02-17T07:09:33.567160Z"
    }
   },
   "outputs": [],
   "source": [
    "some_pcd = o3d.geometry.PointCloud()\n",
    "some_arr = filtered_arr.reshape((3,-1)).T\n",
    "some_pcd.points = o3d.utility.Vector3dVector(some_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:12:03.248465Z",
     "start_time": "2020-02-17T07:12:03.245192Z"
    }
   },
   "outputs": [],
   "source": [
    "shape_tuple = filtered_mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:16:53.823595Z",
     "start_time": "2020-02-17T07:16:53.818194Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:16:40.780963Z",
     "start_time": "2020-02-17T07:16:40.776553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16, 1024)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
