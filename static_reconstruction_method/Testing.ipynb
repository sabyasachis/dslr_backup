{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T17:59:35.801838Z",
     "start_time": "2020-02-19T17:59:34.897487Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "# from utils import * \n",
    "from utils import *\n",
    "import open3d as o3d\n",
    "from models import *\n",
    "from collections import OrderedDict\n",
    "import os, shutil, gc\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:57.430764Z",
     "start_time": "2020-02-19T10:29:57.424603Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:57.443336Z",
     "start_time": "2020-02-19T10:29:57.432716Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='VAE training of LiDAR')\n",
    "parser.add_argument('--batch_size',         type=int,   default=16,             help='size of minibatch used during training')\n",
    "parser.add_argument('--use_selu',           type=int,   default=0,              help='replaces batch_norm + act with SELU')\n",
    "parser.add_argument('--base_dir',           type=str,   default='runs/test',    help='root of experiment directory')\n",
    "parser.add_argument('--no_polar',           type=int,   default=0,              help='if True, the representation used is (X,Y,Z), instead of (D, Z), where D=sqrt(X^2+Y^2)')\n",
    "parser.add_argument('--lr',                 type=float, default=1e-3,           help='learning rate value')\n",
    "parser.add_argument('--z_dim',              type=int,   default=1024,            help='size of the bottleneck dimension in the VAE, or the latent noise size in GAN')\n",
    "parser.add_argument('--autoencoder',        type=int,   default=1,              help='if True, we do not enforce the KL regularization cost in the VAE')\n",
    "parser.add_argument('--atlas_baseline',     type=int,   default=0,              help='If true, Atlas model used. Also determines the number of primitives used in the model')\n",
    "parser.add_argument('--panos_baseline',     type=int,   default=0,              help='If True, Model by Panos Achlioptas used')\n",
    "parser.add_argument('--kl_warmup_epochs',   type=int,   default=150,            help='number of epochs before fully enforcing the KL loss')\n",
    "parser.add_argument('--debug', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:57.453241Z",
     "start_time": "2020-02-19T10:29:57.447217Z"
    }
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:57.457326Z",
     "start_time": "2020-02-19T10:29:57.455129Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = \"/home/saby/Projects/ati/ati_motors/adversarial_based/static_reconstruction_method/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.530352Z",
     "start_time": "2020-02-19T10:29:57.459015Z"
    }
   },
   "outputs": [],
   "source": [
    "# MODEL_FOLDER_NAME = \"second_attempt_triple_data_restarted_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_150.pth\"\n",
    "# model = VAE(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = False\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_filtered_32f_triple_data_restarted_again2_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_245.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_filtered_64f_triple_data_restarted_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_105.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"second_attempt_ground_weighted_filtered_64f_triple_data_continued_correctly_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_260.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fourth_attempt_ground_weighted_filtered_polar_new_unet_64f_2048\"\n",
    "# MODEL_FILE_NAME = \"gen_300.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_no_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_498.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_sem_ground_weighted_filtered_polar_old_unet_32f_1024_continued\"\n",
    "# MODEL_FILE_NAME = \"gen_145.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_slam_weighted_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_115.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"fifth_attempt_inpainting_weighted_no_sem_ground_weighted_filtered_polar_old_unet_32f_1024\"\n",
    "# MODEL_FILE_NAME = \"gen_280.pth\"\n",
    "# model = VAE_filtered(args, n_filters=32).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "###################################\n",
    "# MODEL_FOLDER_NAME = \"first_new_attempt_new_unet_64f\"\n",
    "# MODEL_FILE_NAME = \"gen_125.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"first_new_attempt_new_unet_64f_no_dropout\"\n",
    "# MODEL_FILE_NAME = \"gen_84.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"trying_new_unet_correctly_64f_continued\"\n",
    "# MODEL_FILE_NAME = \"gen_80.pth\"\n",
    "# model = Unet_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "MODEL_FOLDER_NAME = \"trying_new_unet_correctly_64f_no_inpaint\"\n",
    "MODEL_FILE_NAME = \"gen_183.pth\"\n",
    "model = Unet_filtered(args, n_filters=64).cuda()\n",
    "LEARN_TO_FILTER = True\n",
    "MODEL_USED_DATA_PARALLEL = False\n",
    "\n",
    "# MODEL_FOLDER_NAME = \"\"\n",
    "# MODEL_FILE_NAME = \"gen_.pth\"\n",
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "# LEARN_TO_FILTER = True\n",
    "# MODEL_USED_DATA_PARALLEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.535199Z",
     "start_time": "2020-02-19T10:29:59.532084Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TEST_PATH = os.path.join(MODEL_BASE_PATH, MODEL_FOLDER_NAME, 'models', MODEL_FILE_NAME)\n",
    "if not os.path.exists(MODEL_TEST_PATH):\n",
    "    print(\"No Model file found at : {}\".format(MODEL_TEST_PATH))\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.807876Z",
     "start_time": "2020-02-19T10:29:59.537197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = VAE_filtered(args, n_filters=64).cuda()\n",
    "print(\"Loading model from {}\".format(MODEL_TEST_PATH))\n",
    "network=torch.load(MODEL_TEST_PATH)\n",
    "\n",
    "if MODEL_USED_DATA_PARALLEL:\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = network\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    model.load_state_dict(network)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T07:49:43.545790Z",
     "start_time": "2020-02-13T07:49:43.541412Z"
    }
   },
   "source": [
    "### Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.812117Z",
     "start_time": "2020-02-19T10:29:59.809433Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_BASE_PATH = \"/home/saby/Projects/ati/data/data/datasets/Carla/16beam-Data/small_map/testing\"\n",
    "DATA_TEST_FOLDER_LIST = [\"8\", \"24\", \"48\"]\n",
    "SAVE_PCD_NPY = True\n",
    "TEST_NPY_FOLDER = \"_out_out_npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.816163Z",
     "start_time": "2020-02-19T10:29:59.813593Z"
    }
   },
   "outputs": [],
   "source": [
    "LIDAR_RANGE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.826934Z",
     "start_time": "2020-02-19T10:29:59.817585Z"
    }
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])\n",
    "    \n",
    "def draw_pcd(pcd, where='opn_nb'):\n",
    "    if where is 'opn_nb':\n",
    "        visualizer = o3d.JVisualizer()\n",
    "        visualizer.add_geometry(pcd)\n",
    "        visualizer.show()\n",
    "    elif where is 'opn_view':\n",
    "        o3d.visualization.draw_geometries([pcd], width=1280, height=800)\n",
    "    elif where is 'mat_3d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1], pts[:,2])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    elif where is 'mat_2d':\n",
    "        plt.figure()\n",
    "        pts = np.asarray(pcd.points)\n",
    "        plt.scatter(pts[:,0], pts[:,1])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "def draw_registration_result(src_pcd, dst_pcd, x_pt, y_pt, theta):    \n",
    "    src_pcd_tmp = copy.deepcopy(src_pcd)\n",
    "    dst_pcd_tmp = copy.deepcopy(dst_pcd)\n",
    "    \n",
    "    src_pcd_tmp.paint_uniform_color([1, 0, 0])  # red source\n",
    "    dst_pcd_tmp.paint_uniform_color([0, 0, 1])  # blue target\n",
    "    \n",
    "    transform_mat = pose2matrix([x_pt, y_pt, 0], [0,0,theta])\n",
    "    dst_pcd_tmp.transform(transform_mat)\n",
    "    \n",
    "    visualizer = o3d.JVisualizer()\n",
    "    visualizer.add_geometry(src_pcd_tmp)\n",
    "    visualizer.add_geometry(dst_pcd_tmp)\n",
    "    visualizer.show()\n",
    "    \n",
    "process_input = from_polar if args.no_polar else lambda x : x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:29:59.832179Z",
     "start_time": "2020-02-19T10:29:59.828667Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_dynamic_recon(dynamic, recon, mask):\n",
    "    # bin_mask = (mask[:,0] - mask[:,1]).round().view((mask.shape[0], 1, mask.shape[2], mask.shape[3]))\n",
    "    bin_mask = mask[:,1].round().view((mask.shape[0], 1, mask.shape[2], mask.shape[3]))\n",
    "    masked_dynamic = (dynamic * (1-mask))\n",
    "    masked_recon = (dynamic * (1-mask)) + (mask * recon)\n",
    "    return masked_dynamic, masked_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:35:36.305653Z",
     "start_time": "2020-02-19T10:29:59.833833Z"
    }
   },
   "outputs": [],
   "source": [
    "for DATA_TEST_FOLDER in DATA_TEST_FOLDER_LIST:\n",
    "    print(\"\\n\\n\\n    Test folder : {}\".format(DATA_TEST_FOLDER))\n",
    "    ######## Set paths\n",
    "    OUTPUT_PCD_FOLDER = MODEL_FOLDER_NAME + \"_\" + MODEL_FILE_NAME.split(\".\")[0] + \"_pcd\" \n",
    "    if SAVE_PCD_NPY:\n",
    "        OUTPUT_NPY_FOLDER = OUTPUT_PCD_FOLDER + \"_out_npy\"\n",
    "\n",
    "    TEST_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, TEST_NPY_FOLDER)\n",
    "    OUTPUT_PCD_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, OUTPUT_PCD_FOLDER)\n",
    "    if SAVE_PCD_NPY:\n",
    "        OUTPUT_NPY_FOLDER_PATH = os.path.join(DATA_BASE_PATH, DATA_TEST_FOLDER, OUTPUT_NPY_FOLDER)\n",
    "\n",
    "    test_files  = sorted(os.listdir(TEST_NPY_FOLDER_PATH), key=getint)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PCD_FOLDER_PATH):\n",
    "        os.makedirs(OUTPUT_PCD_FOLDER_PATH)\n",
    "    else:\n",
    "        shutil.rmtree(OUTPUT_PCD_FOLDER_PATH)\n",
    "        os.makedirs(OUTPUT_PCD_FOLDER_PATH)\n",
    "\n",
    "    if SAVE_PCD_NPY:\n",
    "        if not os.path.exists(OUTPUT_NPY_FOLDER_PATH):\n",
    "            os.makedirs(OUTPUT_NPY_FOLDER_PATH)\n",
    "        else:\n",
    "            shutil.rmtree(OUTPUT_NPY_FOLDER_PATH)\n",
    "            os.makedirs(OUTPUT_NPY_FOLDER_PATH)\n",
    "\n",
    "    ply_idx = 1\n",
    "    if SAVE_PCD_NPY:\n",
    "        npy_idx = 0\n",
    "\n",
    "    for test_file in test_files:\n",
    "        ###### Load corresponding dataset batch\n",
    "        print(\"processing {}\".format(test_file))\n",
    "        dataset_val = np.load(os.path.join(TEST_NPY_FOLDER_PATH, test_file))\n",
    "        dataset_val = preprocess(dataset_val, LIDAR_RANGE)\n",
    "        dataset_val = dataset_val.astype('float32')\n",
    "        val_loader  = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size,\n",
    "                            shuffle=False, num_workers=12, drop_last=False)\n",
    "\n",
    "        print(\"done\")\n",
    "        print(\"Saving pcds to {}\".format(OUTPUT_PCD_FOLDER_PATH))\n",
    "        recons=[]\n",
    "        total_recon = []\n",
    "        ##### For all batches of data\n",
    "        for i, img_data in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):\n",
    "            dynamic_img = img_data.cuda()\n",
    "\n",
    "            if LEARN_TO_FILTER:\n",
    "                recon, xmask = model(process_input(dynamic_img))\n",
    "                masked_dynamic, masked_recon = masked_dynamic_recon(dynamic_img, recon, xmask)\n",
    "                recon=masked_recon\n",
    "            else:\n",
    "                recon = model(process_input(dynamic_img))\n",
    "\n",
    "            recons=recon\n",
    "            recons_temp=np.array(recons.detach().cpu())\n",
    "            \n",
    "            ###### Save all pcds\n",
    "            for frame_num in range(recons_temp.shape[0]):\n",
    "                frame = from_polar(recons[frame_num:frame_num+1,:,:,:]).detach().cpu().numpy()[0]\n",
    "                frame_actual = np.array([frame_image for frame_image in frame])\n",
    "                frame_flat = frame_actual.reshape((3,-1))\n",
    "                frame_crop = frame_flat#[:,(frame_flat[2]  > 0.005)]\n",
    "                some_pcd = o3d.geometry.PointCloud()\n",
    "                some_arr = frame_crop.T * LIDAR_RANGE\n",
    "                some_pcd.points = o3d.utility.Vector3dVector(some_arr)\n",
    "                pcd_fname = str(ply_idx) + \".ply\"\n",
    "                single_pcd_path = os.path.join(OUTPUT_PCD_FOLDER_PATH, pcd_fname)\n",
    "                o3d.io.write_point_cloud(single_pcd_path, some_pcd)\n",
    "                ply_idx += 1\n",
    "            gc.collect()\n",
    "\n",
    "            ##### Append model outputs array\n",
    "            if SAVE_PCD_NPY:\n",
    "                recon_arr = from_polar(recon).detach().cpu().numpy()\n",
    "                # add color mask as zeros for now\n",
    "                if LEARN_TO_FILTER:\n",
    "                    bin_mask = xmask[:,0].round().view((xmask.shape[0], 1, xmask.shape[2], xmask.shape[3]))\n",
    "                    bin_mask = bin_mask.detach().cpu().numpy()\n",
    "                    color_arr = bin_mask\n",
    "                else:\n",
    "                    color_arr = np.zeros((recon_arr.shape[0], 1, recon_arr.shape[2], recon_arr.shape[3]))\n",
    "\n",
    "\n",
    "                recon_arr_4d = np.concatenate((recon_arr, color_arr), axis=1)\n",
    "                if i == 0:\n",
    "                    total_recon = recon_arr_4d\n",
    "                else:\n",
    "                    total_recon = np.concatenate((total_recon, recon_arr_4d), axis=0)\n",
    "                gc.collect()\n",
    "        print(\"done\")\n",
    "        \n",
    "        ##### Save model outputs array npy if necessary\n",
    "        if SAVE_PCD_NPY:\n",
    "            total_recon = total_recon.transpose(0,2,3,1)\n",
    "            npy_name = str(npy_idx) + \".npy\"\n",
    "            npy_path = os.path.join(OUTPUT_NPY_FOLDER_PATH, npy_name)\n",
    "            print(\"Saving to {}\".format(npy_path))\n",
    "            np.save(npy_path, total_recon)\n",
    "            npy_idx += 1\n",
    "            print(\"done\")\n",
    "print(\"Done for all folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T17:59:41.751715Z",
     "start_time": "2020-02-19T17:59:40.830470Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_val = np.load(\"/home/saby/Projects/ati/data/data/datasets/Real_World/Real_Train_Data/static_npy_data/1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-19T18:00:27.609Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_val = preprocess(dataset_val, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
